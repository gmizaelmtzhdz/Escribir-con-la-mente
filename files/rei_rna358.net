FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 8.96758518353583720000e+001) (1, -3.62222625808239090000e+001) (2, -4.15153492696459470000e+002) (3, 2.16921270329806960000e+002) (4, 1.00072920721969790000e+003) (5, -1.50000000000000000000e+003) (6, 2.31633452030107550000e+002) (7, 7.40219186505664200000e+002) (8, 1.37383191050620560000e+001) (0, 1.06498314404455700000e+000) (1, -6.35756052172690040000e-001) (2, 7.18213863167368420000e+000) (3, 4.91816732602618960000e+000) (4, 2.90996607505600090000e+001) (5, -7.90091825052306970000e+001) (6, 3.01553364602047650000e+001) (7, -9.63337371159981470000e+001) (8, 4.97326153674820800000e-001) (0, -2.10540314534327810000e+001) (1, 3.38908462550885050000e+000) (2, -3.56366210075294770000e+001) (3, -3.26690382774792520000e+001) (4, 4.94733287916174690000e+001) (5, 9.22438385621079110000e+001) (6, -3.04891463853800740000e+001) (7, 4.49092155192730050000e+001) (8, 3.63335451144197610000e+000) (0, -2.23407910087060690000e+000) (1, -1.52383649132115060000e+000) (2, -1.48330002287502860000e+001) (3, -2.49815561138942960000e+001) (4, -7.13101813971238130000e+000) (5, 1.08451710107678810000e+002) (6, -5.49456662491775210000e+001) (7, 9.89406652620276500000e+001) (8, 6.29708544768085240000e-001) (0, -1.09591223802773140000e+001) (1, -7.05280831095454540000e+000) (2, -1.06804740091198000000e+001) (3, 5.80705353775066380000e-001) (4, -1.33954709159741900000e+001) (5, 4.84628602903747210000e+001) (6, -1.19269272584004860000e+001) (7, 2.02734558408845760000e+001) (8, 2.34628863237533960000e+000) (0, 1.48497004714494870000e+000) (1, -8.51084747332576970000e+000) (2, 1.11108387570988910000e+001) (3, -1.28698420809183210000e+001) (4, 5.26081607961079100000e+001) (5, -2.12510901799359040000e+001) (6, 1.48467139186471610000e+001) (7, -5.08886383696256600000e+001) (8, 3.92568232979244260000e-001) (0, 4.00540585225446580000e+000) (1, 7.64755705520877260000e+000) (2, -4.12457873817984290000e+001) (3, 3.26521937529185850000e+001) (4, -6.58047109262005580000e+000) (5, -3.47256454596559290000e+001) (6, 1.30785893820867990000e+001) (7, 1.20126139700692480000e+002) (8, -2.18263053702624180000e+000) (0, 1.93206925720457990000e+000) (1, -1.32464741779657170000e-001) (2, 3.14631687001969460000e+000) (3, -5.85100721088271760000e+000) (4, 9.00094453607174040000e+000) (5, -3.61194783897258760000e+000) (6, 1.32789325139288720000e+000) (7, -9.53494474058872400000e+000) (8, -1.22115861233285850000e-002) (0, -7.20437892116745890000e+000) (1, -1.13465263711418310000e+001) (2, 5.17762283872576750000e+001) (3, -3.55168926891329310000e+001) (4, 8.54723377523318110000e+001) (5, 2.22430071166977290000e+001) (6, 1.64944993677886860000e+000) (7, -1.49470320790115320000e+002) (8, 1.62120041974831080000e+000) (0, -3.75584161353608500000e-001) (1, 6.70252893669274210000e-001) (2, -9.89402312123934370000e-001) (3, 5.22298400491038620000e+000) (4, -6.10880118319475600000e+000) (5, -3.22597386370440550000e+000) (6, 1.57384522789131950000e+000) (7, 4.33419663633795690000e+000) (8, -6.57110575213072370000e-001) (9, 7.33603085229738660000e-003) (10, -5.72731050402052740000e-001) (11, 4.64562453767465580000e-001) (12, -5.28561961163445670000e-001) (13, -7.90571667739445320000e-001) (14, 6.21634937253469190000e-001) (15, -4.29330715160350540000e-001) (16, -2.22788578145198990000e+000) (17, -4.41570591357831050000e-001) (18, -1.37444125265792970000e+000) (19, 4.14302781067053040000e-001) (9, 1.54596297218462400000e-002) (10, 3.91427879910050680000e-001) (11, -3.62524387090321360000e-001) (12, 3.15637658059727380000e-001) (13, 7.24841357114312190000e-001) (14, -7.34334855393859560000e-001) (15, 4.38496213185238400000e-001) (16, 1.74361638261165860000e+000) (17, 5.40930674152730660000e-001) (18, 3.82556004981649270000e-001) (19, 6.92567954155104190000e-001) (9, -2.06656980903547090000e-001) (10, 7.13942952867272270000e-001) (11, -1.59310206376450100000e-001) (12, 7.50006048466260290000e-001) (13, 4.23713563813316040000e-001) (14, -1.10165576026393800000e-001) (15, 2.70812166577467980000e-001) (16, 1.63351655146915340000e+000) (17, 2.08390585962184490000e-001) (18, 3.12905847945508290000e+000) (19, 1.69065420720906000000e+000) (9, 8.42201129565401660000e-002) (10, 2.09653179841853720000e-001) (11, -6.29613681036832460000e-001) (12, 1.77816412372399420000e-001) (13, 1.11492861022979390000e+000) (14, -5.13252426193937520000e-001) (15, 3.50687264025655700000e-001) (16, 2.53239744929547860000e+000) (17, 3.44540554398112540000e-001) (18, 8.86972765887488860000e-001) (19, 9.91764747683127280000e-001) (9, 1.25945991323599020000e-002) (10, 5.72914170273492120000e-001) (11, -2.86439117198708130000e-001) (12, 7.06846378876431200000e-001) (13, 3.19157862644763260000e-001) (14, -2.74830218800177220000e-001) (15, 3.95644712876292490000e-001) (16, 1.28270341612234120000e+000) (17, 4.87216155652528900000e-001) (18, 1.97112183555358220000e+000) (19, 1.39544112445612090000e+000) 
