FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.82899138953117410000e+002) (1, 1.05766194912008630000e+003) (2, -4.53063147345478340000e+002) (3, 9.44259423358855320000e+002) (4, -3.20759544907478360000e+002) (5, -1.50000000000000000000e+003) (6, 6.82913783481500190000e+001) (7, 1.50000000000000000000e+003) (8, -2.02370427663716190000e+001) (0, 4.01242531768934810000e+000) (1, 1.58930834326730730000e+001) (2, -9.54441924020720830000e+000) (3, 8.68250565978103770000e+000) (4, 4.79434455664696650000e+000) (5, -2.22087599524046940000e+001) (6, -1.80778379667236930000e+000) (7, 1.53942156400749700000e+001) (8, -6.48535430390416170000e-001) (0, -1.41523123118215630000e+001) (1, -5.49419256926424420000e+001) (2, 1.29549225603888000000e+001) (3, -1.02712549865074030000e+001) (4, -3.02493460186231290000e+001) (5, 4.25576176127659740000e+001) (6, 1.22952715149659730000e+001) (7, -2.55029767233901660000e+001) (8, 4.76126068650704590000e+000) (0, -3.38965943254038700000e+000) (1, -2.89616046381763790000e+001) (2, -4.61418095251115990000e+000) (3, 3.37876072390412790000e+001) (4, 9.82925251909901120000e+000) (5, -3.05980783355854660000e+001) (6, -1.90554431062798880000e+001) (7, 2.19187624968420140000e+001) (8, -3.73509386183133170000e-001) (0, -3.30086885091217890000e+000) (1, -4.61402856013469620000e+000) (2, 3.60618413461202400000e+000) (3, -4.90869916660282350000e+000) (4, -4.43089013279388320000e+000) (5, 1.18271166931825640000e+001) (6, 5.45129788167990630000e+000) (7, 1.93314085065024170000e+001) (8, -6.25322758676132070000e-001) (0, 6.50032760550597550000e+000) (1, 3.63964548357639290000e+000) (2, 6.27494590114692220000e-001) (3, -3.19705665260775440000e+001) (4, 9.21069045091941870000e+000) (5, 7.14211787684170220000e+000) (6, 6.05291236531176760000e+000) (7, -4.09113773664913720000e+001) (8, 9.36047409160146840000e-001) (0, 9.70650414835258930000e-001) (1, -2.32223093858815090000e-001) (2, 1.80611193504183200000e+000) (3, -2.11706908402124980000e+000) (4, 9.62271052839790420000e-001) (5, 2.77293647080514960000e+000) (6, -1.75365880289222600000e+000) (7, -1.27826741613925080000e+001) (8, 7.92355868153049810000e-001) (0, 1.27424893847708770000e+002) (1, -5.61445910235712060000e+002) (2, -1.69078838948365160000e+002) (3, 1.50000000000000000000e+003) (4, 1.48843887201923310000e+002) (5, -7.13530441262255410000e+002) (6, 9.97015114098812550000e+002) (7, -9.12830997641204590000e+002) (8, 4.38912232019644860000e+001) (0, 1.72809955545489300000e+001) (1, -2.12264935522792690000e+001) (2, -1.67049636324036510000e+001) (3, 3.42923617888730060000e+002) (4, -6.50447262495704170000e+001) (5, -1.62421955084343300000e+002) (6, 6.30904561246605490000e-002) (7, -3.41338780946028630000e+001) (8, 1.06813865301193120000e+001) (0, 4.25147938917917050000e+000) (1, 1.84781405215791710000e+001) (2, 4.95694810418752940000e+000) (3, -5.56522992864686830000e+001) (4, -4.88422231870320460000e+000) (5, 2.82241924785851270000e+001) (6, 3.13750757867148060000e+001) (7, -2.40896914013835150000e+001) (8, 6.90468220263716790000e-001) (9, 3.39579986517569090000e-002) (10, -1.23397865774348860000e+000) (11, -4.17604432161740870000e-001) (12, 2.86206984372799460000e-001) (13, -1.52134946604534460000e+000) (14, -7.33804813111212150000e-001) (15, -1.65431426102669570000e+000) (16, 2.86246507688388770000e-001) (17, -4.08625429746562690000e-001) (18, 7.32178706742159900000e-001) (19, 1.10145601644088380000e+000) (9, -1.05910139202126320000e-001) (10, 1.24806432887385400000e+000) (11, 5.11601744164664310000e-001) (12, -4.47308438975736410000e-001) (13, 1.24620890805622970000e+000) (14, 4.56310279600663390000e-001) (15, 1.50834328474467290000e+000) (16, -7.73951978604933480000e-001) (17, 3.05744442627359840000e-001) (18, -6.56469584331993210000e-001) (19, 7.97425078528262610000e-001) (9, -8.65483254624555140000e-002) (10, 2.86063289311886510000e-001) (11, 2.08663991260724350000e-001) (12, -9.66957459495000670000e-001) (13, 4.82662184190597420000e-001) (14, 7.38903866922708600000e-001) (15, -8.01963663156086910000e-001) (16, -2.70651687158819710000e-001) (17, 5.68121793532028960000e-001) (18, -1.12238275678628870000e+000) (19, 7.74336700528957870000e-001) (9, -1.08244118337210190000e-001) (10, 2.02184156744499610000e+000) (11, 6.37048104474466140000e-001) (12, -9.72702137341133620000e-002) (13, 1.79632088043024040000e+000) (14, 1.86040774026508370000e-001) (15, 3.48495338773046550000e+000) (16, 2.16940382724857830000e-001) (17, -5.24376869493951680000e-001) (18, -4.26682263869973100000e-001) (19, 4.56147295486226230000e-001) (9, -6.52827010237413410000e-002) (10, 9.63876435979666990000e-001) (11, 2.87956948794669320000e-001) (12, -1.58720557523361140000e-001) (13, 1.06177188524868990000e+000) (14, 7.92826336034541670000e-001) (15, 5.94175655454379670000e-001) (16, -2.21773510445893080000e-001) (17, 4.79358280457009010000e-002) (18, -7.54943780308818810000e-001) (19, 1.19944057233970040000e+000) 
