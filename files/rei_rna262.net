FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 8.40208636344278230000e+000) (1, 4.07500955138878300000e-001) (2, -1.05404242441306000000e+001) (3, -7.53850950191707800000e+000) (4, 1.16287253678609190000e+002) (5, 4.58947455073839020000e+001) (6, 1.62587077246852690000e+002) (7, -1.93513481898197970000e+002) (8, -3.50898205168151690000e+000) (0, 1.63927999601584060000e+001) (1, -4.39855431396647400000e+000) (2, -3.46101698820300640000e+001) (3, 1.03704769336849110000e+001) (4, 1.68210453134732660000e+002) (5, -2.57227989341197170000e-001) (6, 2.33467823274922950000e+002) (7, -2.19740640120191760000e+002) (8, -4.23843455678064010000e+000) (0, -8.26778804692061550000e-001) (1, -1.01147804877211710000e+000) (2, 4.02986082459808940000e-001) (3, 3.81084779547264900000e+000) (4, -2.39997900784685170000e+000) (5, 5.67879552569520500000e-001) (6, -8.66789627959748680000e-001) (7, 2.95458298113299870000e+000) (8, 5.30513324684305340000e-001) (0, -1.22997667682409050000e+000) (1, -5.71946144914927950000e+000) (2, 5.47626770701257830000e+000) (3, 7.44231254652059790000e+000) (4, -2.54738193330992900000e+000) (5, 1.22840018838941050000e+001) (6, -1.44284193169196450000e+000) (7, 1.42683890319557280000e-001) (8, 6.73752849731834580000e-001) (0, 5.78391088133261700000e-002) (1, -2.71015704254651580000e+000) (2, -3.52210948804413670000e-001) (3, 2.76212093249544080000e+000) (4, 1.80272759958986130000e+000) (5, -3.89137137344203540000e+000) (6, 2.76419172821903540000e-001) (7, 7.79718123622645100000e+000) (8, 7.11807590254334290000e-002) (0, 1.76303608639238040000e+000) (1, -5.82225226448710330000e-001) (2, 1.32389842643790650000e+001) (3, 1.99124528179890770000e+001) (4, -1.50237615429226330000e+001) (5, -7.31829843783748670000e+000) (6, -1.06686503318402030000e+001) (7, 1.91678968735136160000e+001) (8, 1.02021199943140490000e-002) (0, 3.06048833089775650000e-001) (1, -7.81265004750709370000e-001) (2, 1.58926147948292550000e-001) (3, 5.15092860140142990000e-001) (4, 1.95481067925243530000e+000) (5, -2.34486537607359760000e+000) (6, 2.05917397161461620000e+000) (7, -2.30744421146803890000e+000) (8, -9.18665953254141910000e-002) (0, 4.62131882170814020000e-001) (1, 4.88522143202949230000e-001) (2, 2.08591697894020320000e+000) (3, 7.98448347698092320000e+000) (4, -9.63252621815286810000e-001) (5, -8.43592790354008320000e+000) (6, 4.70386504989508760000e+000) (7, -8.67579324778461470000e+000) (8, 2.05610061783866540000e-001) (0, 6.18250544294915820000e+000) (1, 1.55441057875874630000e+000) (2, 2.14379029453497980000e+001) (3, 3.83049480830037580000e+001) (4, -2.32626798992069970000e+001) (5, -2.92268743293734870000e+001) (6, -9.19054103179969720000e-001) (7, -9.55083208644834340000e+000) (8, 6.69526243869590590000e-001) (0, -6.10479051401954680000e+001) (1, -2.70715864111492350000e+002) (2, -6.98159466858643670000e+002) (3, 1.98402640742107370000e+002) (4, 7.21058927714050920000e+002) (5, -6.53342539170143480000e+002) (6, -1.22124267146244310000e+002) (7, -2.84458356362920530000e+001) (8, -8.51745637681684990000e-001) (9, 1.94608999066220900000e-002) (10, 1.73047639153493040000e-002) (11, 3.31109354706341110000e+000) (12, -8.22004635484112840000e-001) (13, -1.48346087200146370000e+000) (14, 5.63385848987331910000e-001) (15, 5.79126023240818990000e+000) (16, -7.74603257516397910000e-001) (17, -4.04109701481959290000e-001) (18, -9.19454352379704960000e-002) (19, 4.74237626803279080000e-001) (9, -1.41210937785766460000e-003) (10, -4.25009377183237500000e-002) (11, -2.15647468694300140000e+000) (12, 6.94109923846643160000e-001) (13, 8.27945504720752570000e-001) (14, -4.25774205457184750000e-001) (15, -3.94955018444129770000e+000) (16, 5.74020202095575250000e-001) (17, 1.15400137704080340000e-001) (18, 3.09895647740611110000e-002) (19, 8.66089439556278710000e-001) (9, 4.48547876424731760000e-001) (10, -4.43201603483466490000e-001) (11, -3.45920207414413960000e+000) (12, 8.05204306903443360000e-001) (13, 3.07392857060035540000e+000) (14, -1.11649672301668690000e+000) (15, -9.79528262950354640000e+000) (16, 2.17050631713497920000e+000) (17, 4.29724638266927750000e-001) (18, 6.26704570221323640000e-002) (19, 8.12698754850419540000e-001) (9, -8.56071996619507390000e-001) (10, 6.81262345056770860000e-001) (11, -2.09921588704528620000e+000) (12, 9.06054057290138100000e-001) (13, -8.81036512935401530000e-001) (14, 4.48240267942513930000e-001) (15, 1.14211111343199680000e+000) (16, 8.34720355527981520000e-001) (17, -6.13650865071592940000e-001) (18, -8.02193482218603180000e-002) (19, 1.24278081562635000000e+000) (9, -7.99687970533809190000e-003) (10, -2.43610304714929620000e-002) (11, -5.20438939142612340000e+000) (12, 1.38743406820869520000e+000) (13, 3.37152164827907040000e+000) (14, -1.15611969610833270000e+000) (15, -1.04684786463145620000e+001) (16, 1.81010379374159050000e+000) (17, 6.10852767788964470000e-001) (18, 2.74722038869384570000e-001) (19, 1.20650720741580520000e+000) 
