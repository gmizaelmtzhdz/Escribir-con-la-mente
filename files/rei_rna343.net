FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 8.45210138493658650000e+000) (1, -1.34487723277962060000e+001) (2, 2.74357415572154900000e+001) (3, 3.95083297990483260000e+001) (4, -1.57486509025629770000e+001) (5, -3.72516706972601310000e+001) (6, 2.28599849557026220000e+001) (7, -4.80658266612991550000e-001) (8, -1.03750516979268830000e+000) (0, 8.61897942656042470000e-002) (1, 3.77170790842779220000e+000) (2, 8.11153438872330820000e-001) (3, -4.00089190404764490000e+001) (4, 5.72151481335615840000e+000) (5, 2.18667138278612820000e+001) (6, 2.62526662438933050000e+001) (7, -3.65071399852486560000e+001) (8, 2.30109545886391810000e+000) (0, -1.12148338771339890000e+000) (1, -1.21868159218524890000e+001) (2, 6.76113796479526300000e+000) (3, -5.07201129985031600000e+000) (4, -4.10421083582076650000e+000) (5, 3.67200738945534510000e+000) (6, 7.22653972562306460000e+000) (7, -5.72108574281899870000e+000) (8, -3.01069698246928700000e-001) (0, 4.75081466938038040000e-001) (1, 1.29672362615878750000e+001) (2, 3.23286321156945800000e+000) (3, -2.74251595685308230000e+001) (4, 1.82126758917853590000e+001) (5, 3.32602449696440350000e+001) (6, 1.99905344423524300000e+000) (7, -3.74816023288091180000e+000) (8, 1.80786752914889800000e-001) (0, 5.06483718854979690000e+000) (1, 3.21550511718908040000e+001) (2, -1.17260991082371330000e+001) (3, 9.94278438682158060000e+000) (4, 5.14604937991035880000e+001) (5, -1.44696545094659230000e+000) (6, -2.20138400169575060000e+001) (7, -3.47933477725997080000e+000) (8, -2.02668557766862320000e+000) (0, -2.45725717666663290000e-001) (1, 3.56667562341048900000e+000) (2, -5.27114184278990460000e+000) (3, 4.08554573316441690000e+000) (4, 8.20604495770751720000e+000) (5, -4.60706453952515280000e+000) (6, -5.30545909966352200000e-001) (7, -2.15435536749476150000e+000) (8, -1.51654237774235810000e+000) (0, -8.64966934659538440000e-002) (1, 8.88330646355810160000e-001) (2, -1.16420513721795530000e-001) (3, -7.71340324371741380000e+000) (4, 5.54987372760426110000e+000) (5, 1.82519801645134190000e+000) (6, 7.02653634170534060000e+000) (7, -1.37108920035192980000e+001) (8, -1.61876177882645410000e+000) (0, 1.04351571165525860000e+001) (1, -1.06136719884112730000e+001) (2, 1.21450423541005290000e+001) (3, 1.63373336346911980000e+001) (4, 3.21071187974631730000e+001) (5, -3.76355511896498380000e+001) (6, 2.26323921395121420000e+001) (7, -2.04022792049255380000e+001) (8, -2.59487337366462290000e-001) (0, 1.03972080998422320000e+000) (1, 2.70337878517489120000e+001) (2, 7.31282464699063170000e+000) (3, -6.78169949990513320000e+001) (4, -1.46148904149405680000e+001) (5, 4.78040684121056290000e+001) (6, 3.37419142405958750000e+001) (7, -7.28923257387693990000e+000) (8, 8.07759191936495370000e-001) (0, -6.21318270361531600000e+000) (1, 1.43386383240315340000e+001) (2, -2.51380585107640330000e+001) (3, -4.01006651397223380000e+001) (4, 2.76760086542791550000e+001) (5, 2.26552910975497210000e+001) (6, -6.17150233585020480000e+000) (7, -2.60179806938048270000e+001) (8, 9.67126165112996980000e-001) (9, 1.64226056542082190000e-001) (10, -2.23839019450595670000e-001) (11, 1.62862966599384240000e+000) (12, -7.52217522368951230000e-001) (13, 6.06251351091272260000e-001) (14, 1.43700327003231250000e+000) (15, -4.27707980000001380000e-001) (16, -3.11526669672336660000e-001) (17, 4.97671285032685260000e-001) (18, 7.63137721856016750000e-002) (19, 1.97456742739416070000e+000) (9, -3.50720566415364530000e-002) (10, 3.64174889647880670000e-002) (11, -9.96932580706795140000e-001) (12, 6.53344316233378190000e-001) (13, -3.65689308803211540000e-001) (14, -1.20611003020834560000e+000) (15, 8.83460798024614190000e-001) (16, -3.41153746323084870000e-002) (17, -4.18894523582221900000e-001) (18, 3.56587438353675460000e-002) (19, 2.74311012351026670000e-001) (9, 8.38193707769653630000e-001) (10, -2.98234198083792260000e-001) (11, -1.13574308309586880000e+000) (12, 9.64094169479837390000e-001) (13, -6.14818211040867420000e-001) (14, -1.27010650368604460000e+000) (15, 1.00734307169228650000e-001) (16, -1.07123007313618370000e-001) (17, -4.40323715024219300000e-001) (18, 9.07889268226679920000e-001) (19, -5.77249387122785870000e-002) (9, -2.52354622701260120000e+000) (10, -1.27378423365015260000e+000) (11, -1.95772402264514090000e+000) (12, 1.63894953449763210000e-001) (13, -6.46840111443210300000e-001) (14, -2.07288963438221870000e+000) (15, 8.77928106497498110000e+000) (16, 1.01657789905511800000e+000) (17, -7.07592351161935030000e-002) (18, -2.25054283267415210000e+000) (19, 5.28788959552123310000e+000) (9, -3.55885934794044960000e-001) (10, -3.15453846911797120000e-001) (11, -1.52849353806297650000e+000) (12, 7.64276345349267580000e-001) (13, -6.53036729588304390000e-001) (14, -1.87578927262060270000e+000) (15, 9.92948964097935200000e-001) (16, 6.57677099443809250000e-001) (17, -4.96003832444727070000e-001) (18, 6.65307679092374950000e-002) (19, 5.86176271499045800000e-002) 
