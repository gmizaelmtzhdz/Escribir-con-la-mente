FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 5.80764058232308144625e-02) (1, 6.63853864371777291353e-02) (2, 1.38084532618522715097e-01) (3, 1.29964994192123484140e-01) (4, 2.37901601195336098726e-02) (5, 1.43819572329521250253e-01) (6, 7.67829361557961220797e-02) (7, 3.82339450716973061617e-02) (8, 6.66463094949723000582e-02) (0, 8.75117647647858376558e-02) (1, 8.80148950219155068453e-02) (2, 3.03113925457001442965e-02) (3, 1.76389345824718546396e-01) (4, 2.83390748500824685152e-02) (5, 1.32049063146114420420e-01) (6, 1.06981890201568674570e-01) (7, 1.10063875019550394541e-01) (8, 2.07044253051281046396e-01) (0, -1.21676573455333780771e-01) (1, -1.39346996247768473154e-01) (2, -1.60840490758419107920e-01) (3, -1.39456713497638773447e-01) (4, -2.45735588669777627047e-02) (5, -1.91624538898468088632e-01) (6, -9.04325935244560952242e-02) (7, -1.03473054170608591562e-01) (8, -1.24307641685009073740e-01) (0, 6.01657497882843728121e-02) (1, 1.20544360876083445078e-01) (2, 1.12396651804447245127e-01) (3, 1.16371476948261332041e-01) (4, 1.58620769083499979502e-01) (5, 1.58782029449939798837e-01) (6, 3.44560089707375283297e-02) (7, 6.85857552289963479097e-02) (8, 1.62572199404239725595e-01) (0, -8.17244294285774941500e-02) (1, -1.14631319344043802744e-01) (2, -5.91938886046410317476e-02) (3, -3.50781324505806679781e-02) (4, -4.71195670962334389742e-02) (5, -1.91178994178772043711e-01) (6, -2.47667375206948037203e-02) (7, -9.07302293181420083101e-02) (8, -1.82839916944503855234e-01) (0, 1.27282323241233896738e-01) (1, 3.62516659498215432222e-02) (2, 1.47223958671093058115e-01) (3, 1.14326568245887827402e-01) (4, 1.34575107991695475107e-01) (5, 2.78769749403000588472e-02) (6, 1.73486078083515238291e-01) (7, 2.15118402540683817392e-01) (8, 2.33034136891365761812e-02) (0, -3.81384584307671303804e-02) (1, -9.53142064809799904879e-02) (2, -1.00169645547866892343e-01) (3, -1.42446095049381327158e-01) (4, -5.51484617590904946383e-02) (5, -1.99625285267829966074e-01) (6, -5.00494483113289589937e-02) (7, -1.58776989132165979868e-01) (8, -6.10045287013054604586e-02) (0, 1.28732586205005716806e-01) (1, 9.56790316104889626558e-02) (2, 2.75812315940857644136e-02) (3, 7.13047738373280282076e-02) (4, 3.39545997977257485445e-02) (5, 1.32949912846088480478e-01) (6, 3.21109014749527688082e-02) (7, 2.18876475393772196298e-01) (8, 1.05830350816249918466e-01) (0, -1.79068097770214151865e-01) (1, -2.58902701735497231539e-02) (2, -2.04899886548519205576e-01) (3, -1.41908006668090891367e-01) (4, -1.18607954978942942148e-01) (5, -1.88648225665092539316e-01) (6, -2.14684056043624948984e-01) (7, -2.42813917994499917086e-02) (8, -7.40731301903725380953e-02) (0, 3.31929269433022255953e-02) (1, 1.69204691350460123545e-01) (2, 1.61045262515544962412e-01) (3, 3.64963430166245217379e-02) (4, 1.51066252887249063974e-01) (5, 8.57310685515404458101e-02) (6, 1.56326705515384745127e-01) (7, 2.86201480031014199312e-02) (8, 5.05826118588448281344e-02) (9, -6.32985922694206948336e-02) (10, 1.98570707738399576670e-01) (11, -1.28194386065006327158e-01) (12, 1.35696904659271311289e-01) (13, -1.32696719765663218027e-01) (14, -5.25153669714928383883e-02) (15, 1.43278123736381601816e-01) (16, -8.13919547200203652437e-02) (17, 2.01439240872860025888e-01) (18, -1.83771984577179026132e-01) (19, 1.70718962252140116220e-01) (9, -3.96842899918556923922e-02) (10, 1.42058359384536814218e-01) (11, -2.83491554856301064547e-02) (12, 1.94425458014011454111e-01) (13, -8.28415247797966713961e-02) (14, -1.50257149636745523935e-01) (15, 9.58174932003021950777e-02) (16, -5.14897498488426919039e-02) (17, 9.50588154792786355074e-02) (18, -1.48463906645774912363e-01) (19, 1.34437145590782236582e-01) (9, -1.31748275756836008554e-01) (10, 4.07407972216606850679e-02) (11, -1.64517609328031610971e-01) (12, 1.24748075306415628916e-01) (13, -6.81929829716683144625e-02) (14, -9.87865495681763405855e-02) (15, 6.10747690498829598482e-02) (16, -5.95728400349617714937e-02) (17, 1.71796077787876200205e-01) (18, -2.22238245606423134859e-02) (19, 1.58997872769832682138e-01) (9, -1.76398323774337839609e-01) (10, 1.33473077714443277841e-01) (11, -1.93698855042457651621e-01) (12, 3.10863348841667885836e-02) (13, -1.83248819708824228769e-01) (14, -5.50907942652703042086e-02) (15, 2.12525570690631937509e-01) (16, -1.47020803689956736093e-01) (17, 1.35628150701522898203e-01) (18, -4.71587273478508706148e-02) (19, 2.15037563741207193857e-01) (9, -1.12720990478992533212e-01) (10, 1.67266720831394266611e-01) (11, -8.78039541840553994234e-02) (12, 1.97021881043911051279e-01) (13, -1.96915807127952646738e-01) (14, -1.19293706417083811289e-01) (15, 7.20806847512722725924e-02) (16, -1.25379698276519846445e-01) (17, 3.51434367895127053316e-02) (18, -7.96675923466683144625e-02) (19, 1.35361099541187357431e-01) 
