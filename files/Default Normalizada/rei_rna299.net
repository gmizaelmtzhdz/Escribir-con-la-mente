FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -6.32407525289836240000e-001) (1, 1.54564828273901430000e+000) (2, -1.66479792247522460000e-001) (3, -5.12703584793050120000e+000) (4, 9.72172434650649060000e-001) (5, 3.79875639765681060000e+000) (6, -4.95834838733460570000e-001) (7, -2.04200046306952920000e+000) (8, -2.43044478482241200000e-001) (0, 1.81983139448245180000e+000) (1, 1.31255969794611540000e+000) (2, 4.27804568751447970000e+000) (3, -1.47829815252563020000e+000) (4, 1.55792697723754920000e+001) (5, -3.18659841698888610000e+000) (6, 1.62008088634154890000e+001) (7, -6.61880873880460820000e+000) (8, -2.12321741193029300000e-001) (0, -5.61414929014313200000e+000) (1, 2.80810740604472690000e+000) (2, -2.04327454573535010000e+000) (3, -1.22916099699052840000e+001) (4, 9.83738429058566410000e+000) (5, 1.52771851629027960000e+001) (6, -5.30745732821205870000e+000) (7, 3.25905684586925370000e+001) (8, -3.14432126667553640000e-002) (0, 6.74060898187688770000e-001) (1, 3.18974936488884530000e-001) (2, -4.76962844574214360000e+000) (3, -3.19273239794239010000e+000) (4, 6.82830406321604230000e+000) (5, 8.08584108906026340000e+000) (6, 2.66251485200287030000e+000) (7, 6.03221910090477480000e+000) (8, -2.92373046201367280000e-001) (0, -1.66385244794727740000e-001) (1, 1.28483551451824490000e+001) (2, -7.67231808812631930000e+000) (3, -4.34610330068358050000e+000) (4, -4.77983198336650620000e+000) (5, 1.60610242343416950000e-001) (6, -7.20073339820101800000e-001) (7, 3.77237370978398580000e+000) (8, 1.10377012607196460000e+000) (0, 2.03668468710519250000e+000) (1, 8.63091703971635660000e+000) (2, -3.51060955960804180000e+000) (3, -9.93652003913062210000e+000) (4, -2.21378574495714100000e+000) (5, 1.18747595826982690000e+001) (6, 1.40505989542084410000e+001) (7, -1.73048104705940740000e+001) (8, -1.02934525021829300000e-001) (0, -1.12822538537313720000e+000) (1, 2.31857564460658820000e+000) (2, 8.87313295950810320000e-001) (3, -1.00514790292753410000e+000) (4, -9.94294379728346730000e+000) (5, -2.56890175409122230000e-001) (6, -5.73785623684144140000e+000) (7, 3.54098004801394820000e+000) (8, -2.26620252826203600000e-001) (0, 5.81000441525944210000e+000) (1, 2.93987626992943960000e+000) (2, 2.09225001651830970000e-001) (3, 9.52124178886394820000e+000) (4, -2.05630739990960580000e+001) (5, -1.13670508840051600000e+001) (6, 4.98584041466813410000e+000) (7, -1.51809898282058630000e+001) (8, -1.28444678116190980000e-001) (0, 1.91385148357421380000e+000) (1, 1.89752443576028720000e+000) (2, 3.80851936511325960000e+000) (3, 3.51627823251446790000e+000) (4, -1.83148107398998140000e+000) (5, -4.79348340923114780000e+000) (6, 5.11366823476398040000e+000) (7, 2.88183131958737950000e+001) (8, -4.50447728368757960000e-001) (0, 3.43199065854781980000e-002) (1, -1.76861394473414290000e+000) (2, 4.49196307238149560000e+000) (3, -2.28102879881745310000e+000) (4, 1.88520667481390510000e+000) (5, 1.47075939686329950000e+000) (6, 3.76084726862624930000e+000) (7, -1.16072999903139460000e+001) (8, 3.11576672007033050000e-003) (9, 1.01450502835390770000e+000) (10, -1.10023157496244560000e+000) (11, 4.54741571575529520000e-001) (12, -3.14935399649539920000e+000) (13, -5.99420272567098840000e-001) (14, 1.08868031931902290000e+000) (15, -3.64601209211521260000e+000) (16, -1.22131617433813930000e-001) (17, 4.09670099398924290000e-001) (18, -2.00381975494858010000e+000) (19, 2.16906168521345450000e-001) (9, -1.43241616394160730000e+000) (10, 5.98499937294544650000e-001) (11, -3.27770022687586430000e-001) (12, 2.90561651445067600000e+000) (13, 1.25391471798072910000e+000) (14, -1.14309913168221740000e+000) (15, 2.91327693753562180000e+000) (16, -7.33257288258126750000e-002) (17, -2.47479564442595060000e-001) (18, 2.82302289666714930000e+000) (19, 7.05921597856128180000e-001) (9, -3.83731419908143500000e+000) (10, 1.18341828165810230000e+000) (11, 8.55930249779658810000e-001) (12, 2.38992336337968900000e+000) (13, 9.78013243284939330000e-001) (14, -8.74628761961557030000e-001) (15, 2.88071020578241650000e+000) (16, 8.25609486257894540000e-001) (17, -1.22280602086453660000e+000) (18, 2.73784491958574930000e+000) (19, 5.92662361120040340000e-001) (9, 6.72123739726687260000e-001) (10, -9.96803106608835310000e-001) (11, 2.73796876981064530000e-001) (12, 6.22794750305762920000e-001) (13, 1.37012302568671070000e+000) (14, -1.14573522770394540000e+000) (15, -1.76730505651466440000e+000) (16, 6.11115985065873390000e-001) (17, 5.40183990269848870000e-001) (18, 2.55703727318417280000e+000) (19, 3.39801887125517620000e-001) (9, 5.06572826721078280000e-001) (10, 1.88245953897426690000e+000) (11, 2.00975381766171020000e+000) (12, 2.98448182219034170000e+000) (13, 1.07198067393781240000e+000) (14, -2.91158314510362940000e+000) (15, 6.61318150709307440000e-001) (16, 3.05528526184274040000e+000) (17, -1.83843072915296890000e+000) (18, 2.59709308469153830000e+000) (19, 9.30352392722046170000e-001) 
