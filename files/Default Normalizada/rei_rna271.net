FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.75734792559584660000e-001) (1, 1.06087815781216710000e+000) (2, 5.95770979632211590000e-001) (3, -1.29128553312760430000e+000) (4, -1.20532654361244630000e-001) (5, -1.04935129373822370000e+000) (6, 1.76857342922251080000e+000) (7, -3.34863561376664130000e+000) (8, -4.37615787748050070000e-002) (0, -8.94273209041620000000e-001) (1, 1.39894759522772570000e+000) (2, 4.19227978983851820000e+000) (3, -1.86336450120204100000e+000) (4, 7.72072411622193220000e+000) (5, 9.05451188921884940000e+000) (6, 2.34891744675520010000e+000) (7, -3.89374907196926980000e+000) (8, 4.69626271667119680000e-001) (0, -6.51954179480579850000e-002) (1, 1.67646999478876910000e+000) (2, 4.31310810034628010000e-001) (3, 5.82512808164514560000e-001) (4, -2.83778164638116740000e+000) (5, -9.22234301385785770000e-001) (6, 2.13066700731666940000e+000) (7, -9.19706121764643720000e-001) (8, -3.02869643275564200000e-001) (0, -4.70106867322611600000e+000) (1, -1.48034412530929150000e+001) (2, -1.90178266215061420000e+000) (3, 7.94466968183580580000e+000) (4, 1.35128533116599780000e+001) (5, -2.24060540427781660000e+001) (6, -7.09752290579864910000e+000) (7, 4.07620389641187440000e+001) (8, -6.30131492123078400000e-001) (0, 6.95864796937834470000e+000) (1, 4.12089847963860480000e+000) (2, 9.74747398469945380000e+000) (3, -1.21681531526714240000e+001) (4, 1.48919991376882770000e+000) (5, 8.10565917993291810000e-001) (6, 1.09786916401060950000e+000) (7, -3.20804651573957070000e+001) (8, 3.15713330573616000000e-001) (0, -3.04664449757918330000e+000) (1, -5.03081036303676310000e+000) (2, -8.14762001123861170000e+000) (3, -2.18566421297986850000e+000) (4, -7.63867123012598360000e+000) (5, 3.68514409139002550000e+000) (6, 1.43632203869151380000e+001) (7, -2.11509629163129670000e+001) (8, 6.34995504468408250000e-001) (0, 1.17278607428564490000e+000) (1, 8.93082866751255720000e+000) (2, -7.95210256397094640000e+000) (3, 1.76746405405405370000e+001) (4, -1.00180079848620430000e+001) (5, -8.98884720950501580000e+000) (6, 3.90160067461629280000e+000) (7, -1.82312882573383820000e-001) (8, -1.53762283103003660000e-001) (0, -5.21524499925830170000e-001) (1, 2.85381641644963050000e+000) (2, 1.20721106458995830000e+000) (3, 4.68778191679174230000e+000) (4, -5.65541311246297520000e+000) (5, -2.20251964640083870000e+000) (6, 9.87272827302638060000e+000) (7, -6.23246676611396920000e+000) (8, -2.32690062438113100000e-001) (0, 6.53838822595086190000e-001) (1, 1.02693947020959600000e+000) (2, -1.83111456682533920000e+000) (3, -1.23569895937929460000e+000) (4, 1.02323663479021820000e+000) (5, -3.77246865509139350000e+000) (6, -3.98170636348284420000e+000) (7, 2.17245360672991290000e+000) (8, -1.67753411742502380000e-001) (0, 3.04292775467343010000e+000) (1, -4.03375024463436920000e+000) (2, 1.26979760088803890000e+001) (3, -1.36183164032676820000e+001) (4, 1.76044403410758430000e+001) (5, -3.05722600129376070000e+000) (6, -4.44239016751482150000e+001) (7, 5.81597264764852750000e+001) (8, -6.07628863061068890000e-001) (9, -1.47468500979986090000e+000) (10, -2.87360261869597790000e-001) (11, -2.82616524663433390000e+000) (12, -2.44617242444159670000e-001) (13, -3.10972016198857670000e-001) (14, -3.87736822416205330000e-001) (15, -7.97980771415764730000e-001) (16, 2.49740507222038040000e+000) (17, 2.25626051242730650000e+000) (18, -1.19513973371377270000e-001) (19, 6.45468942611509890000e-001) (9, 3.17404097174094880000e+000) (10, 5.11498573138342350000e-001) (11, 2.68200884238293820000e+000) (12, 1.53584767040642490000e-002) (13, -1.34851927564845650000e-001) (14, 5.36882339593275360000e-001) (15, 7.22590061876648980000e-001) (16, -2.54604368223492990000e+000) (17, -2.15702280384072420000e+000) (18, 2.55676469870086130000e-001) (19, 7.18214138826775090000e-001) (9, -2.03987118926934400000e+000) (10, 1.81021948401034650000e+000) (11, 9.89636120009055760000e-001) (12, 2.76031321869611660000e-001) (13, 8.12177799397176600000e-001) (14, 2.15748590150204670000e+000) (15, 1.21514848166738210000e+000) (16, 5.79935759812206460000e-001) (17, -1.28293203056212140000e-001) (18, 1.09789198457494370000e+000) (19, 4.68942692996305420000e-001) (9, 6.91105520084849270000e+000) (10, -6.49516318866810270000e-001) (11, 7.67215883038811390000e-001) (12, 3.42346231452918650000e-001) (13, 5.99386809359313750000e-002) (14, 3.40379832688329220000e-001) (15, 1.25412669174556890000e+000) (16, -3.16738272367203020000e+000) (17, -5.11243680107763780000e+000) (18, 3.17753682761864660000e-001) (19, 8.80208774949557290000e-001) (9, 1.12998524237042490000e-001) (10, 1.26940954706083780000e+000) (11, 8.32446929134300540000e+000) (12, 1.46419739517983080000e+000) (13, 1.37850927568349960000e+000) (14, 5.81070003213976060000e-001) (15, 1.47271926567349110000e+000) (16, -5.57155356374464810000e+000) (17, -3.97027390675280410000e+000) (18, -2.53234024859692100000e-001) (19, 1.15664396843747810000e+000) 
