FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.08203673061730720000e-001) (1, 2.33286083298103820000e-001) (2, 4.27789483302942540000e-002) (3, -2.65601983719797110000e+000) (4, 2.03000415548300060000e+000) (5, 2.71967137276803220000e-001) (6, 1.33066479202046770000e+000) (7, -1.05677397892171050000e+000) (8, -3.95981666913384070000e-002) (0, -1.15679018788067920000e+001) (1, -4.53871948861521270000e+000) (2, -7.65416046788555260000e+000) (3, 2.82374730740596010000e+001) (4, 3.43971750592237340000e+001) (5, -1.30445560678691220000e+001) (6, -3.63598254286139810000e+001) (7, 1.23747667728013640000e+001) (8, 4.53762948628684940000e-001) (0, -1.55339017803620970000e-001) (1, 1.81393641571406370000e+001) (2, -2.62458885455470360000e+000) (3, 5.40467333075832710000e-002) (4, -2.31865331877193980000e+001) (5, -4.72071512511948570000e-001) (6, 2.15567692475476360000e+000) (7, 1.07905292973584750000e+001) (8, 3.42937629376777280000e+000) (0, 3.98388469003869260000e+000) (1, 2.29518647048913960000e+001) (2, -1.62940038000472780000e+001) (3, 7.61081016647051370000e+000) (4, -2.21921767648865750000e+001) (5, -2.37049214753363310000e+001) (6, 2.45143033333043770000e+000) (7, 5.17189665274411610000e+001) (8, 2.70336610465900720000e+000) (0, 2.80805835520192650000e+000) (1, 8.43139110557614120000e+000) (2, 2.50269992504469190000e-001) (3, -2.92238541531131300000e+001) (4, -7.81184375919438790000e+000) (5, 1.77660215726349370000e+001) (6, 1.71359343611997620000e+001) (7, -1.08344012732672720000e+001) (8, 4.75924803316261800000e-001) (0, -9.91928551672107970000e-002) (1, -9.29517799321324280000e-001) (2, 4.64123444086318400000e+000) (3, -4.83940045039807750000e-001) (4, 1.10426803852876150000e+000) (5, -9.38945653010516250000e-001) (6, 4.81593378886169980000e+000) (7, -1.07951587144762800000e+001) (8, -1.61893739323625360000e-001) (0, 7.64225326083583930000e+000) (1, 7.88098669805224720000e+000) (2, 1.38401020862833460000e+000) (3, 2.40738423331771470000e+001) (4, -1.51142574996670210000e+001) (5, -3.39186044660304730000e+001) (6, 1.78059033712905650000e+001) (7, 3.06554761212353670000e+001) (8, -5.91987599680504910000e-002) (0, -5.28773239504205850000e-001) (1, 7.18476904993698890000e+000) (2, -1.54459331874547030000e+001) (3, -1.68112669302113640000e+001) (4, 1.18723120123363390000e+001) (5, 1.67957121030538980000e+001) (6, 3.56310867984993170000e-001) (7, 1.86891401732173890000e+001) (8, -3.88385340465772100000e-004) (0, 4.94225962872739900000e+000) (1, 1.00950005307804760000e+001) (2, 1.08278780528714780000e+001) (3, 3.86379245334012320000e+001) (4, -2.64501613390222450000e+000) (5, -5.88617107927907810000e+001) (6, 2.07737384200034900000e+001) (7, 1.01122894328386060000e+001) (8, 2.03502773122940520000e-001) (0, -1.45429806316871970000e-001) (1, -6.59959911843401970000e-001) (2, 6.42322910028426340000e-001) (3, 1.82869230130300560000e+000) (4, 3.18302609557088400000e+000) (5, -3.75741198967351230000e+000) (6, 2.28803166803361390000e+000) (7, -2.89174433366203050000e+000) (8, -7.92053436314687910000e-002) (9, -4.49416916819665780000e-001) (10, 1.61492706043434600000e-001) (11, 1.53692260736315500000e+000) (12, -8.29007612060061350000e-001) (13, 5.09910518876164230000e-001) (14, -1.60143272593164700000e+000) (15, 6.09285173507140290000e-001) (16, -3.50459924422252100000e-001) (17, -6.13645377552054060000e-001) (18, 4.29004053571359290000e+000) (19, -1.77298140523684450000e-001) (9, 1.50221607655991600000e+000) (10, -9.60247923382188120000e-002) (11, -5.35974046990198020000e-001) (12, 7.62586182476581160000e-001) (13, -6.61503271911452970000e-001) (14, 1.76116846304528110000e+000) (15, -4.02898957681043830000e-001) (16, 3.90421850978476430000e-001) (17, 1.69315070566871780000e-001) (18, -3.17623186888508210000e+000) (19, 8.88546534197468540000e-001) (9, 3.43646253690218280000e-001) (10, -7.35902360916154240000e-001) (11, 6.62817590669648740000e-001) (12, 3.33425669610968980000e-001) (13, -1.42366420401365560000e+000) (14, 1.71958045726857890000e+000) (15, -1.17966595141813780000e+000) (16, 8.57196106297113070000e-001) (17, 7.00954519065480560000e-001) (18, -2.02911204601566380000e+000) (19, 5.32500513949683450000e-001) (9, 3.64710834515682780000e+000) (10, 1.62376895777432360000e-001) (11, -4.12691267779198790000e-001) (12, 8.20292496776036220000e-001) (13, -4.48083982158935360000e-001) (14, 1.22549766076658000000e+000) (15, 3.43510632592149810000e-001) (16, -1.77540906409245080000e-001) (17, -4.23169195450141030000e-001) (18, -1.70174390831259980000e+000) (19, 9.36441038543971650000e-001) (9, 4.88856778959748000000e+000) (10, -1.08323635776913110000e+000) (11, 6.68773099154812980000e-001) (12, 7.12877918920836960000e-001) (13, -2.60751922523725770000e+000) (14, 2.02941342666815890000e+000) (15, -1.59261206766597900000e+000) (16, 1.03260172417650970000e+000) (17, 9.40950549754586920000e-001) (18, -4.04513590136612940000e+000) (19, 6.25020130617704670000e-001) 
