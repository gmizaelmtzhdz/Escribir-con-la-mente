FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 7.39824921192496990000e-001) (1, -4.42869318937699760000e+000) (2, -2.35613824642799190000e+000) (3, 2.19673885681518190000e-001) (4, 5.84267118192893080000e+000) (5, 4.38428376811446710000e+000) (6, 6.72042952706828970000e+000) (7, -1.17435569843554100000e+001) (8, 4.30602016615738880000e-001) (0, -2.43132843067799740000e+000) (1, -1.02785411214251440000e+000) (2, 3.12461798540197840000e-001) (3, -8.53539974672887420000e+000) (4, 7.48802541504392670000e+000) (5, 2.01932205728561130000e+001) (6, -2.39078922913569560000e+000) (7, 5.54262779053610010000e+000) (8, 1.14590852740707480000e+000) (0, 9.55858853169104680000e-001) (1, 1.82903511415627950000e+001) (2, -8.61261405557429960000e+000) (3, -1.00875299752313750000e+000) (4, 4.69311242939261050000e+000) (5, -6.10597398462238150000e+000) (6, 9.47556313547531000000e-001) (7, -6.39819468927703580000e-001) (8, -3.34102809759932780000e-001) (0, 2.93073721092939440000e-001) (1, 8.69845599401842050000e+000) (2, 2.34634905555996860000e+000) (3, 6.15880177974808790000e-004) (4, -2.16729557732111360000e+001) (5, 3.41338344610412480000e+000) (6, -2.19352855591372940000e+000) (7, 1.78960441105222400000e+001) (8, 7.17336108531389380000e-002) (0, 4.57434898619446390000e-002) (1, -1.68690143388800320000e+001) (2, -2.72661897327119720000e+000) (3, 7.94531620148200620000e+000) (4, 2.45550766170257940000e+001) (5, -9.15080531106332630000e+000) (6, 1.17830166823512870000e+001) (7, -1.08899377497224600000e+001) (8, 8.35534843774565330000e-001) (0, 1.21883252946450660000e+001) (1, 5.36904537535387410000e+001) (2, -1.24304502683764880000e+001) (3, -1.33172957628278310000e+001) (4, 8.76809387871567840000e+000) (5, -1.11536105893034440000e+000) (6, 2.57821213449092900000e-002) (7, -1.01147519035884890000e+001) (8, -3.04483983531431780000e+000) (0, -1.80934515393700400000e+000) (1, 2.10669335589205930000e+000) (2, -3.38553111913536140000e+000) (3, -2.26718525441302310000e+000) (4, 1.28126936221307180000e+001) (5, -1.23835963911727240000e+000) (6, -1.08341879189111280000e-001) (7, -3.53820811901854530000e+000) (8, 3.43326723870191420000e-001) (0, 3.48386594085583140000e+001) (1, 7.38868905268728890000e+001) (2, 8.48281713596313660000e+000) (3, -1.70974779583208060000e+000) (4, -1.39966881487507270000e+002) (5, 5.18626636344346110000e+001) (6, 9.52748235168187740000e+000) (7, -9.48737950295908520000e+001) (8, -4.92873032608115480000e+000) (0, -2.17738646953268010000e+000) (1, -1.69766715030774410000e+001) (2, 7.80662529796673970000e+000) (3, -1.66183661717020410000e+000) (4, -7.77086476750977620000e+000) (5, 1.32526388464908250000e+001) (6, 1.04394121580137170000e+000) (7, -8.54469362268623730000e+000) (8, -9.74675196886789500000e-002) (0, 6.70780739322014760000e-001) (1, -1.81288964098339920000e+000) (2, -4.67895389972734110000e-001) (3, 2.46113675391225510000e+000) (4, -1.62921903347380350000e+000) (5, -1.81951675651301080000e+000) (6, 2.70263572999897270000e+000) (7, -3.00438607363260330000e-001) (8, 2.63239041322258780000e-001) (9, -2.34534154426056210000e-001) (10, -8.00218203545188800000e-001) (11, 6.20220831357974620000e-002) (12, 1.04054243056779930000e+000) (13, 7.87296107873407980000e-001) (14, 4.08355088966978640000e-001) (15, 1.17199223644567190000e+000) (16, -5.88322589171609150000e-002) (17, 1.04233309110198640000e+000) (18, -5.69525646282507240000e-001) (19, 9.46741665110835020000e-001) (9, 6.83935170203055050000e-001) (10, 5.48139209299670190000e-001) (11, 3.18644884677069420000e-001) (12, -3.60024740619888760000e-001) (13, -2.91335348837238610000e-001) (14, -4.25269457057759040000e-001) (15, -1.23724974187380400000e+000) (16, -5.49495120680938440000e-003) (17, -7.02814160264273460000e-001) (18, -1.60922593974711960000e+000) (19, 5.57966553403081990000e-001) (9, -2.88021332605123130000e+000) (10, 1.75605918337750060000e+000) (11, 2.80253614540795580000e+000) (12, -1.80736779253948980000e+000) (13, 2.79835351923562180000e-001) (14, -6.62418559777320920000e-002) (15, -1.94640354420004600000e+000) (16, 6.36286967276973870000e-002) (17, 2.11350083861897400000e+000) (18, 3.76727279096809830000e+000) (19, 1.04301199903223770000e+000) (9, 1.12899760054059840000e+000) (10, -4.11808039256907510000e-001) (11, 3.78850447727821120000e-001) (12, 6.17771657028379990000e-001) (13, 1.14042363031716910000e+000) (14, -4.11478390690986300000e-001) (15, -1.85490193088165570000e+000) (16, 7.62305866521433700000e-002) (17, -8.22577351548180120000e-001) (18, -6.05296781533141020000e+000) (19, 1.24625044726587970000e+000) (9, -1.74223570312130290000e+000) (10, 1.72690858791602620000e+000) (11, 1.61144523526510190000e+000) (12, -1.46778295856500620000e+000) (13, 7.74429701477610260000e-001) (14, -8.50214574603543110000e-001) (15, -2.35949285918758860000e+000) (16, 5.28793836351418970000e-001) (17, -4.07699638070588010000e-001) (18, -7.40686834593837990000e-001) (19, 7.00076295009737000000e-001) 
