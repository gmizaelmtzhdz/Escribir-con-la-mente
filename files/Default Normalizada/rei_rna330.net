FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -5.52594563043030900000e-001) (1, -1.66600455584622130000e+000) (2, -3.62328016151385280000e+000) (3, 1.78546087819231620000e+000) (4, 1.39589249827545460000e+000) (5, 4.37851180543256380000e+000) (6, 4.55770476550893020000e+000) (7, 4.75450090452667510000e+000) (8, -9.03826280394059570000e-002) (0, 2.65291289415546190000e-001) (1, -1.20486134003579480000e+000) (2, -8.15801296385322060000e-001) (3, 3.69988804716040500000e+000) (4, -2.02957965212846900000e+000) (5, -1.50285579302166150000e+000) (6, -8.58385967829080610000e-001) (7, 4.68134483065958570000e+000) (8, -1.62979303996047180000e-001) (0, 2.02146834213124100000e-001) (1, -1.00551109528380240000e-001) (2, 4.60335883607693400000e+000) (3, -2.83880056557170590000e+000) (4, 7.04288782929814340000e-001) (5, 1.79581732064950720000e+000) (6, 2.32724577661242020000e+000) (7, -1.09630369734179990000e+001) (8, -1.03770896695401630000e-001) (0, -4.38684076889434170000e-001) (1, 6.96013027892070020000e+000) (2, -6.47329111163869260000e+000) (3, 1.15784768005453050000e+001) (4, -7.96596198763034820000e+000) (5, -1.26771755807594070000e+001) (6, 2.53843669829326490000e+000) (7, 6.52773222759234350000e+000) (8, 1.09751828747823920000e+000) (0, -2.83403975824082540000e+000) (1, 6.50505071105771380000e+000) (2, 1.10946752515876080000e+001) (3, 2.59995948613336940000e+001) (4, -5.34897354731912460000e+001) (5, 2.03926959269838480000e+001) (6, 2.84539265832321320000e+001) (7, -2.11155309076902210000e+001) (8, 8.14713234774352650000e-001) (0, 1.49319237221192420000e+000) (1, -1.61480767811882050000e+001) (2, -1.20603222921674930000e+001) (3, -1.72634564727844410000e+001) (4, 6.69466708296112930000e+001) (5, -3.11241252129119130000e+001) (6, -2.54316097762227540000e+000) (7, -2.42773443298005670000e+001) (8, -1.10348636642170160000e+000) (0, -4.22367745925988820000e+000) (1, 3.83541878471302630000e+000) (2, -1.22601971350729380000e+001) (3, -1.50830351961219870000e+001) (4, 1.08120263391808220000e+001) (5, 2.12645090000961080000e+001) (6, -7.59710346438419660000e+000) (7, 2.19712693711642830000e+001) (8, 1.51912457144750630000e+000) (0, 8.78110914898722620000e-001) (1, 1.78336474901231260000e+000) (2, 1.42950487944225310000e+000) (3, -7.05422034528335560000e+000) (4, 1.27691655431483400000e+000) (5, 1.05026958190708570000e+000) (6, -9.98922432400304490000e+000) (7, 5.16963187703539620000e+000) (8, -1.23634962676402370000e-001) (0, -1.06193095949674650000e+001) (1, -6.30537091909642820000e+000) (2, 1.12089167957008090000e+001) (3, -1.14912748798586290000e+001) (4, -3.45868077324601590000e+001) (5, 4.27902904885031180000e+001) (6, -3.06129166301513460000e+001) (7, 9.34166968012449850000e+000) (8, -7.63750882912506260000e-001) (0, 3.50458832468534130000e+000) (1, 6.17358677351120380000e+000) (2, 6.06203500601632150000e+000) (3, -4.75522057730504870000e+000) (4, -4.23873869276295780000e+000) (5, 6.20725023192106560000e+000) (6, 2.32900844300508250000e+001) (7, -2.54260395204346250000e+001) (8, -7.17761883362817540000e-001) (9, -2.73099970938829580000e+000) (10, -2.05239500647608080000e+000) (11, -3.02845749241400690000e+000) (12, -1.00885311398208290000e+000) (13, -6.98558744615278670000e-001) (14, -6.00869563919588790000e-001) (15, -1.14368742741569540000e-002) (16, -2.96595493472168890000e+000) (17, 2.10960197971772540000e-001) (18, 3.21242840130122830000e-001) (19, 6.72013669248259450000e-001) (9, 2.73502905761615800000e+000) (10, -3.02868159896878870000e-001) (11, 1.51087106454083720000e+000) (12, 7.26792245653470780000e-001) (13, 6.83081537434292120000e-001) (14, 5.42860760352272040000e-001) (15, -2.49323246041423860000e-001) (16, 2.58916571698353120000e+000) (17, 1.95539255124889470000e-002) (18, -3.50109304594370510000e-001) (19, 8.56680040443634990000e-001) (9, 3.04441777125474270000e-001) (10, 5.54343902373776040000e+000) (11, 4.43240227896466440000e+000) (12, 1.49559002005626280000e+000) (13, -1.99957977748493360000e-001) (14, 2.40812535401391800000e-001) (15, 1.03165912072622110000e+000) (16, 3.22147521753967710000e-001) (17, 5.24241486789620680000e-001) (18, 3.75413005367402570000e-001) (19, 8.46289689184008260000e-001) (9, 5.05460087212867750000e+000) (10, -3.80180886734546510000e+000) (11, 1.71049787783659870000e+000) (12, 8.26157795998618160000e-001) (13, 4.38695772358266290000e-001) (14, 7.37477749670724940000e-002) (15, -1.53961815535676630000e+000) (16, 3.12287159697365310000e+000) (17, -3.90272746036804840000e-001) (18, -1.09892270816199740000e+000) (19, 1.06728940670216650000e+000) (9, 2.77931938761546830000e+000) (10, 4.17712025948951830000e+000) (11, 4.50910275496227000000e+000) (12, 1.24330585790508460000e+000) (13, 5.80876518310681430000e-001) (14, 7.19603023832587900000e-001) (15, 3.21533019153615600000e-001) (16, 2.83603246817144550000e+000) (17, -2.90198666616882210000e-001) (18, -4.42831418882056680000e-001) (19, 9.46450601741596010000e-001) 
