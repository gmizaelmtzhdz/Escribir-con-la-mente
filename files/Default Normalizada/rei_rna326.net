FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.03368257218750510000e+000) (1, -9.86252199847256090000e-001) (2, 3.53502577230567770000e+000) (3, 9.94119046096743550000e+000) (4, -2.00502418382875370000e+001) (5, -1.13636798775004680000e+001) (6, -4.41511304718522460000e-001) (7, 4.20698413948273230000e-001) (8, -1.57228743085129690000e-001) (0, 7.35044834537609320000e+000) (1, -1.39029934430952080000e+000) (2, 6.20953421298871880000e+000) (3, -6.78202099914732860000e+000) (4, 1.84608383042459640000e+001) (5, -2.18917849236021600000e+001) (6, 4.97299441775351530000e+000) (7, -1.83992490296743580000e+001) (8, -1.15387088394528670000e+000) (0, 6.45981814060977210000e-001) (1, 1.45794628951084100000e+000) (2, 1.01692879800757980000e+000) (3, -5.78770437481464840000e+000) (4, 4.30340983712364360000e+000) (5, 1.28708830212145190000e+000) (6, 1.03843387845905540000e+000) (7, -5.48719706652515080000e+000) (8, -1.19977106638322940000e-001) (0, 2.81683683367925100000e-001) (1, 3.46671956776412670000e+000) (2, 2.94529469279482290000e+000) (3, 2.56621136630336140000e-001) (4, -1.74192617352436800000e+001) (5, 7.61580964399522650000e+000) (6, -4.59175301236520110000e+000) (7, 2.35425821256148890000e+001) (8, 1.05708403300301450000e+000) (0, 2.81823017046717440000e+000) (1, 2.39578046734626190000e+000) (2, 2.45306003444199080000e+000) (3, -8.55969590924716960000e+000) (4, -1.79009070225199960000e+000) (5, 6.05924797741546280000e-001) (6, 2.38458348773237410000e-001) (7, -1.12900795059685510000e+000) (8, -1.46863514587888790000e-002) (0, -1.09285738606845360000e+000) (1, -1.15293813961865100000e-001) (2, -1.16708485968090090000e+000) (3, 5.03559817774886450000e-001) (4, -8.18026100864241990000e-001) (5, 7.32936495780330380000e-001) (6, -1.29851020853716630000e+000) (7, 3.62848387773102350000e+000) (8, -1.66477295032149610000e-001) (0, 9.54921153232754170000e-001) (1, -4.46943694163753240000e+000) (2, -9.92504302722781010000e-001) (3, 8.42094611292219630000e-001) (4, 1.07396883543555220000e+001) (5, 6.47459814432910900000e-001) (6, 1.89665148312038820000e+000) (7, 8.73694811876130830000e+000) (8, 1.66180428898453720000e-001) (0, -1.55881226338892390000e+000) (1, -1.15850068447041520000e+001) (2, -3.65718949425545900000e+000) (3, 4.04756966737166270000e+001) (4, 1.18965314234516880000e+000) (5, -2.64214660720519920000e+001) (6, -1.58187599244338490000e+001) (7, 1.14775051115517640000e+001) (8, -1.91686023792163930000e-001) (0, -1.62930262975126430000e+000) (1, 2.49538863740312820000e+000) (2, -5.71234948343367740000e-001) (3, -1.42616212152123760000e+001) (4, 1.44323473891591250000e+001) (5, 1.57735192158655820000e+001) (6, 2.93418078886835330000e+000) (7, -5.49087579023512800000e-001) (8, 2.97209737298161970000e-001) (0, 4.39713713344685870000e+000) (1, -1.01361185742552050000e+001) (2, 5.00308990859415110000e+000) (3, 3.22328130964009670000e+001) (4, -1.41608276117687130000e+001) (5, -1.56049943419050640000e+001) (6, -1.32092374200440630000e+001) (7, 4.24322606422636280000e+001) (8, -3.28535356078701880000e-001) (9, -1.36972123694340440000e+000) (10, 4.93336764250828670000e-001) (11, -4.11308939869430730000e-001) (12, 9.63102158513798100000e-001) (13, -1.07836923069847220000e+000) (14, -1.46376417596104600000e+000) (15, -9.56579555724535600000e-002) (16, -4.68585107425938840000e-001) (17, -1.51965527372633820000e+000) (18, 6.42818383665939070000e-003) (19, 2.90899360554828180000e-001) (9, 4.91957589029239750000e-001) (10, -7.18035248037124930000e-001) (11, 4.08659247009204090000e-001) (12, -6.25613044775353510000e-001) (13, 1.42900086793120230000e+000) (14, 2.64008308922106920000e-001) (15, 1.22540581095627030000e-001) (16, 4.77153221751730530000e-001) (17, 7.85044078571857980000e-001) (18, -7.13518148774453240000e-002) (19, 7.93327511900083770000e-001) (9, 1.72322910880982790000e+000) (10, -1.80228677366288530000e-001) (11, -6.43590432549536850000e-001) (12, -1.10822669309757510000e-001) (13, 4.46909864214644010000e-001) (14, 4.38809012277853350000e-001) (15, 3.42339653268241350000e-002) (16, 7.98541603019845000000e-001) (17, 2.22338365870544760000e+000) (18, -5.69560752809418310000e-001) (19, 7.77661851508697930000e-001) (9, 2.45401230498407230000e+000) (10, -5.88869313046983870000e-001) (11, 8.63963409436331280000e+000) (12, 1.16242501419864790000e+000) (13, -1.90539759353213230000e+000) (14, 4.67257844908961940000e+000) (15, 2.42360549963719980000e+000) (16, 6.17994982506018590000e-001) (17, 6.17854565398969560000e-002) (18, -5.05779257215029140000e-001) (19, 9.57196842531548130000e-001) (9, 2.28047785901153020000e+000) (10, 1.64135339227391790000e-001) (11, 2.89919759956371250000e+000) (12, 1.06601888350218090000e+000) (13, 4.04115780604260680000e-001) (14, 4.70307226292590560000e+000) (15, 1.65974776183790040000e+000) (16, 1.45500757821283380000e+000) (17, 1.81320643586150500000e+000) (18, -1.09839145536379030000e+000) (19, 9.60455487344409440000e-001) 
