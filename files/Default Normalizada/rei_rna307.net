FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -8.18199494367269020000e-001) (1, -4.96645992586319810000e+000) (2, 3.04679769692055210000e+000) (3, -8.70688498400186720000e+000) (4, -8.46651205217213490000e-001) (5, 8.54610525620404180000e+000) (6, -2.13447611583684840000e+000) (7, -1.71978753554578430000e+000) (8, 3.32328877265216540000e-001) (0, -4.36269147912790520000e+000) (1, 2.05199199498759070000e+000) (2, -2.20507381013166360000e+000) (3, -1.09196959529318660000e+001) (4, 1.81226391757520670000e+001) (5, 6.26549054429664130000e+000) (6, 4.36415846222197870000e+000) (7, -5.22598753900363720000e+000) (8, 5.95968281596464090000e-001) (0, 6.25480654649184790000e-001) (1, -5.03077729050405260000e-001) (2, -2.18865916796149260000e+000) (3, 6.24889504078182600000e+000) (4, -6.81215262092934460000e+000) (5, -4.17646566784774810000e+000) (6, -8.99907140347893930000e-002) (7, 6.03882540305828910000e+000) (8, 2.02377646065513700000e-001) (0, -1.30354834499875220000e+000) (1, -1.81646466131671480000e+000) (2, 1.66077736737871270000e-001) (3, -7.64309952851248480000e+000) (4, 1.26229400625217300000e+001) (5, 1.18850273679280370000e+001) (6, 1.46732760715382500000e+000) (7, 5.17575159298711630000e+000) (8, 4.95469439208522490000e-001) (0, -3.50944423765989780000e-002) (1, 1.30468964417248450000e+001) (2, -5.96024548690650930000e+000) (3, 6.43052353302243310000e-001) (4, 2.17391248535981370000e+000) (5, -9.25586540129738640000e+000) (6, -9.57294672729612110000e-001) (7, 1.46991643170815270000e+001) (8, 9.73047084224554880000e-001) (0, -5.16566791130580680000e+000) (1, 3.06962684279128270000e+001) (2, 4.23441970823259480000e+001) (3, 2.57963951663157650000e+001) (4, 2.33874689417894500000e+001) (5, -6.33458523990065320000e+001) (6, -9.31715811835494210000e+001) (7, -2.11625077901935900000e+001) (8, -6.01987568614572250000e-001) (0, -5.83464506196935420000e+000) (1, 1.63727371642094220000e+001) (2, -1.01696809300566660000e+001) (3, -2.55770064353743360000e+001) (4, 8.43445858469998020000e+000) (5, -8.84102894547405960000e+000) (6, 1.69625986921472180000e+001) (7, -3.71154665620989090000e+001) (8, 1.77529240343091920000e+000) (0, -3.91777225399744290000e+000) (1, -4.33945627707191940000e+000) (2, -4.49517602619493940000e+000) (3, -1.36585189748583740000e+001) (4, -3.22715904408848560000e+000) (5, 8.97707837323491020000e+000) (6, 7.99494611359542870000e+000) (7, -1.08040920661009600000e+001) (8, 1.21981672557757760000e+000) (0, -7.96891169039329660000e-001) (1, 2.95110195846886150000e+001) (2, 2.96039543110292240000e+000) (3, -6.83658825678098620000e+001) (4, -1.13470856004388520000e+001) (5, 5.34773528424399910000e+001) (6, 3.05956812109458910000e+001) (7, 6.63135086158079630000e+000) (8, 7.42304422248316160000e-001) (0, -1.33442191366787540000e+000) (1, 8.98800574163240460000e+000) (2, -5.41993114888258520000e-001) (3, -3.59686962647593160000e+001) (4, 8.06702654593431490000e+000) (5, 4.10260561949817560000e+001) (6, 1.78430737700776090000e+001) (7, -4.15681304796710730000e+000) (8, 4.58053351071610600000e-001) (9, -2.54422464012768410000e-001) (10, 1.05504788696653650000e+000) (11, 1.02045675318266120000e+000) (12, -1.64888414141508730000e-001) (13, -1.16109674872266400000e+000) (14, -7.26662423435023990000e-002) (15, 8.60270442229728040000e-002) (16, -6.28198860293022300000e-001) (17, 6.04892034191455320000e-001) (18, -8.10266946119111990000e-001) (19, 1.02403408441386670000e+000) (9, -1.14500196785630730000e-001) (10, -6.97494325959860270000e-001) (11, -1.19569053452173720000e+000) (12, -1.91666533936647980000e-001) (13, 1.23599514597065490000e+000) (14, 1.37011461905003320000e-001) (15, -4.09108978090523710000e-001) (16, 1.10677040095720720000e+000) (17, -5.23265517919261240000e-001) (18, 8.54945386498031530000e-001) (19, 3.57809828838014600000e-001) (9, -1.88564133026275460000e+000) (10, -1.74114246265629990000e+000) (11, -7.47233233660310470000e-001) (12, 1.77135040811905230000e+000) (13, 4.46233761306113680000e-002) (14, 3.23414085702440510000e-001) (15, -1.15183538742054570000e-001) (16, 1.77173476098843110000e+000) (17, -2.19690107383118170000e-001) (18, 4.03037671773526730000e-001) (19, 5.92841708827829490000e-001) (9, -2.58213397059645720000e+000) (10, -2.27213676303834640000e+000) (11, -4.48571178760430640000e+000) (12, 1.89265514822070700000e+000) (13, 1.22565603973173690000e+000) (14, 1.06036274605501970000e-001) (15, -6.92473382215597950000e-001) (16, 2.61735117244956730000e+000) (17, 3.44926886372634020000e-001) (18, -1.08759461885258180000e+000) (19, 7.09360518644461920000e-001) (9, 1.28699278929863930000e+000) (10, -1.08066933715968760000e+000) (11, 5.18360823704101750000e-001) (12, 2.16999976834302140000e+000) (13, 4.39820718236350440000e-001) (14, -8.24565993389357880000e-002) (15, 9.43802873186523780000e-001) (16, -8.50865039399597790000e-001) (17, -3.01857112135428710000e-001) (18, -3.50382358562707390000e-001) (19, 4.13969657081071470000e-001) 
