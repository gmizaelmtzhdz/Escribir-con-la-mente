FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.96474874188656210000e+000) (1, 1.62792534936739700000e+001) (2, -9.37531128536759080000e+000) (3, 6.06015667328304900000e+000) (4, 5.94383837525271730000e+000) (5, -3.15045127595033540000e+000) (6, 1.56438285428470200000e+000) (7, 2.52090718316862980000e+001) (8, -9.28728867118509440000e-001) (0, 6.54015439566627510000e+000) (1, 1.34723032438314070000e+001) (2, 1.98902538505701990000e+000) (3, -3.73822546418248610000e+000) (4, 1.55001265830808330000e+000) (5, -1.18139894773732990000e+001) (6, 1.75772464401225010000e+001) (7, -1.17896720440039560000e+001) (8, -1.10893876232796920000e+000) (0, 5.56360748363591910000e+000) (1, 3.69108420817561280000e+000) (2, 3.45242119255515640000e+000) (3, 9.25312085490760520000e+000) (4, -2.92324392015564920000e+001) (5, 3.68699112740010240000e+000) (6, -2.09893062834830910000e+000) (7, -1.63886660255837530000e+001) (8, -5.08089615008369240000e-001) (0, -9.08201587297509800000e-002) (1, -1.22906589533673460000e+001) (2, 3.44502593808029810000e+000) (3, -7.53276511375398440000e+000) (4, 3.40906236099271350000e+001) (5, -3.01604683630447350000e+001) (6, 3.41687650033282920000e+000) (7, 2.37643095648808260000e+001) (8, 5.39676965935365070000e-001) (0, -2.91636643173583150000e+000) (1, -6.24765118536920850000e-001) (2, 2.71495780172600840000e-001) (3, -6.82544140746435080000e+000) (4, 1.30956450158129840000e+001) (5, 1.24845089925271180000e+001) (6, 1.26278664712568680000e+000) (7, 3.50260021416511340000e+000) (8, 4.29577879215549740000e-001) (0, 6.75866658633366700000e-001) (1, -4.06870826337980060000e+000) (2, 2.72361807680573250000e+000) (3, -3.39035107532143610000e+000) (4, -1.12623644460724260000e+000) (5, 2.33036905482998130000e-001) (6, -3.31889110959915760000e+000) (7, 1.05034777265465930000e+000) (8, -2.01229494869360540000e-001) (0, -2.32006843162959650000e+000) (1, 1.09414428493898350000e+001) (2, -4.05147287963321650000e+000) (3, 1.30359398641673640000e+001) (4, -9.61016718291371030000e-001) (5, -3.93295220625175590000e+000) (6, 3.94901575077437880000e+000) (7, -3.76689000730506420000e+000) (8, 3.98554768778052400000e-001) (0, 3.41699457501055020000e+000) (1, 9.65608900154236420000e+000) (2, -5.05570008803939250000e+000) (3, 2.50112012340099010000e+000) (4, 7.57099781291087660000e+000) (5, -1.28568403123189440000e+001) (6, 6.43933498613272270000e+000) (7, 8.76978324054610070000e+000) (8, -1.84927437058988180000e-002) (0, -2.56240673223446100000e-002) (1, 4.42807163727546800000e-001) (2, -1.30221190134890640000e+000) (3, 3.29399868702692620000e+000) (4, -8.63385645653763860000e-001) (5, -1.60709212741237060000e+000) (6, -5.61895499962586250000e-001) (7, 2.26929858133738630000e+000) (8, 2.03262392548040540000e-001) (0, -2.33323711665750010000e+000) (1, -1.30788882047753960000e+001) (2, 1.36424180166459180000e+001) (3, -3.47410443439004890000e+000) (4, -5.63846059503459070000e+000) (5, -3.54507825061616670000e+000) (6, 1.03152674963415360000e+000) (7, -2.61869048843034200000e+001) (8, 8.73250481137256120000e-001) (9, 1.28558572181182320000e+000) (10, 8.85956698646528930000e-001) (11, -9.76702787442406680000e-001) (12, 1.68313935928799740000e-002) (13, -1.23722269554146160000e+000) (14, -1.63864285568582770000e+000) (15, -5.29375128993705200000e-001) (16, -2.72923845424318400000e+000) (17, 1.19814936776829420000e+000) (18, 4.64969286013204860000e-001) (19, 1.20535525198332060000e+000) (9, -1.11144962787333080000e+000) (10, -2.84606228310135050000e-001) (11, 3.23415298919321750000e-001) (12, -8.82103688954294360000e-002) (13, 6.30943417669901360000e-001) (14, 1.91477503468617450000e+000) (15, 7.23194753147893170000e-001) (16, 1.08830877313445430000e+000) (17, -1.22547922365642960000e+000) (18, -8.98412348140007260000e-001) (19, 7.28409819069590570000e-001) (9, -2.18945166096075240000e+000) (10, 7.79775660685734780000e-001) (11, 7.03115815948659240000e-001) (12, 4.19662546389158730000e-001) (13, 1.07679981019112580000e+000) (14, 2.88797334844051120000e+000) (15, 1.45119882024321780000e+000) (16, -4.53415638899246850000e-001) (17, 1.83564835980562700000e+000) (18, -1.96915966157589220000e+000) (19, 9.48719659475740330000e-001) (9, -2.39722554302538750000e-001) (10, -1.00777662595478620000e+000) (11, 1.64577818939809690000e+000) (12, 1.10554605014999940000e+000) (13, 2.65243874781567080000e-001) (14, -2.27765719633443540000e+000) (15, 3.32407929147379540000e-001) (16, 1.90654827888821040000e-001) (17, -5.19484742329512450000e+000) (18, -6.37296541748856530000e-001) (19, 9.44062657070257380000e-001) (9, -2.45574509902248120000e+000) (10, -8.31199472699999280000e-001) (11, 1.53994121978402850000e+000) (12, 3.40144325307378650000e-001) (13, 2.11698122662290220000e+000) (14, 2.81619755964067100000e+000) (15, 1.04591761792720580000e+000) (16, 3.46296498975931310000e+000) (17, 1.76181166055087910000e-001) (18, -1.15823139561589670000e+000) (19, 2.18268134894932830000e-002) 
