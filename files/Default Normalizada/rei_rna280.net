FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.90874592810574570000e-001) (1, 4.62758629558117910000e+000) (2, -7.36325005489961600000e-001) (3, 1.46635381067492380000e-001) (4, -8.73274705730018220000e+000) (5, -9.18536976563651300000e-001) (6, 1.17169509303910500000e+001) (7, -7.75819083764833550000e+000) (8, 1.10514825774576660000e-001) (0, 5.87713164654697180000e+000) (1, -7.99465080412064030000e+000) (2, 1.57345531056976660000e+001) (3, 1.98156869000080250000e+001) (4, -2.07869336511382200000e+001) (5, -2.55514981432625130000e+001) (6, 5.45181675807848360000e-002) (7, -6.71802954061364320000e+000) (8, -1.45354392634011110000e+000) (0, -4.48173218841409760000e-001) (1, 4.90494755545896940000e+000) (2, -9.91857551218575750000e+000) (3, 8.88032807052026740000e+000) (4, -9.80931937638278570000e-001) (5, -3.48690239151523470000e-001) (6, 4.91881170812336240000e+000) (7, 2.04882249442396440000e+001) (8, 2.47098675730608760000e-001) (0, -1.01556594979488970000e+000) (1, 3.97036563810078080000e+000) (2, -4.40014437248459840000e-001) (3, -2.92769899252719680000e+000) (4, -8.54990532896404080000e+000) (5, 3.66980725243389160000e+000) (6, 4.24343635072294130000e+000) (7, -2.34812143139830850000e+000) (8, -7.91521501471410120000e-002) (0, 1.44963831791813000000e+000) (1, 8.99718462283243810000e-001) (2, -1.61476712998449170000e+000) (3, 5.90446635332225340000e+000) (4, -7.95426623316960500000e+000) (5, -4.13860628276100330000e+000) (6, 1.25552914531057860000e+000) (7, 4.90831031423966560000e+000) (8, -8.67196725394462490000e-002) (0, -4.91576344573903960000e+000) (1, 8.30600821763001740000e+000) (2, 9.03307869352462770000e+000) (3, -2.87117702856484840000e+001) (4, 3.50469739038960240000e+001) (5, -2.05379678517452010000e+001) (6, -7.92272251826268250000e+001) (7, -4.03919112888963600000e+001) (8, -1.68121501033034760000e+000) (0, -2.76528470934612170000e+000) (1, 3.10431065768796440000e+000) (2, -3.72469800879610350000e+000) (3, 4.11587325086682570000e+000) (4, -1.91836551563579700000e+000) (5, 7.79908269448059870000e+000) (6, 1.87121649174075940000e+000) (7, 1.58857594185233780000e+001) (8, 6.99074591592313780000e-001) (0, -7.04652087778858790000e-001) (1, -2.74325941096457360000e+000) (2, 7.47560061836438820000e+000) (3, -7.80676012722788840000e+000) (4, 1.36042772960172090000e+001) (5, -6.45735746740068310000e-002) (6, 7.57446156538598810000e+000) (7, -2.62736567001280750000e+001) (8, 1.82420665842877110000e-001) (0, -3.17775281154940800000e+000) (1, 1.36774793587170420000e+000) (2, 3.45183813444358470000e+000) (3, -7.33062000436853900000e+000) (4, -1.28870283872427650000e+001) (5, 1.64762299553152760000e+001) (6, -1.38709506662243560000e+001) (7, 7.17584214666033390000e+000) (8, -2.56642303613737520000e-001) (0, 1.93457768169590280000e+000) (1, 6.86886838941989720000e+000) (2, -1.17045491247219870000e+001) (3, -5.67501703520154720000e-001) (4, -1.68521096279649430000e+001) (5, -9.47854131673071750000e-001) (6, 1.05989834402587420000e+001) (7, 2.97318509763947780000e+000) (8, 1.21969502559519860000e+000) (9, 2.69243028665021460000e+000) (10, -1.37762934420974980000e-001) (11, -8.27160167394259900000e-001) (12, -3.41889568218645130000e+000) (13, -1.09973341472102760000e+000) (14, -1.25299642060037770000e-001) (15, 3.66986602294396340000e-001) (16, -8.21932743832960330000e-001) (17, 3.74997692276340670000e-001) (18, 9.34852346977742280000e-002) (19, 1.50474335044452180000e-001) (9, -1.73703795244322930000e+000) (10, 1.07157820291681830000e-001) (11, 1.14506033767311740000e+000) (12, 1.60604546451237030000e+000) (13, 1.03371079048808070000e+000) (14, 2.87852311321162730000e-001) (15, -2.09800119645455360000e-001) (16, 1.19192608558058200000e+000) (17, 5.04911374708303500000e-001) (18, 2.32764032322750340000e-001) (19, 1.08240532301625650000e+000) (9, -1.24778957709866780000e+000) (10, -3.11748753376790920000e-001) (11, 1.27489723687560120000e-001) (12, 4.53570349277842570000e-001) (13, 3.40778876137230610000e+000) (14, 5.04074069241435390000e-001) (15, 8.66195562897430160000e-001) (16, 1.72075833579625460000e+000) (17, 5.00526280445034000000e-001) (18, 2.63431604789813980000e-001) (19, 8.93588696596516070000e-001) (9, -2.91376407645488070000e+000) (10, 1.21249368172851210000e+000) (11, 9.85369012413947920000e-001) (12, 2.28009958725544060000e+000) (13, -5.67511825863670660000e-001) (14, 6.05568617583623350000e-001) (15, 1.05393759666345080000e+000) (16, 1.39304886967500980000e+000) (17, -1.40550777239778800000e-001) (18, 1.31581850598078650000e+000) (19, 1.08883955403996250000e+000) (9, -7.06207530117086080000e+000) (10, 2.24115293840922400000e-002) (11, -3.59355372017313880000e-001) (12, 6.21435164041776120000e+000) (13, 5.33391744727706120000e+000) (14, 7.52125563953753070000e-001) (15, 2.46676137743253500000e+000) (16, 3.02111876934004500000e+000) (17, -1.49005604133186260000e+000) (18, 1.00991616674085800000e+000) (19, 6.80913000540187660000e-001) 
