FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -8.34332666587018630000e-002) (1, 2.96122894768537870000e-001) (2, 7.45127321949258650000e-002) (3, -5.96629211617291430000e-001) (4, -2.30648758720669140000e+000) (5, 2.55538767786218820000e+000) (6, -2.85971707480365730000e+000) (7, 5.40910176175132840000e+000) (8, -4.71706610540596590000e-003) (0, -9.21467587454553790000e+000) (1, -2.83275806583118590000e+000) (2, -5.78307751604098820000e+000) (3, -9.78625174795229920000e+000) (4, 3.10961393009364930000e+001) (5, 8.89654245692732810000e+000) (6, 2.27881675013389500000e+000) (7, 1.13118836247934970000e+001) (8, 1.19897237538260560000e+000) (0, -1.07099121248046170000e+001) (1, -1.34591762765789100000e+001) (2, 1.10623348971456640000e+001) (3, -4.10675040013462040000e+000) (4, -1.89315458518614930000e+001) (5, 3.89636462693239950000e+001) (6, -3.93546302460278810000e+001) (7, 4.59803159893836270000e+000) (8, 1.51414581341066160000e+000) (0, 2.43724578179272870000e-001) (1, -2.06579652076831020000e-001) (2, 1.80644611571460330000e-001) (3, -3.56970957389011190000e-001) (4, -1.25727853840426460000e+000) (5, 9.86492241126598830000e-001) (6, -5.30750685316908610000e-001) (7, -2.42046717987422310000e-001) (8, -1.96367234140536750000e-001) (0, 7.05233260899984420000e+000) (1, 2.58719179541850900000e+001) (2, -6.23335740078170360000e+000) (3, -9.10645117106879450000e+000) (4, 2.88873855511078630000e+000) (5, -7.28067827467031580000e+000) (6, 1.72435268799104300000e+001) (7, -1.38322429217797000000e+001) (8, -1.41633367196635970000e+000) (0, -3.50466892977525960000e+000) (1, -4.04038616149880350000e+000) (2, -1.47237826742559110000e-001) (3, -4.07868005887226380000e+000) (4, 1.00936690390739410000e+001) (5, 1.32362042869555360000e+001) (6, -1.50475646469102120000e+000) (7, 3.99966387525598590000e+000) (8, 8.27449395268501480000e-001) (0, 1.58087761985003430000e+000) (1, 1.59557958570010680000e+001) (2, -6.17945623463249840000e+000) (3, -7.70806964703116160000e-001) (4, 3.59302791075554720000e+000) (5, -7.48808656353485700000e+000) (6, 4.19860387653552270000e+000) (7, -8.20007417965517330000e+000) (8, -7.62030503451592980000e-002) (0, -8.48788857709259050000e+000) (1, -1.98026284737621130000e+001) (2, 1.78061917861763170000e+001) (3, -1.42367849677907600000e+001) (4, 5.50688922414285020000e+000) (5, 3.21830338011712630000e+001) (6, -2.15140697454225740000e+001) (7, -5.38980402437965510000e+001) (8, 1.14727987528705810000e+000) (0, 6.82651592477213960000e-001) (1, -9.17305955528071040000e-001) (2, 9.20216641315105940000e-001) (3, -1.95492070480723570000e+000) (4, 9.91914510548240420000e-001) (5, -1.67054129492324300000e+000) (6, 2.04826771536060460000e+000) (7, 2.44966770893130730000e+000) (8, -3.45399228118281890000e-002) (0, 4.53611035278361830000e-001) (1, 1.02219371243600320000e+000) (2, -5.69854398131685810000e-001) (3, 1.97509481136791250000e+000) (4, -4.04886735780597990000e+000) (5, -1.19421041095239700000e+000) (6, -9.91384298389527570000e-001) (7, 2.85019743876068790000e+000) (8, 8.85735402371304850000e-003) (9, -1.11080380863310730000e+000) (10, 5.56324075864647270000e-001) (11, 2.45694458354504820000e-001) (12, -2.96949212310841570000e+000) (13, 8.57452232643002410000e-001) (14, -9.14751964419445280000e-001) (15, -1.27876179505564870000e+000) (16, -9.86643840860399260000e-003) (17, -9.45314428143761540000e-001) (18, 7.58489733141693880000e-001) (19, 6.79619183538032080000e-001) (9, -5.65425188700750120000e-002) (10, -4.34285003669392990000e-001) (11, 1.06371973545792160000e-001) (12, 4.61585277319809160000e+000) (13, -7.48458617132521820000e-001) (14, 1.29547154421810440000e+000) (15, 1.50418836748826390000e+000) (16, -1.08578122291872150000e-001) (17, 1.97615627339478170000e+000) (18, -2.85284521088286120000e-002) (19, 6.06370616700336650000e-001) (9, -1.80642611668869370000e+000) (10, -3.71586856371978800000e-001) (11, -4.05141378603664780000e-002) (12, -1.46370100180379020000e-001) (13, -7.47851556127047960000e-002) (14, 1.65036433596308150000e+000) (15, 5.65075240876918070000e-001) (16, 2.94077425857654060000e-001) (17, 1.15497296416076820000e+000) (18, 4.20503253911244990000e+000) (19, 4.01416646873317410000e-001) (9, -1.46782530913351830000e+000) (10, -9.45298130176785210000e-001) (11, 3.59678317952040920000e-001) (12, 1.79124719143475650000e+000) (13, -9.01494927163332460000e-001) (14, 1.38719070851803310000e+000) (15, 1.48066463352384110000e+000) (16, -4.14590027030004970000e-001) (17, 2.38845535065390190000e+000) (18, -1.04300093036704780000e+000) (19, 6.64449835782273230000e-001) (9, 2.67392032358449510000e+000) (10, -7.34339787928870110000e-001) (11, -9.00267361229454720000e-001) (12, 1.49977699762002750000e+000) (13, -1.49372603536226700000e+000) (14, 1.21032968230974800000e+000) (15, 1.85782841990022260000e+000) (16, 3.98300828810732590000e-001) (17, 1.20898552702986840000e+000) (18, -3.49174413706475230000e-001) (19, 6.97091352890773400000e-001) 
