FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.31211994385090900000e+000) (1, 4.13347664787169580000e+000) (2, -8.57851102755008550000e+000) (3, -3.84415059549595600000e+001) (4, 2.39152382500854480000e+001) (5, 4.08353546822964900000e+001) (6, 1.09785121695624530000e+001) (7, -7.70773359438861490000e+000) (8, 1.27831482804068060000e+000) (0, 2.34816842576646230000e+000) (1, -1.37545856730277620000e+000) (2, 2.07783858106786790000e+000) (3, 3.09889649269978930000e+000) (4, -1.10719533767331960000e+001) (5, -6.03385996875334470000e+000) (6, 5.99998862901290140000e+000) (7, 3.14953276078005030000e+000) (8, 1.29482246619690850000e-001) (0, 5.04327343153325280000e-001) (1, 6.28903178556930250000e+000) (2, -1.46731473780011920000e+000) (3, -7.55673298494475440000e+000) (4, 2.85063664871333030000e+000) (5, -2.38810488279742030000e+000) (6, 9.88991244879390610000e-001) (7, -5.66004207592825990000e+000) (8, 3.97988022843367910000e-002) (0, -8.80834215594310340000e+000) (1, 1.09150937792969780000e+001) (2, -2.81731731299518500000e+000) (3, 7.66465777026785420000e-001) (4, -2.03960983540557240000e+001) (5, 2.46787314187559160000e+001) (6, -4.57553894872718350000e+001) (7, 1.77827563977665020000e+001) (8, 9.42869424650405020000e-001) (0, -6.41893184058879030000e+000) (1, 1.80523763042215530000e+001) (2, 4.60731961012807020000e+000) (3, -2.40386481066473290000e+001) (4, -1.23685882716374390000e+001) (5, 1.78184377146942020000e+001) (6, -1.93191160866426940000e+001) (7, -3.14720186150014420000e+001) (8, 1.54598675162309300000e-001) (0, 1.75574834708349450000e+000) (1, 1.10722265993991800000e+001) (2, 2.74808470446306070000e+000) (3, -3.56489130270912180000e+001) (4, -1.04489249669328040000e+000) (5, 1.43574016622771780000e+001) (6, 1.55713819296146190000e+001) (7, -1.00130385111097200000e+001) (8, 4.85036212697781130000e-001) (0, -4.10396226901174890000e-001) (1, -3.81393470239601480000e+000) (2, 2.63261244796738050000e+000) (3, -8.07298778204535660000e-001) (4, -2.33453005017167310000e-001) (5, 7.46843800422203860000e+000) (6, 3.37096661825963650000e-001) (7, 4.67869190164937660000e-001) (8, 1.59298250280335450000e-001) (0, -3.09445910068073190000e-002) (1, 5.26354003769168300000e-001) (2, 2.60946467128973740000e-001) (3, -1.09490483699340450000e+000) (4, 4.44348256627748310000e+000) (5, -1.48734937128316580000e+000) (6, 3.73637512457555500000e+000) (7, -6.70890309090408720000e+000) (8, -1.69404311982230190000e-001) (0, -4.95458983395111650000e+000) (1, 1.29613283024470880000e+000) (2, -8.17625055659529920000e+000) (3, -2.99180276842551550000e+000) (4, -5.17648282540671130000e-002) (5, 1.78780360663756850000e+001) (6, -3.02214331327361340000e+001) (7, 2.71136859473173610000e+001) (8, 8.70491511679250870000e-001) (0, -9.60651064400596780000e-001) (1, -6.25724070709592000000e+000) (2, -1.10613592111587370000e+000) (3, 5.43011618386603970000e+000) (4, 8.91197381286019490000e+000) (5, 5.57126568057563000000e+000) (6, 5.28880029401612010000e+000) (7, 8.03763605007634750000e+000) (8, 4.37114669082047940000e-001) (9, -2.68448696983939970000e-001) (10, -2.41803410540738370000e-001) (11, -1.89965594565841900000e+000) (12, 6.60153278561279170000e-002) (13, 1.01663517697889090000e-001) (14, 6.57880792408418120000e-001) (15, -1.70017264041967950000e+000) (16, 1.20861791114973590000e+000) (17, 7.33861352822531700000e-002) (18, 3.49233072364284860000e-001) (19, 7.08741638210396040000e-001) (9, 1.55956358432562920000e-001) (10, 9.78810045680508780000e-001) (11, 1.92643200074728750000e+000) (12, -3.95534469371019440000e-002) (13, 2.00066321900776280000e-001) (14, -5.17676209464603690000e-001) (15, 1.33337881520681960000e+000) (16, 2.14098091445195290000e-001) (17, 3.34224383519655610000e-001) (18, 4.96026088741016840000e-001) (19, 4.91004285395471030000e-001) (9, 3.86601695935542390000e-001) (10, 8.66474205885266690000e-001) (11, 1.68119354609230860000e+000) (12, -1.33539763807111020000e-001) (13, 5.72097744851805650000e-001) (14, -8.08493082436506190000e-001) (15, 9.09733539375723650000e-001) (16, -1.16489023913289660000e+000) (17, -1.27614272274115310000e-001) (18, 7.49530119329289150000e-001) (19, 6.89564519497233850000e-001) (9, -6.81861513464802730000e-001) (10, 3.19739226746551000000e+000) (11, 2.90164908090533300000e+000) (12, -3.64049833113948670000e-001) (13, 1.12961925048769790000e-002) (14, -3.82350901613249750000e-001) (15, 3.07537349422671410000e+000) (16, 6.10629859402834810000e+000) (17, 2.10018575172487590000e+000) (18, 4.63953075927004410000e-001) (19, 7.19147194378409570000e-001) (9, -1.76886576173705920000e-002) (10, 2.64838241980926670000e+000) (11, 4.72841346231107720000e+000) (12, -1.47117811105597100000e+000) (13, 1.14233093217528500000e+000) (14, -1.64597131715953200000e+000) (15, 3.52824116954619440000e+000) (16, 4.58122112441459340000e-001) (17, 1.78943863617967120000e+000) (18, 1.07683071394763650000e+000) (19, 6.65004678851838230000e-001) 
