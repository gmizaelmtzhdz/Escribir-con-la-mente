FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -8.42710193579628150000e-002) (1, 6.57538991644804450000e-001) (2, -3.15437822612085970000e-001) (3, 1.05044339591976410000e+000) (4, -8.92143348605514360000e-001) (5, -1.88847682936141850000e-001) (6, 2.78337226584129790000e-001) (7, 1.09709495498114530000e+000) (8, -2.76560825800462480000e-001) (0, 2.10144927115803760000e-001) (1, 2.64498324858200060000e+000) (2, -1.39182611149573090000e+000) (3, 5.55106837555871290000e+000) (4, -2.13552253954086700000e+000) (5, -4.09875762062313510000e+000) (6, 5.87275709777630440000e+000) (7, -5.78107277457087790000e-001) (8, -2.08393914308714430000e-001) (0, 6.86119750989082710000e+000) (1, -8.36458989037337620000e-001) (2, -4.92950516229472320000e+000) (3, 1.00582821848302470000e+001) (4, 1.74318902271240400000e+001) (5, -2.67444636918891270000e+001) (6, 1.83452878291842330000e+001) (7, -8.25419810988680070000e+000) (8, 7.77116457925397960000e-001) (0, 1.46630649034520370000e-002) (1, 5.15619272559080160000e+000) (2, 7.64235076473595410000e+000) (3, -2.13153531720399880000e+001) (4, -7.92518895975035060000e+000) (5, 2.41803151492203520000e+001) (6, -7.36028116085939030000e+000) (7, 4.03783775838392960000e+001) (8, 2.02820629919548440000e-001) (0, 3.88625785999669620000e+000) (1, 2.20159873574245110000e+000) (2, 1.68648535895082290000e+001) (3, -6.33781171473871210000e+000) (4, -6.30359465847359250000e-001) (5, -1.51159877618674350000e+001) (6, 2.26198064773366350000e+001) (7, -3.35918944751990410000e+001) (8, -2.28447692744161300000e-001) (0, 7.53355133126723060000e+000) (1, -8.71998076739175150000e+000) (2, 6.34158587496335540000e+000) (3, -3.19907195635763090000e+000) (4, 1.17591854951683230000e+001) (5, -1.78834690437858730000e+001) (6, 1.06858303748671780000e+001) (7, -2.66756555548200220000e+001) (8, 2.44327049422113470000e+000) (0, 1.02812562613664450000e-001) (1, 8.34445863080733650000e+000) (2, -1.10457736424411020000e+001) (3, 6.29084079618608530000e+000) (4, -2.78454659699159280000e+000) (5, 1.55494530183685150000e+000) (6, -5.29127834062876330000e-001) (7, 2.83783851747956110000e+001) (8, -6.25312216764256410000e-001) (0, 9.08098768867644290000e-001) (1, -3.71201275811993400000e+000) (2, 1.11823988837336210000e+001) (3, -5.93288268333092360000e+000) (4, 2.44018616431283640000e-001) (5, -1.89462918350332870000e+000) (6, 5.88078910848099220000e+000) (7, -2.42609318849318890000e+001) (8, 5.14018856739777320000e-001) (0, -9.13217545848491910000e-001) (1, -2.85504600749752590000e+000) (2, 7.04768267620172750000e+000) (3, -2.97464357280960280000e+001) (4, 5.34947200463661780000e+000) (5, 4.58759081145836020000e+001) (6, -9.45080941558924970000e+000) (7, 3.55360484755651030000e+001) (8, 2.39630994828886030000e+000) (0, 4.33362932051181200000e-001) (1, 1.84398171536567580000e+001) (2, -1.31938611400978200000e+001) (3, -1.59194562408209750000e+000) (4, -1.46118286696094960000e+001) (5, 1.93109754425446560000e+001) (6, -1.30387553257669150000e+000) (7, 6.44039949000092240000e+001) (8, -1.37013169521887650000e+000) (9, -4.89781945905710980000e+000) (10, 2.14835173046354070000e+000) (11, -9.15285126252175090000e-002) (12, 5.73804215167626700000e-001) (13, -5.58097838276013020000e-002) (14, 1.35909254360043220000e-001) (15, -1.46482799210605300000e+000) (16, -1.32394107443165240000e+000) (17, -6.51307669903732340000e-001) (18, 7.41860530154160310000e-002) (19, 4.95516543402811700000e-001) (9, 1.01361424563586390000e+000) (10, -1.26874337995812890000e+000) (11, -3.78904611208499610000e-001) (12, -4.18555252319083470000e-001) (13, -4.45168516888895180000e-002) (14, -1.44219400531256760000e-001) (15, 1.77568149633272480000e+000) (16, 1.35345013192349280000e+000) (17, 5.00705460162650160000e-001) (18, -2.38924101971078970000e-001) (19, 8.05384930481919390000e-001) (9, 5.26572185688721990000e+000) (10, 3.87127596291147010000e-001) (11, -7.56079951283169290000e-001) (12, -2.26394664407185500000e-001) (13, -1.35889983414831990000e-001) (14, 1.10818287812338090000e+000) (15, 1.20309876219828120000e+000) (16, 6.61120738135380080000e-001) (17, 1.14181704672739050000e+000) (18, -4.76514818083806520000e-001) (19, 1.08746674631699510000e-001) (9, -3.41380071564262890000e+000) (10, 1.35552528007637400000e+000) (11, 4.40813175012267850000e-001) (12, 1.26187632300524170000e+000) (13, -1.69091179464941050000e+000) (14, 3.98816770009236100000e-001) (15, 3.15321269853220620000e+000) (16, 3.89832707992361230000e+000) (17, -1.40453427912575980000e+000) (18, -1.09884245195289210000e+000) (19, 3.98794370368704850000e-001) (9, 1.19864872492906240000e+001) (10, -2.28450664019954130000e+000) (11, 5.00222298725972570000e-001) (12, 1.99653702446686540000e-001) (13, -7.31521980497194750000e-001) (14, 7.85752604673208180000e-001) (15, 2.70893628066166460000e+000) (16, 2.39202750088783580000e+000) (17, 5.22730300293288490000e-001) (18, -9.73265234983256680000e-001) (19, 6.82238924765745990000e-001) 
