FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.69268535028452400000e-001) (1, -1.56062646696505780000e+001) (2, 9.82634093671319820000e-001) (3, 4.13216206164919770000e+001) (4, -9.63138830441019780000e+000) (5, -3.79124363387951180000e+001) (6, -1.36052107605310940000e+001) (7, 1.23074223007349310000e+001) (8, -6.15495374797629500000e-001) (0, 5.25303300268530560000e+000) (1, 1.61852913468644100000e+001) (2, 4.34633286498965710000e+000) (3, -4.25022681764759900000e+000) (4, -5.13379782714140940000e+001) (5, -8.53797782242073740000e+000) (6, 1.23678592145676250000e+001) (7, 8.66327630852024240000e-001) (8, 6.55123396032101030000e-003) (0, -3.98841092535476390000e-001) (1, 1.16973088020027130000e+000) (2, -6.46594974116928460000e-001) (3, 1.18525269582849880000e+000) (4, 7.77611061969642140000e-001) (5, -2.76597324023049310000e+000) (6, 7.24528736284984380000e-001) (7, 3.78028050719839300000e-001) (8, 2.20669285534697970000e-001) (0, 2.19393486889519050000e+000) (1, -2.55839650754607110000e+000) (2, -2.10146799720027790000e+000) (3, 5.58205429619325780000e+000) (4, 2.39787704756347320000e+001) (5, -1.19987527165772220000e+001) (6, 1.31121222998746970000e+001) (7, -1.40002728472645560000e+001) (8, 1.36248834305647830000e-001) (0, -3.90574693156080290000e+000) (1, -1.79131979515881350000e+001) (2, 3.68760096563086660000e+000) (3, 7.21415319455836990000e+000) (4, 4.77867464676270120000e+001) (5, -3.24625008727948710000e+000) (6, -2.55409863362845610000e+000) (7, -4.26464145908191340000e+001) (8, 2.88650627889338710000e-001) (0, 2.94140695513488250000e+000) (1, 1.10889995146178210000e+000) (2, 2.83055987114300270000e+000) (3, 7.17592219955163820000e+000) (4, -7.23749463328527630000e-001) (5, -8.85053456581771240000e+000) (6, 1.52617112582051070000e+001) (7, -1.74456855098934050000e+001) (8, -2.38938075907001750000e-001) (0, 5.87445015989991360000e-004) (1, 9.80172934179761410000e+000) (2, -5.34797188366888760000e+000) (3, 4.18516201074052940000e+000) (4, 3.70877071932626560000e+000) (5, -1.56328670225845790000e+001) (6, 6.89150338804372890000e+000) (7, 3.70886513831385530000e+000) (8, 8.81324910840446840000e-001) (0, -8.92487886983634900000e-001) (1, 3.89050402080799000000e+000) (2, -2.71117033012743920000e+000) (3, -1.36815093730881440000e+001) (4, 1.23572605378129110000e+001) (5, 1.87094346410547420000e+001) (6, 1.20769842967165410000e-001) (7, 9.44551661337050060000e+000) (8, 4.10280123074088620000e-001) (0, 3.72818515816616140000e+000) (1, 3.46359470161403940000e+000) (2, -1.15370543000233190000e+000) (3, 3.37383316880726270000e+000) (4, -1.92872582720270030000e+001) (5, -3.80813762387880450000e+000) (6, 6.61797181293321040000e+000) (7, 8.04703772761286020000e+000) (8, -3.23591343506909270000e-001) (0, 1.39978732947709790000e-001) (1, 2.12355557693242820000e-001) (2, -1.73495130369316360000e+000) (3, 1.31463739762221990000e+000) (4, -3.95927465829307450000e+000) (5, -7.14414769907188330000e-001) (6, -2.15346947833070250000e+000) (7, 7.49604316773891190000e+000) (8, 5.42120331421967820000e-002) (9, -5.22807449931671940000e-001) (10, -7.89493927142598580000e-001) (11, 5.37232853645122170000e+000) (12, 4.66543357635345770000e-001) (13, -8.10126859932509440000e-001) (14, -1.55112544313302430000e-002) (15, -1.39996769773352050000e+000) (16, -1.30174057353821190000e+000) (17, 2.53732868956757780000e-001) (18, -1.04803404372187940000e+000) (19, 8.20471918034381910000e-001) (9, 1.75711697445079170000e-001) (10, 1.24235045366334060000e-001) (11, -3.12725608148363630000e+000) (12, -7.50532191919062620000e-001) (13, 5.04459269380295280000e-001) (14, -1.54754705895757490000e-001) (15, 1.12229321098837210000e+000) (16, 6.32035845835062340000e-001) (17, 3.92690161950134730000e-001) (18, -4.66730358043125740000e-001) (19, 6.83217201556039600000e-001) (9, 1.21140076014478450000e-001) (10, 1.55132016908994280000e-001) (11, 8.98063158968921750000e-001) (12, -1.27126744044006660000e+000) (13, 1.05174169742917440000e+000) (14, 5.34467594949444960000e-001) (15, 3.88892023004729140000e-001) (16, 1.05121562153592210000e+000) (17, 1.05028541142416930000e+000) (18, 8.07847773028369630000e-001) (19, 7.20994187090656660000e-001) (9, 3.86260081150998140000e-001) (10, -6.08039512706646910000e-001) (11, -2.15359716711353280000e+000) (12, -3.42303132093123500000e-002) (13, 4.92620116311145020000e-002) (14, -2.26482811592544710000e+000) (15, 1.23192922802474510000e+000) (16, -2.55231060600468570000e-001) (17, 2.75167904124636300000e+000) (18, -7.20536283691143800000e+000) (19, 1.26022272990334310000e+000) (9, 1.23096799662839730000e+000) (10, 1.78549089237176850000e+000) (11, 6.06443992110471180000e-001) (12, 1.17491269741823270000e+000) (13, 1.68344814778564640000e+000) (14, -2.68428060475946540000e+000) (15, -2.27685443381137920000e-003) (16, 2.55954036317653480000e+000) (17, 1.75036249448005020000e+000) (18, -1.80436308586186090000e+000) (19, 6.16247247754945880000e-001) 
