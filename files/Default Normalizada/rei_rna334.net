FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 7.68887070095621720000e+000) (1, -1.48220573076406770000e+000) (2, 2.08515216637037120000e+000) (3, 1.59665303640847970000e+001) (4, 2.09848378759521380000e+001) (5, -3.27685886938041550000e+001) (6, 9.14104957210841110000e+000) (7, -2.02287849566042940000e+001) (8, -1.25640681636913220000e+000) (0, 3.89003635716868800000e-001) (1, 9.87629294579897630000e+000) (2, 2.77426306912033240000e-001) (3, -2.14297581876688930000e+000) (4, -1.82823214986086530000e+001) (5, 5.37227781504823020000e+000) (6, -2.85610195568881230000e+000) (7, 2.21118045973013930000e+001) (8, 6.16005168110683730000e-001) (0, 2.04455833839202680000e-001) (1, 9.87012719474893530000e+000) (2, 2.19728420688112090000e+000) (3, 1.52462576257971950000e+001) (4, -4.26042158476009260000e+001) (5, 6.87868354433269060000e+000) (6, -9.94917232216917390000e+000) (7, 4.37905856945865250000e+001) (8, 7.02146022990759590000e-002) (0, -1.07946627098790500000e+000) (1, 2.04657766953907360000e-002) (2, -1.21829602534773200000e+000) (3, 5.05674211943245220000e+000) (4, -2.70156161616756100000e-001) (5, -2.94760032131824850000e+000) (6, 1.82634565658313070000e-001) (7, 2.41101569808672170000e+000) (8, 5.06889631221094320000e-001) (0, -6.88916118937285990000e-001) (1, 2.11439035862562780000e-002) (2, -2.41233589869072900000e-001) (3, 1.14372685281868010000e+000) (4, -3.48781219482313840000e+000) (5, 1.54038070880358790000e+000) (6, -1.89751558878006370000e+000) (7, 4.66816970841802800000e+000) (8, 1.57189653474969770000e-001) (0, -2.84508744454558380000e+000) (1, 2.11556346364876580000e-001) (2, -1.67025746375958990000e-001) (3, -4.17643673770447950000e+000) (4, 3.07691826881734840000e+000) (5, 8.05188749176167920000e+000) (6, -2.04831179252709330000e+000) (7, 7.26348734727530590000e-001) (8, 1.28997291408710500000e-001) (0, -6.86409977797199570000e+000) (1, 3.94171799986138270000e+000) (2, -5.08348169991826900000e+000) (3, -1.51625923100557320000e+001) (4, 2.11833074828422170000e+001) (5, 1.25303460646196520000e+001) (6, 1.57569660772317730000e+000) (7, -4.81917613981614680000e+000) (8, 1.01176346112384460000e+000) (0, 2.26778318398378670000e-001) (1, 1.27459284183891220000e+001) (2, -1.05861589662854900000e+001) (3, 1.60878777898014360000e+001) (4, -4.89386195289109340000e+000) (5, -2.50191101915233500000e+001) (6, 1.90141957749961190000e+000) (7, 3.18334339285901180000e+001) (8, 7.33124063769415630000e-001) (0, 2.84842618322884270000e+000) (1, -1.37405959444246870000e+001) (2, -1.99023668085493240000e-001) (3, 1.31166303384672640000e+001) (4, -4.75343081782789150000e+000) (5, -1.72668078641790610000e+001) (6, -4.70631387019947840000e+000) (7, 7.60067065285780430000e+000) (8, -3.46857538054329950000e-001) (0, -4.01538025170864010000e+000) (1, 6.69762394753601150000e+000) (2, -3.37152449251811040000e-001) (3, -2.34513496060930220000e+000) (4, 3.01328480117456890000e-001) (5, 1.60875022515400520000e+001) (6, -3.29450056042455320000e+000) (7, 3.86057921067855410000e+000) (8, 7.72877607614126490000e-001) (9, 2.56697776916824660000e-001) (10, 1.42123262894589560000e+000) (11, -1.84611335218622320000e-002) (12, 2.50545503449469020000e+000) (13, -2.20405732754899250000e+000) (14, -2.33722027623045390000e-001) (15, 7.23138225901925670000e-001) (16, -7.48850699259503650000e-001) (17, 4.62618057546676230000e-001) (18, -2.61921753430630070000e-001) (19, 7.81304977931187550000e-004) (9, -2.88307527968399650000e-001) (10, -9.15692498732433640000e-001) (11, 6.58136893415531000000e-002) (12, -2.06155082966260080000e+000) (13, 1.13505094903224800000e+000) (14, -8.98336163128692020000e-001) (15, -2.67265652292582900000e-002) (16, 4.10369314030620440000e-001) (17, 7.38569170778674910000e-003) (18, 7.70750346285593800000e-001) (19, 9.93509103438067640000e-001) (9, -6.04901086735913470000e-001) (10, -3.46195118876839530000e-002) (11, -6.35859454962441340000e-001) (12, 7.26809762655555410000e-001) (13, -1.36395434357326680000e-001) (14, -1.43633190529985180000e+000) (15, -7.47090826617434310000e-001) (16, 6.31979563364433870000e-002) (17, -6.10300528534657160000e-002) (18, 1.20396402475584050000e+000) (19, 5.08195143690287730000e-001) (9, -9.35957847365202160000e-001) (10, 1.38452908509796570000e+000) (11, -8.26917125700625260000e-001) (12, 9.38874481979381730000e-001) (13, -1.04052401492215590000e+001) (14, 3.76432304173999240000e+000) (15, -2.16220490232938900000e+000) (16, 7.88458016975733810000e-001) (17, 1.47674586294288160000e+000) (18, 1.67751482851846470000e+000) (19, 8.31953285035353260000e-001) (9, 2.62197429448096240000e-002) (10, 6.22125609380295710000e-001) (11, -9.65620608102001010000e-001) (12, -1.75550632259011930000e+000) (13, 5.53249450551871360000e-001) (14, -7.15601332349984130000e-001) (15, -3.84073137030436940000e-001) (16, 3.72985775467128520000e-001) (17, 1.35241230088649610000e+000) (18, 2.44737194105188840000e+000) (19, 7.46119188013384950000e-001) 
