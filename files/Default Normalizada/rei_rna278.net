FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.85719637601838740000e+000) (1, 1.56612493845416220000e+000) (2, -6.04759178972640130000e+000) (3, 5.96103723690539060000e+000) (4, -4.52157690245252210000e+000) (5, -3.04459236126371070000e+000) (6, 5.59747520133951460000e-001) (7, 1.33593345765753210000e+001) (8, -2.35090393811736380000e-001) (0, 2.25652629109134040000e+000) (1, 1.64598872755921090000e+000) (2, -8.10348458139545260000e+000) (3, 2.33861131525980470000e+000) (4, 2.78098840109651140000e+000) (5, -6.49282002561120390000e+000) (6, -4.01540769534393680000e+000) (7, -7.39462479821698260000e+000) (8, 9.22387464620368690000e-001) (0, 2.44849692422402660000e+000) (1, -1.07898078558248810000e+001) (2, 1.34607837602996310000e+001) (3, -9.31683116178576220000e+000) (4, 5.59367707566129630000e+000) (5, 1.06591558953425380000e+001) (6, -1.67836993700015850000e+001) (7, -4.28584415779248860000e+001) (8, -1.63479552761614770000e-001) (0, -1.48710691160634130000e+001) (1, -1.01191521778842010000e+001) (2, 4.64842899670958330000e+001) (3, 8.85668528868104230000e+000) (4, -2.97657122973162810000e+001) (5, 4.80766214016934090000e+001) (6, -5.61016923967393100000e+001) (7, 2.54080059566820930000e+001) (8, -1.17317219141542130000e-002) (0, -1.25983844099879750000e+000) (1, 4.19451304709372310000e-002) (2, 1.60303687236489930000e+000) (3, 4.88271895849361040000e+000) (4, -1.80776085488122760000e+000) (5, -3.59414598701938100000e+000) (6, 2.35287239088705170000e+000) (7, 1.23168471751514940000e+001) (8, -1.05809306020669210000e-001) (0, 1.64141002088261300000e+000) (1, 2.39953378558039390000e-001) (2, 1.94701109578083550000e+001) (3, 1.61005440159645130000e+001) (4, -6.32334134839433300000e+000) (5, -7.53395732824019770000e+000) (6, -1.98473678749499280000e+001) (7, 8.18704771101309350000e+000) (8, 9.33203446624497390000e-001) (0, 1.50022966891518970000e+000) (1, 1.35893673385968330000e+001) (2, -1.35112236594622440000e+001) (3, 1.12650867543296580000e+000) (4, -1.20230617774308270000e+001) (5, 3.63289995991964990000e-002) (6, 1.78203357010383790000e+000) (7, 3.02532299731872680000e+000) (8, 1.13398726580045930000e+000) (0, -4.78354891130596020000e+000) (1, 4.74370318913715930000e+000) (2, -1.09892375525474240000e+001) (3, -7.23907828704861610000e+000) (4, 8.25829185603699760000e+000) (5, 1.25516447523558590000e+001) (6, 9.18812690872367100000e+000) (7, 3.65097051323436830000e+001) (8, 1.21063151076669810000e+000) (0, -4.91841165468895720000e-001) (1, -1.55081438641648830000e+000) (2, 1.80800553866172970000e+000) (3, -9.60974536504750350000e+000) (4, 3.78504894755126120000e+000) (5, 9.01318526679572510000e+000) (6, 2.01507340693876640000e+000) (7, -6.19292220016565320000e+000) (8, -5.53911383136610040000e-001) (0, 4.43349334787808310000e+000) (1, 1.85436114027360620000e+001) (2, -1.13403343072362710000e+001) (3, -2.74919833116687040000e+001) (4, -1.25277079755050170000e+001) (5, 1.95418785040606690000e+001) (6, 3.88463998762639240000e+001) (7, -3.28039888923041690000e+001) (8, 3.59123207866490840000e-002) (9, 3.32063041254676510000e-001) (10, 2.99043470027392820000e+000) (11, 3.87812410894248120000e-001) (12, 3.19993486910345460000e-001) (13, 4.50128034876045560000e+000) (14, -3.24634484487119550000e-002) (15, -5.25410352508775990000e-001) (16, -3.30233234600157910000e-001) (17, 1.82541320457752600000e+000) (18, 5.96345621011444060000e-001) (19, 5.21386841808043620000e-001) (9, -5.81703154301427830000e-001) (10, -1.60315945051948260000e+000) (11, -1.26606446712663220000e-001) (12, -1.12893456015371530000e-001) (13, -2.06902290438041270000e+000) (14, -1.41715383193750130000e-001) (15, 8.22536291574091690000e-001) (16, 3.21485984742309160000e-001) (17, -5.11139268233266050000e-001) (18, -5.11690545219703810000e-001) (19, 7.03080612236765880000e-001) (9, -2.12239659760672380000e+000) (10, -1.35631999496319700000e+000) (11, 1.00285762633911850000e+000) (12, 1.31727156120967110000e-001) (13, -3.83556179462048340000e-001) (14, -1.42224761992831520000e+000) (15, 8.48967619422605240000e-001) (16, 1.37903272889317410000e+000) (17, -4.11418951614463340000e+000) (18, -1.97314216011376030000e-001) (19, -1.16176961724121050000e-001) (9, -1.38545451489035830000e+000) (10, -7.73955918360118230000e-001) (11, -5.42468585141235300000e-001) (12, -9.69797767350374370000e-002) (13, -1.34507309735677210000e-001) (14, -4.68365533318680800000e-001) (15, 1.19509542451501960000e+000) (16, -6.50601473451610350000e-001) (17, 8.63311429675981070000e-001) (18, -7.61133118764216190000e-001) (19, 1.33668036036975810000e+000) (9, -9.21253461975916730000e-001) (10, -2.60720452071478850000e+000) (11, 5.35061376749588760000e-001) (12, -4.73698261290906810000e-001) (13, -2.49819181685871780000e+000) (14, -1.69140855050521010000e-001) (15, 1.06647296941572670000e+000) (16, 9.61459135421257160000e-001) (17, -1.96959550464138580000e+000) (18, -7.91795168266660410000e-001) (19, 5.86059795645401560000e-001) 
