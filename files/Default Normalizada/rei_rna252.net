FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -6.40564528632571670000e+000) (1, -3.59620591865812190000e+000) (2, -2.53579852429180620000e+000) (3, -1.20782445264235230000e+000) (4, -6.71920468653106970000e+000) (5, 1.57629040877563820000e+001) (6, 1.74141020267864640000e+000) (7, 2.65322219877327610000e+001) (8, 2.45080853800103640000e-001) (0, -6.73905782430556230000e+000) (1, -2.58860500265972140000e+001) (2, 1.21424886059943820000e+000) (3, 1.01800568636242520000e+001) (4, 4.32860415933667040000e+000) (5, 6.16011762895673700000e+000) (6, -7.66924165192859950000e+000) (7, 4.59617383113300270000e+000) (8, 3.33560669596717710000e-001) (0, 1.55179678344522930000e+000) (1, 5.61291604947998920000e+000) (2, 4.62641354909184840000e-001) (3, 2.81171913247169640000e+000) (4, -3.03469140490252440000e+000) (5, 7.65507514454275340000e-001) (6, -5.81056565428507900000e+000) (7, 9.09877747883526490000e-001) (8, -7.98974888471261080000e-002) (0, 3.61944540532109670000e-001) (1, 7.54581787053394960000e-001) (2, 8.97774469463496370000e-001) (3, -3.71243235471662380000e+000) (4, 3.83728923533589720000e+000) (5, 3.61347416083107390000e+000) (6, -1.23548972922922480000e+000) (7, -5.17694220136181290000e+000) (8, 1.55311270074358490000e-002) (0, 8.87359887489190060000e+000) (1, -3.45494144647915610000e+000) (2, 9.29209060405067080000e+000) (3, -1.11690403132209680000e+001) (4, 5.61260600268030800000e+000) (5, 1.88385834099349090000e-001) (6, -1.67495536024327080000e-002) (7, -3.24306911022397340000e+001) (8, 3.08439432527911340000e-001) (0, -8.00018196991065620000e+000) (1, 5.67724961223532800000e+000) (2, -1.28582726459018510000e+001) (3, -2.20781560462773360000e+001) (4, 2.88406153856567830000e+001) (5, 1.37327311731571790000e+001) (6, 8.63647526177718030000e+000) (7, 1.19037034460720580000e+001) (8, 1.31931408885935380000e+000) (0, 1.02847241534446020000e+001) (1, 3.36325111073803170000e+001) (2, -1.12042259838992350000e+001) (3, -6.97385948862140110000e+000) (4, 5.72447616048542060000e+000) (5, -2.59540187500472900000e+001) (6, 1.43497492717626170000e+001) (7, 1.49750074178848660000e+001) (8, 4.00012491890045900000e-001) (0, 3.31627898248640960000e+000) (1, -4.96307960136414430000e-001) (2, 4.93672646293887410000e+000) (3, -3.21394331726522700000e+000) (4, -2.29039876401374130000e+000) (5, 5.54186927534225400000e+000) (6, -4.82948850202299340000e+000) (7, -1.12678079143440380000e+001) (8, 4.36297768446920420000e-001) (0, 1.86487435809816570000e+000) (1, 1.24133709974146560000e+001) (2, -2.86781185240609600000e+000) (3, 6.10292120103895550000e-001) (4, -2.82982865689956140000e+000) (5, -4.41906197477786830000e+000) (6, -2.17722514392911610000e+000) (7, 2.04477935328510130000e+000) (8, 5.21534080944683450000e-001) (0, -3.17267566672109540000e-001) (1, -1.85209291694177480000e+000) (2, 7.47622551910052670000e-001) (3, -4.47831782304700530000e+000) (4, 2.97676162181691060000e+000) (5, 2.62655587208277600000e+000) (6, 1.97740613072383150000e+000) (7, -3.57843096539554880000e+000) (8, 8.53093974859350650000e-002) (9, -6.38557665056084690000e-001) (10, -7.77842853851147260000e-001) (11, 1.09740240723354950000e+000) (12, -1.52331709501897890000e+000) (13, -4.41786936029533510000e-001) (14, 2.11675816581404250000e-001) (15, -4.58502274665504810000e-001) (16, -2.82013333301020850000e-001) (17, -1.37754035788438320000e+000) (18, 1.33688607553486170000e+000) (19, 1.21393857730761880000e+000) (9, 4.64032220347454340000e-001) (10, 5.69982532013830530000e-001) (11, -7.28544242718896730000e-001) (12, 7.65732782149653680000e-001) (13, 9.40308742561778850000e-002) (14, -7.36018707564224240000e-002) (15, 1.34482044480351980000e-001) (16, 4.64970965365599510000e-001) (17, 1.60779641788678360000e+000) (18, 2.22398811621110000000e-001) (19, 1.84915241225627030000e-001) (9, 6.11745662580412630000e-001) (10, -6.25977227438683670000e-001) (11, -5.04352863115040330000e+000) (12, 4.27710831334135830000e+000) (13, 3.92603244231224830000e-001) (14, 1.01505334132828530000e-001) (15, -6.53119531024680680000e-001) (16, 8.86159301509944490000e-001) (17, 8.77091453757402050000e-001) (18, -8.94576260080421550000e+000) (19, 8.14322637238176660000e-001) (9, 1.25545636545944190000e+000) (10, 1.32190238190101610000e+000) (11, -1.79344749200531180000e+000) (12, 4.18121081358414950000e+000) (13, 1.05993815221759700000e+000) (14, -1.26559896082530780000e+000) (15, 3.92085623393189360000e-001) (16, -1.92859048398239620000e+000) (17, 3.45691484761001490000e+000) (18, 5.40039227935887930000e-003) (19, 6.05044316600164670000e-001) (9, 2.83041164441751090000e-001) (10, 1.67666468771201660000e+000) (11, 6.06330773294036800000e+000) (12, -4.72689482613856790000e+000) (13, 1.64518684557355940000e+000) (14, 5.46957840499655360000e-002) (15, 6.94858964020230170000e-001) (16, -2.70095653197128850000e+000) (17, 5.99842277369774800000e-001) (18, 8.02153206196484980000e+000) (19, 7.37459554253654390000e-001) 
