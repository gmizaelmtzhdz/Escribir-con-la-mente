FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -7.24859439167697420000e+000) (1, 8.80552699613269320000e+000) (2, -2.24013543648498730000e+001) (3, -1.83577392056699300000e+001) (4, 2.57519837022252640000e+001) (5, 1.96083751563106720000e+001) (6, 4.25747212602614590000e+000) (7, 2.36603558399841280000e+001) (8, 1.35589481198230290000e+000) (0, -3.55666861406936090000e+000) (1, -6.50122864069071050000e+000) (2, 2.37488075049580550000e+001) (3, -1.68658729060756620000e+001) (4, 4.05229720129712060000e+000) (5, 2.23471425121017440000e+001) (6, -1.24489413424777170000e+001) (7, -4.82621816350584110000e+001) (8, -5.34255729699316780000e-001) (0, 4.18210083047033090000e+000) (1, 3.24425851696816680000e+000) (2, 1.20071476442703440000e+000) (3, 5.16587021557386720000e+000) (4, -1.68274136637189070000e+001) (5, -1.54393100442107700000e+000) (6, 1.17005746473797070000e+000) (7, -3.13419858685610550000e+000) (8, -1.80937558914441880000e-001) (0, -6.00195340481958000000e+000) (1, 1.60911380609653700000e+001) (2, 3.22034551949965220000e+000) (3, -2.60887716585534510000e+001) (4, -5.29030307238309310000e+000) (5, 2.22741389178692300000e+001) (6, -1.26447862163234550000e+001) (7, -3.82815010347103310000e+001) (8, 8.32778460703615390000e-002) (0, 3.97512965278391580000e-001) (1, 3.43002171887244820000e+000) (2, -1.34826229354686360000e-001) (3, -8.35928172765790830000e+000) (4, 7.17328085379700480000e+000) (5, -2.47070969422425210000e+000) (6, 7.06099697257636900000e+000) (7, -1.36741022909570230000e+001) (8, -2.92946253023321810000e-002) (0, 4.84700226830865950000e+000) (1, 1.20207678206340190000e+001) (2, -7.83693604651592060000e+000) (3, -1.79002357653257110000e+001) (4, -8.94116478779798740000e+000) (5, 1.80558140374728740000e+001) (6, 3.47897787093352520000e+001) (7, -3.61755547501261460000e+001) (8, -3.35674179779304640000e-001) (0, -1.57575596731216280000e+000) (1, 1.79254306334943500000e+000) (2, -1.17467927631884720000e-001) (3, -1.08145930742207830000e+001) (4, 4.47195044833079440000e+000) (5, 9.48686370508702300000e+000) (6, 2.43809688157055420000e-001) (7, -4.14897732132502210000e+000) (8, -6.83876860506979600000e-001) (0, -1.15610234496891630000e+001) (1, 1.26975782077958730000e+001) (2, 3.25086557604088090000e+000) (3, 2.77070189647187260000e+000) (4, -2.02750170162291600000e+001) (5, 2.15861641722708410000e+001) (6, -5.23341664471256750000e+001) (7, 1.71820429598702770000e+001) (8, 1.21332811774152050000e+000) (0, 9.71337470949297450000e-001) (1, -1.32801583159243730000e+001) (2, 3.30417860738757060000e-001) (3, 1.93731153523661740000e+001) (4, 4.49815068911615420000e+000) (5, -3.02295614551915960000e+000) (6, 8.61800348011956350000e+000) (7, 1.29226399640420910000e+001) (8, 4.39838379563840480000e-001) (0, 2.56479381564450430000e+000) (1, 1.74104309392713510000e+000) (2, 1.42765387439776980000e+000) (3, 3.22335721325710440000e+000) (4, 4.63807852642304040000e+000) (5, -2.06446788440250370000e+001) (6, 7.53727480778809070000e+000) (7, -1.12454845000208220000e+001) (8, -1.45363393136009460000e-001) (9, 4.30047739149251430000e-001) (10, 4.31623559974189330000e-001) (11, -2.67687914300445700000e-001) (12, -4.99232840627414910000e-001) (13, -3.40213945565400740000e+000) (14, 6.30874869147167730000e-001) (15, 2.45414577240817610000e+000) (16, 3.00898877983367400000e-001) (17, -1.15355233062132090000e-001) (18, 2.48742598912352130000e+000) (19, 1.27896186370275180000e+000) (9, -1.70732264892338000000e-001) (10, -5.34967328729660240000e-001) (11, 7.99582563674733240000e-001) (12, 9.58136898771760670000e-001) (13, 2.57026339756219000000e+000) (14, -7.46670542169115660000e-001) (15, -7.32673028568697760000e-001) (16, -2.55633304126812680000e-001) (17, 8.75241893338755240000e-001) (18, -1.59622695862385800000e+000) (19, 4.00889312945303670000e-001) (9, 2.76079177127543650000e-001) (10, 6.93500437276043940000e-002) (11, 5.12233836061732670000e-001) (12, 6.30181286982343660000e-001) (13, 1.44472940615221110000e+000) (14, -2.89837880055673510000e-001) (15, -1.91117952358989830000e+000) (16, -1.83643160823810580000e-001) (17, 4.98250621731713470000e-001) (18, -1.01925038449186920000e+000) (19, 2.07700874391714970000e-001) (9, -6.18047003935892400000e-001) (10, -8.51199983815808300000e-001) (11, 8.80263284514946400000e-001) (12, 8.10758035938816680000e-001) (13, 2.60240495127615290000e+000) (14, -9.10608179157407440000e-001) (15, 7.10633729552160530000e-001) (16, -1.63840239765523890000e-001) (17, 1.10956818228113030000e+000) (18, -1.26369125403791280000e+000) (19, 1.08394662310234110000e+000) (9, 2.57216712602313600000e-001) (10, -6.28499455948815070000e-001) (11, 1.96201164277452440000e+000) (12, 1.93499846443233640000e+000) (13, 2.63014888277742240000e+000) (14, -1.69864350303514410000e+000) (15, -4.17220044027380890000e-001) (16, -1.04070318177288600000e+000) (17, 1.47958817495562030000e+000) (18, -1.44208263993942440000e+000) (19, 7.07136843606452350000e-001) 
