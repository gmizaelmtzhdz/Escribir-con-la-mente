FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.65477518577435570000e-001) (1, 7.74191319142068180000e-001) (2, 9.14099963011135500000e-001) (3, -2.08293511701756180000e+000) (4, 1.86700340494608600000e+000) (5, -2.09324614140849050000e-001) (6, 3.26942220679462060000e+000) (7, -6.05898374405920310000e+000) (8, 5.12071396779216340000e-002) (0, 7.80174430499132930000e+000) (1, -3.29970336797253380000e+000) (2, 4.70671952780604210000e+000) (3, 1.76997077028620670000e+001) (4, -2.99814012410903710000e+001) (5, -7.12604076209315100000e+000) (6, -5.93784763248185500000e+000) (7, 7.00308311371651730000e-001) (8, -9.13073561741992610000e-001) (0, -2.29498809950634350000e-001) (1, -8.43340551251470500000e-002) (2, -1.22503921724103250000e+000) (3, -1.34102134655607390000e-001) (4, -1.61983836740109990000e+000) (5, 2.02439074068775860000e+000) (6, 9.52332757865124950000e-001) (7, 4.91391782396388340000e+000) (8, -1.56008176188491690000e-001) (0, 4.43677583189554470000e-001) (1, 6.16051190268561830000e+000) (2, 3.11217480049879840000e+000) (3, 5.12437608180626820000e+000) (4, 4.59973768043004230000e+000) (5, -6.14923727262201590000e+000) (6, 2.23449789879549110000e+000) (7, -1.34718900096031470000e+001) (8, -6.17789739320024480000e-002) (0, -7.00705868020337190000e-001) (1, 7.18854505095703920000e-001) (2, -1.06745630276456380000e+000) (3, 2.95651639726410490000e+000) (4, -6.81255606247843980000e-001) (5, -9.40568385212339210000e-001) (6, 2.63080164426077800000e+000) (7, 7.19066124598788490000e-001) (8, -1.12667706410595510000e-001) (0, -5.34402849745459550000e+000) (1, 4.72044143475544950000e+000) (2, -6.02271796306734060000e+000) (3, 8.72601696424010750000e-001) (4, 6.89323155393381710000e+000) (5, 1.27994848198975700000e+001) (6, -1.84259186213722100000e+000) (7, 1.84210659908920360000e+001) (8, 5.23951654767182080000e-001) (0, 3.02318449364442540000e+000) (1, 1.53057601657669280000e+000) (2, 8.04785303278512210000e+000) (3, 1.02888557523746710000e+001) (4, 3.30027201598426470000e+000) (5, -9.61719402101478770000e+000) (6, -3.85635732147871700000e+000) (7, 6.40717668592158060000e+000) (8, -2.99978329726287850000e-001) (0, 6.74619099641724060000e+000) (1, -3.64353666630535140000e+000) (2, 1.93398023074245100000e+001) (3, 2.75799669863026580000e+001) (4, -4.33568467602064440000e+000) (5, -2.59765444838896930000e+001) (6, 4.47785999939544420000e+000) (7, -1.00843365271987810000e+001) (8, -3.84885936102281000000e-001) (0, -1.29566297740460710000e+000) (1, -5.48947936462514360000e+000) (2, -5.11446738515762610000e+000) (3, 4.14372392303198470000e+000) (4, 3.43566818757039580000e+000) (5, -4.89697591624587060000e+000) (6, -9.22555328451750970000e+000) (7, 8.60478545522617820000e+000) (8, -2.93021507060226340000e-001) (0, 1.39974307528588730000e+000) (1, -3.61668222380920450000e+000) (2, 7.45281594664934310000e+000) (3, -1.27413701562213680000e+001) (4, 1.06114801826630390000e+001) (5, 4.79831709108851760000e-001) (6, 1.89809579344095750000e+000) (7, 2.96863619718714840000e+000) (8, 7.67538122528911630000e-001) (9, 3.22378716965421860000e-001) (10, -2.08903893849201270000e-001) (11, -3.56285870682197060000e+000) (12, -1.47218431654252170000e+000) (13, 2.71185929938069050000e+000) (14, -2.66410557804943220000e-001) (15, 1.03640587142992960000e+000) (16, -4.11970156993541670000e-001) (17, -6.68406116567567320000e-001) (18, -3.81647515842829080000e-001) (19, 5.05478792159091190000e-001) (9, -2.45513962262922410000e-001) (10, 1.52275469748963050000e-001) (11, 2.35392353875865230000e+000) (12, 1.04722345389958330000e+000) (13, -2.60468674524567280000e+000) (14, 4.63013778850591470000e-001) (15, -8.25874592446747880000e-001) (16, 2.49428927432371380000e-001) (17, 3.95860489430472420000e-001) (18, 2.36954057079440810000e-001) (19, 7.57134583774976000000e-001) (9, -3.57994573589899680000e+000) (10, 7.29068676280744450000e-001) (11, 2.40470944387108230000e-001) (12, 2.15724628819963370000e+000) (13, 7.49051809015420680000e-001) (14, 8.56209823500848180000e-001) (15, -2.55817066575092470000e+000) (16, 5.51879236484298820000e-001) (17, 2.83565165190864610000e-001) (18, 1.91730725094333980000e+000) (19, 3.72615706429289480000e-001) (9, 4.06026566584128900000e+000) (10, 1.00430139955033560000e+000) (11, -8.84743406216667250000e-001) (12, -4.41888156028873550000e-001) (13, 1.35209345761468300000e+000) (14, 4.66681506918859510000e-001) (15, 9.77639519578023860000e-001) (16, -6.44699798644117530000e-001) (17, 1.12428507142482780000e+000) (18, 5.29732908107924280000e-001) (19, 1.24270931443187100000e+000) (9, -8.21110021302151160000e-001) (10, 6.71148685638848550000e-001) (11, 4.92963760374631650000e+000) (12, 2.85252774572519070000e+000) (13, -2.08231265661833080000e+000) (14, 5.93791721529237200000e-001) (15, -1.76696423131099900000e+000) (16, 4.95310399833043700000e-001) (17, 1.88931087426234770000e+000) (18, 1.70183912963428450000e+000) (19, 1.05378560481735840000e+000) 
