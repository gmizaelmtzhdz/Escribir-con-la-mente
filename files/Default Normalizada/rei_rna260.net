FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 6.09193787546339750000e+000) (1, 3.94013263822276550000e+000) (2, 5.90609391503203530000e+000) (3, 6.39064191160546620000e+000) (4, -3.98656219587158440000e+000) (5, -1.04145708466420870000e+001) (6, 3.23552161076112550000e+000) (7, -1.92115103458388670000e+001) (8, 9.27733919927809290000e-001) (0, 7.52746087832168680000e-001) (1, -6.46581398592281360000e-001) (2, 3.60567866878530640000e+000) (3, 6.11132141989812400000e-002) (4, 7.40709445732552220000e+000) (5, -4.00081999710556860000e-001) (6, -7.15559887482097160000e+000) (7, 8.83807746840492920000e+000) (8, 2.35547677336369160000e-002) (0, -1.77221780450814160000e+000) (1, 8.53492662485786900000e+000) (2, -9.48182124508108080000e+000) (3, 1.47520070543560600000e+001) (4, -8.03698710953695010000e+000) (5, 1.84411729403316920000e+000) (6, 4.00483843354968730000e-001) (7, 1.52815250567889320000e+000) (8, 5.07895050758904070000e-001) (0, -1.32623795112069360000e+001) (1, -1.32509741181193910000e+001) (2, 2.50144472520454680000e+001) (3, -3.66491994780149530000e+000) (4, -1.33248323581287490000e+001) (5, 4.22685067352709610000e+001) (6, -3.92381697169149460000e+001) (7, 1.54431963724352330000e+001) (8, -2.63826877376130750000e-001) (0, 3.91328710651168030000e-001) (1, -2.75988980489745650000e+000) (2, 5.45736849474193790000e+000) (3, -3.12244810134641290000e+000) (4, 7.84672034483843910000e+000) (5, 6.07387626362999480000e-001) (6, -7.81141649242699820000e+000) (7, -3.43622457099355260000e+000) (8, -1.03462892817020190000e-001) (0, 4.96280293854012070000e-001) (1, 3.52563122340080650000e+000) (2, -2.04207181174056100000e+000) (3, -3.23772906725050010000e+000) (4, -2.25992018619151020000e-001) (5, -3.80538497097209040000e+000) (6, 2.72841814580680350000e-001) (7, -6.50051541633246300000e-001) (8, 5.63642369691433550000e-001) (0, -3.42937354332302210000e+000) (1, -8.67505795343127420000e+000) (2, -1.04752910262376910000e+001) (3, -8.12017284260051400000e+000) (4, 6.04464928475971330000e+000) (5, -5.64357724976089490000e-001) (6, 1.03744534461088320000e+001) (7, 2.80717459011671980000e+000) (8, 9.59298793471255880000e-002) (0, -6.35586228086894070000e+000) (1, -1.39371260530479600000e+001) (2, -2.28717596870808610000e+000) (3, -4.53355086599674540000e+000) (4, 9.13253768057172620000e+000) (5, 2.84323209770214240000e+000) (6, -8.99306195343582000000e+000) (7, 1.17760505010223650000e+001) (8, 2.05815115894053930000e-001) (0, 4.55013880024786770000e-001) (1, -1.04003788164673750000e+000) (2, 2.27205400862603260000e+000) (3, -1.23123262876396320000e+000) (4, 3.07414636718422550000e+000) (5, -5.86791208677000410000e-001) (6, -1.77274366304733650000e+000) (7, -3.67895066894798810000e+000) (8, 1.83769578058755770000e-001) (0, 6.51763573898991090000e-001) (1, -2.64910241386032250000e+000) (2, 1.99226033386854580000e+000) (3, -1.73934264232473000000e+000) (4, -5.17746098097988110000e-001) (5, 2.48515182430954470000e+000) (6, 2.93923441702384160000e+000) (7, 5.76376957663904400000e+000) (8, -4.23451192998511360000e-001) (9, -3.58068809630577520000e-001) (10, 1.33626686597393740000e+000) (11, -1.04697464859257240000e+000) (12, 1.58118113861294930000e-001) (13, -3.14645019724114090000e+000) (14, -1.46528460119112450000e+000) (15, 2.13086990013317600000e-001) (16, -4.13010192466966690000e-001) (17, 2.47219054547680010000e+000) (18, -2.58110900644221180000e+000) (19, 5.20502600670902930000e-001) (9, 5.78842099897992830000e-002) (10, -1.16628813846428230000e+000) (11, 1.30974154529846270000e+000) (12, 2.98210970830559380000e-002) (13, 2.69849169281786900000e+000) (14, 2.01729357660104820000e+000) (15, 1.52238017520027170000e-002) (16, 2.48654524866083910000e-001) (17, -9.17224900743059070000e-001) (18, 2.77635650766926960000e+000) (19, 7.43553185742762860000e-001) (9, 2.09127635225786700000e+000) (10, 8.93188835718335520000e-001) (11, 1.16778916467381650000e+000) (12, 6.79328789012236590000e-001) (13, 2.36874477894743940000e+000) (14, 1.39332806692699720000e+000) (15, 2.24058582160909840000e+000) (16, -8.61869288373909410000e-001) (17, -3.51334301848447210000e+000) (18, 1.23135622813857640000e+000) (19, 2.13343872943251240000e-001) (9, -7.34489263595733580000e-003) (10, -1.22850626024177450000e+000) (11, 1.18555971075273870000e+000) (12, -2.90987015674124440000e-001) (13, 6.63427014720052830000e-001) (14, 1.28161920371465650000e+000) (15, -7.77284488000786310000e-001) (16, 1.09410451469683760000e+000) (17, 3.06959068980259040000e+000) (18, 3.10672237112737640000e+000) (19, 7.11373074412864900000e-001) (9, 7.93136415056011620000e-001) (10, -9.10084870227497180000e-001) (11, 9.90789348188286120000e-001) (12, -3.58369271072390640000e-001) (13, 3.40375585191726060000e+000) (14, 1.24527753585038450000e+000) (15, -3.92170089695903780000e-001) (16, 1.06401626926850890000e+000) (17, -3.76717395059928740000e+000) (18, 2.56019429718749430000e+000) (19, 1.07278446881450450000e+000) 
