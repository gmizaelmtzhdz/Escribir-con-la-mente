FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.48457629139066860000e+000) (1, -3.45233922198058640000e+001) (2, -1.45757822797139800000e+001) (3, 5.71279506101245890000e+000) (4, 7.22658854060617270000e+001) (5, -6.23994492969688340000e+000) (6, -9.87685453146225360000e+000) (7, -1.01905038391406890000e+001) (8, 1.13438965313046050000e+000) (0, -5.10267480806979010000e+000) (1, -2.45333803299539280000e+001) (2, 2.64422809456127080000e+001) (3, -1.10735936886410880000e+001) (4, -1.51547815841189560000e+001) (5, 3.80117297365951360000e+001) (6, -2.94862080914967810000e+001) (7, -3.12847587104918570000e+001) (8, 4.36505717727047720000e-001) (0, 3.19470212021619560000e+000) (1, 1.13811978127963180000e+001) (2, 5.98581299369223530000e+000) (3, 1.92466763707263230000e+001) (4, -6.38957913123372520000e+001) (5, 2.55787019986504480000e+000) (6, -1.80197701946045650000e+001) (7, 5.81476843012041370000e+001) (8, -1.75749148349745640000e-001) (0, 4.98052461542466600000e+001) (1, -1.45979434381263160000e+002) (2, -2.61643809880363670000e+001) (3, -2.53671939585976130000e+002) (4, -9.92750987182600750000e+000) (5, 5.15688450576919190000e+002) (6, 1.39873346298070860000e+002) (7, 3.44131050086407190000e+002) (8, 1.15019174129408910000e+001) (0, -9.35602770931732160000e-001) (1, -6.22137403397890550000e-002) (2, 2.03751704973166130000e+000) (3, -7.16124895267737220000e+000) (4, 4.41639527042952020000e+000) (5, 3.64887139815676380000e+000) (6, 1.70455211999005350000e+000) (7, -5.81073462306876730000e+000) (8, 1.08993992082172850000e-001) (0, 1.10954144784867200000e+000) (1, -1.71596496418412310000e+001) (2, 3.26270840164750590000e+000) (3, 3.59888623366676750000e+000) (4, 1.17807899229124370000e+001) (5, 5.39181246550878330000e+000) (6, -2.06476150656012290000e+001) (7, 1.69529795782498870000e+000) (8, 7.98028623772561900000e-001) (0, 3.91803331634344170000e-001) (1, 1.51213220923531110000e+001) (2, -1.61538984443309770000e+001) (3, 1.25410015528694850000e+001) (4, -5.46960730275966520000e+000) (5, -8.83418222348046460000e+000) (6, 2.81337910278204670000e+000) (7, 3.58503865809512090000e+001) (8, 6.19261085101993900000e-002) (0, 6.47075947204214130000e-001) (1, 1.16512964285616820000e+000) (2, -6.77168260083832130000e-001) (3, -1.85369325152158380000e+000) (4, -2.80608617700590070000e+000) (5, 1.93996391392219400000e+000) (6, -5.96084004599351180000e-001) (7, 3.08856704517926860000e+000) (8, -4.74567442479483580000e-002) (0, -2.32197800303330610000e+000) (1, -3.42109715588698960000e-001) (2, 3.00381466540224210000e-002) (3, 4.47182279058789870000e+000) (4, 5.78525749049256090000e+000) (5, -4.97722516870409580000e+000) (6, 3.89516081859310680000e+000) (7, -4.30796461731490870000e+000) (8, 1.95602940490636170000e-001) (0, 4.52515907358036620000e+000) (1, 2.60475159441192660000e+000) (2, 1.58497419114908040000e+000) (3, 1.00014076846152180000e+001) (4, -2.29604934725905780000e+001) (5, -6.84333759734585460000e+000) (6, -2.38182137452812230000e+000) (7, 1.01204387745432700000e+001) (8, -5.13298386730523080000e-001) (9, 3.70245770737241080000e-001) (10, -1.24735135421999000000e-002) (11, 3.51026825352801000000e-001) (12, -9.95540151666740700000e-001) (13, -4.09220970970759160000e-001) (14, -5.50183990772391550000e-001) (15, -3.65666523148889420000e-001) (16, -5.56352299320811210000e-001) (17, -3.05894571729370680000e-001) (18, -5.02027513016241600000e-001) (19, 1.54437744280373270000e+000) (9, -2.72135510028596090000e-001) (10, 2.88072971348505510000e-001) (11, -3.66927596397199630000e-001) (12, 3.22599361201414910000e-001) (13, 1.05426616627411480000e+000) (14, 4.95553346522215170000e-001) (15, 7.84384200261702640000e-001) (16, 9.12419405495270900000e-001) (17, 3.29651330437128630000e-001) (18, 4.81270678255497690000e-001) (19, 4.21564678711081110000e-001) (9, -1.53808678745018690000e-001) (10, 5.71131685634492460000e-001) (11, -6.17842796429791230000e-001) (12, 4.77373864547700260000e-001) (13, 5.16988940417742350000e-001) (14, 1.18384161926373900000e-001) (15, 8.26937849485318900000e-001) (16, 1.30546506954486860000e+000) (17, 1.06200906346259470000e+000) (18, 1.06978875378793380000e+000) (19, 5.73865818384516560000e-001) (9, 3.63632351622813930000e-001) (10, 3.26771600899315780000e-001) (11, -1.48145310382980430000e-001) (12, -2.85763934122804320000e-001) (13, 3.42735065457367400000e+000) (14, 2.77461529885355720000e-001) (15, 9.71940546785602820000e-001) (16, 7.23782774793140020000e-001) (17, 1.19412284374843350000e+000) (18, 1.64334462962210440000e+000) (19, 1.03930114029372090000e+000) (9, -5.67491569832319520000e-001) (10, 1.15057881365396050000e-002) (11, -1.04151810743307390000e+000) (12, 1.52283413372762740000e-001) (13, 3.02835049759708360000e+000) (14, 2.02737441921917180000e+000) (15, 7.44291522105054120000e-001) (16, 1.18226485445003990000e+001) (17, 5.75501785109954160000e+000) (18, 2.54021497793248810000e+000) (19, 5.69821910682659750000e-001) 
