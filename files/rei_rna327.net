FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.86491486250743160000e-001) (1, -1.34332901801618140000e-001) (2, 1.11103937819816200000e+000) (3, -9.31396874210512090000e-001) (4, 1.98355225036209080000e+000) (5, -1.13056532717134140000e+000) (6, 1.25632834636019370000e+000) (7, -3.27989147269853510000e+000) (8, -2.07227309182445530000e-004) (0, -4.18896860836636180000e+000) (1, 4.03393368336842610000e+000) (2, -2.61326522590871860000e-001) (3, -8.61450524929166410000e+000) (4, -1.32218516762447680000e+001) (5, 9.10280572443391910000e+000) (6, -1.27369194515796890000e+000) (7, -1.50452326206087370000e+000) (8, 1.06340177812801830000e+000) (0, -1.99383366286002460000e+000) (1, 2.00846584691506490000e+000) (2, 4.24535846679942350000e+000) (3, -1.65353102401150530000e+000) (4, 1.33124699436966120000e+000) (5, -2.33160781848793070000e+000) (6, 6.93696425503492970000e+000) (7, -1.39074585435723040000e+001) (8, -2.51617832794604310000e-001) (0, 2.48892632504710850000e+000) (1, 1.09131364280611360000e+001) (2, 2.06977144638045020000e+000) (3, -3.25620674259920050000e+001) (4, -3.24063700655141810000e+000) (5, 1.12210148476902520000e+001) (6, 1.57680978832104280000e+001) (7, -1.03090302965987400000e+000) (8, 3.08596968471352980000e-001) (0, 8.88305781340843930000e-001) (1, 1.27607780153308670000e+000) (2, -3.13483450567719710000e+000) (3, -2.61704672755645480000e+000) (4, 4.88571532290397670000e+000) (5, 2.69698702335967110000e+000) (6, 2.98956121395660990000e+000) (7, 6.45146683064641110000e+000) (8, -1.03054868582266350000e-001) (0, -1.78599024100810840000e+001) (1, -5.44160783161050700000e+000) (2, 1.89438454273199070000e+001) (3, -3.38150923984933840000e+001) (4, -1.49926044075725040000e+001) (5, 6.78083271303456460000e+001) (6, -2.40202996389430620000e+001) (7, -4.06458611766878450000e+001) (8, -3.35157954408026540000e-001) (0, -8.16185791245859350000e+000) (1, 6.62135617048324310000e+000) (2, -1.60561336229704990000e+001) (3, -2.64368894596658000000e+001) (4, 2.46585071808038660000e+001) (5, 2.24348459234819440000e+001) (6, -8.12501232158019700000e+000) (7, 2.63404655328606870000e+001) (8, 1.90765975402759840000e+000) (0, 4.73547204988982620000e+000) (1, 7.45609131806653000000e-001) (2, -2.51470134044121170000e+000) (3, 3.07976425471211710000e+000) (4, -1.20706561496260320000e+001) (5, -8.96848942555285160000e+000) (6, 9.17934308259020250000e+000) (7, 3.56521002799119510000e+000) (8, 2.89910660249329510000e-002) (0, 1.85951349536743370000e+000) (1, -3.49301596438497610000e+000) (2, 4.11279433565357700000e+000) (3, -4.35184855040059930000e+000) (4, 4.93393180299396940000e+000) (5, 3.66345457452056430000e-001) (6, -1.06001260835546360000e+001) (7, -2.20823721075027860000e+000) (8, 7.13710825908439590000e-001) (0, -4.60815650261337420000e+000) (1, 2.55899791631890810000e-001) (2, -7.84520636293045910000e+000) (3, -1.10125531718555030000e+001) (4, 2.54410317004016080000e+000) (5, 1.71100412028174100000e+001) (6, -1.87296484439863810000e+001) (7, 2.33280820220499690000e+001) (8, 1.18958428769455330000e+000) (9, 2.29302476487428560000e+000) (10, -1.22388966569510190000e+000) (11, -1.34989012556856960000e+000) (12, 5.21550713568481150000e-001) (13, -3.09301924637981300000e+000) (14, 2.10881689518695320000e-001) (15, 4.15387161528025960000e-001) (16, -2.33702972863348600000e-001) (17, -1.61505860455262870000e+000) (18, -6.02245775059609620000e-002) (19, 1.11698501227839110000e+000) (9, 3.48137943217533660000e-001) (10, 1.02860535011881530000e+000) (11, 1.11768029610179580000e+000) (12, -5.83752359912536160000e-001) (13, 2.83680384898220920000e+000) (14, 2.80105808384747790000e-002) (15, -3.44727471644480750000e-001) (16, 5.31939866051285740000e-001) (17, 1.06081659787725550000e+000) (18, 3.98424545415867580000e-001) (19, 3.97643218963876390000e-001) (9, -4.23655909917865170000e+000) (10, 1.43465495044819480000e-001) (11, 2.29936273471820090000e+000) (12, -6.13366267324703670000e-001) (13, 1.95178370283600740000e+000) (14, 2.83813433230296730000e-001) (15, 3.01541108076725070000e-001) (16, 1.20638906176930030000e+000) (17, 1.37075669319475210000e+000) (18, -5.99484787173044860000e-002) (19, 8.25964983778815780000e-001) (9, 5.73886855191555070000e+000) (10, 8.16130717358184990000e-001) (11, 3.11586672617508720000e+000) (12, -1.00746257041673300000e+000) (13, 5.04746696690670400000e+000) (14, -1.08795110271158870000e-001) (15, -1.92035825490666760000e+000) (16, 1.56145721511371890000e+000) (17, 8.64330935615143850000e-001) (18, 3.00674913225059990000e+000) (19, 8.08394762061493300000e-001) (9, -7.14675874496615740000e+000) (10, -7.75229949516613610000e-001) (11, 6.05309656894883210000e+000) (12, -1.14529924786631710000e+000) (13, 4.40120930835294820000e+000) (14, 1.94977548220106710000e-001) (15, -2.01833330163743770000e-001) (16, 2.92206895293443660000e+000) (17, 3.10732669006082320000e+000) (18, 1.94951007997738830000e+000) (19, 6.48713047171971090000e-001) 
