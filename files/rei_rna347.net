FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -5.77276497738941700000e+000) (1, 2.93417999402178890000e+001) (2, -2.26777155926522460000e+000) (3, -6.53669002819885490000e+001) (4, -5.80697530365401700000e+000) (5, 2.21410203763072850000e+001) (6, 3.55686134912125450000e+001) (7, -3.07138434361285770000e+001) (8, -1.78428850683279010000e+000) (0, 4.28537774786782500000e+000) (1, -1.96180934255358860000e+001) (2, 3.49879840367417570000e+000) (3, 5.75708235304184870000e+001) (4, -8.25356622355261390000e+000) (5, -2.99935095935179770000e+001) (6, -1.67579036073391660000e+001) (7, 2.39345698811773070000e+001) (8, 1.98304882976853780000e+000) (0, 1.09069344335560960000e+001) (1, 3.78327074941841130000e+001) (2, -8.63785039628322340000e+000) (3, 5.11553638760900850000e+000) (4, 2.17939466659905820000e+001) (5, 1.56551737604922390000e+001) (6, -2.36703087990558920000e+001) (7, 4.73481599492699130000e-001) (8, -3.22408744141069860000e+000) (0, 2.93439167238501830000e-001) (1, -5.15309908682538610000e+000) (2, -1.95093538318004130000e+000) (3, -9.14277260239147440000e+000) (4, 7.35426173698108790000e+000) (5, 1.97692672555792870000e+001) (6, 1.36734764726693040000e+000) (7, 5.72224216242227170000e+000) (8, 6.45653249493145840000e-001) (0, -1.55070601619567610000e+000) (1, -1.86469987220856130000e+000) (2, -1.75105420893591020000e+000) (3, 1.54983534649251720000e+001) (4, -3.30396224306129030000e-001) (5, -8.48915808210557190000e+000) (6, -2.48104472760765570000e+000) (7, 3.04157205785421070000e+000) (8, 2.62284423928616620000e+000) (0, -6.36691271600185880000e+000) (1, 1.18033111675774160000e+001) (2, -7.27705824674791170000e-001) (3, 4.15582253021516830000e+001) (4, 2.31081068374046940000e+001) (5, -7.76841084135581210000e+001) (6, -5.06653672325984860000e+000) (7, 6.03300069420992550000e+000) (8, 2.32378285694640530000e-001) (0, 1.13719744077066860000e+001) (1, 3.70496935575682420000e+000) (2, 5.08885655752462180000e+000) (3, 1.01361927704497390000e+001) (4, -3.57753905365720610000e+001) (5, -9.40969613884044520000e+000) (6, -3.15665242994889850000e+000) (7, -3.05733553930374620000e+000) (8, -1.27727309639162320000e+000) (0, 4.95258652218798260000e+002) (1, 8.34117682994704380000e+001) (2, -1.18364221470758700000e+001) (3, -6.78512734404991700000e+001) (4, -1.63266682552116260000e+001) (5, -8.50380545215853800000e+001) (6, -2.57910017308059240000e+001) (7, -4.59178523273916730000e+000) (8, 3.15296241242678650000e+000) (0, -7.30590306485919600000e+000) (1, -5.20476270111597690000e-001) (2, 5.48528519096212720000e+000) (3, 3.88683353333607900000e+001) (4, 1.60344629317084150000e+001) (5, -1.08053684589992630000e+002) (6, 2.89244033390632820000e+001) (7, 1.01468255411957010000e+001) (8, 8.97852401226843510000e-001) (0, 2.04457412425805350000e+000) (1, -1.60944300400871970000e+001) (2, -9.22529642134253150000e-001) (3, 2.96942065144037420000e+001) (4, 2.21976308818971060000e+000) (5, -1.50618845647346490000e+001) (6, 2.88254757926729030000e+000) (7, 2.86090412498316980000e+001) (8, 2.47982245007135750000e+000) (9, -8.51757568792754770000e-001) (10, -9.20089143059227400000e-001) (11, 4.21341360772014170000e-001) (12, -1.23750949605311460000e+000) (13, 8.69095339954319870000e-001) (14, -9.91632185398636960000e-001) (15, -3.80191878968413830000e-001) (16, -3.71138500828302300000e-001) (17, 6.78708352925555090000e-001) (18, -4.08151155424044450000e-001) (19, 1.05900576748897480000e+000) (9, 7.34172463888661420000e-001) (10, 7.45599597529209010000e-001) (11, -3.76129199055587670000e-001) (12, 8.06811958230744810000e-001) (13, -1.13438840897763750000e+000) (14, 8.96481704796538880000e-001) (15, 1.66274872793454880000e-001) (16, 1.10332614065743640000e-001) (17, -6.65023245072691500000e-001) (18, 2.91082211130365480000e-001) (19, 1.03497802472334840000e+000) (9, 6.19190301190073570000e-001) (10, 4.84347050133883460000e-001) (11, -2.94186857476616990000e-001) (12, 1.03084011680585790000e+000) (13, 9.12933761047585060000e-001) (14, 5.85965812050937670000e-001) (15, 3.36860501273731900000e-001) (16, 6.39342875256305320000e-002) (17, -3.90470190172431900000e-001) (18, -3.90060810400380650000e-001) (19, 2.36182520345610770000e-001) (9, -1.67050660413909120000e-001) (10, -1.05970620220328130000e+000) (11, -3.99572262691703650000e-001) (12, 1.99387994139607310000e-001) (13, -1.33462206126423970000e+000) (14, 8.93593012138698460000e-001) (15, 4.54895822851931200000e-001) (16, 1.18808755270561480000e-001) (17, -5.71708468292368430000e-001) (18, 2.24354572505462890000e+000) (19, 7.36537795447353870000e-001) (9, -7.60814995667436710000e-001) (10, -1.30511791708697780000e+000) (11, -2.84706742565835780000e-001) (12, 2.12525039825782880000e+000) (13, 1.65367203819263090000e+000) (14, 5.23658071753462570000e-001) (15, 8.82220985457144670000e-001) (16, 2.30336095983063280000e-002) (17, 1.19692172412622520000e-001) (18, -1.44643968270503610000e+000) (19, 7.45693581379503030000e-001) 
