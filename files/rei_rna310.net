FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.98450345614947990000e-001) (1, -2.55503560419643620000e-002) (2, 1.12909100865603730000e+000) (3, -1.45534948238224900000e+000) (4, -1.27387099851537840000e+000) (5, 1.58657360383996430000e+000) (6, 1.58366600539984950000e+000) (7, 4.20792461847178690000e+000) (8, 1.12297676259602640000e-001) (0, 3.30094072586233290000e-002) (1, -1.64665104466924640000e+001) (2, 3.24330764598038670000e+000) (3, 4.07569826597409970000e+000) (4, -2.38542212301200870000e+000) (5, 7.33883699658208140000e+000) (6, -5.99458343163997580000e+000) (7, 7.38013318801490750000e+000) (8, 2.79851826163083630000e-002) (0, -7.18239733157274160000e+000) (1, -1.51738193782473210000e+001) (2, -1.49892701014210820000e+000) (3, -1.08641091461503270000e+001) (4, -8.32808838954206720000e+000) (5, 2.16472751042982100000e+001) (6, 2.08152744428904680000e+000) (7, 5.00456053895866580000e+000) (8, 1.59261365379023020000e+000) (0, -4.39562128989963340000e+000) (1, 9.38773160105678170000e+000) (2, -6.61390826742728950000e+000) (3, -9.12370955134319320000e+000) (4, 4.41157103911653080000e+000) (5, -3.51557034287949400000e+000) (6, 5.42214427058058760000e+000) (7, -5.04901549658419930000e+000) (8, 5.25528905752047030000e-001) (0, -1.25096218805319600000e+000) (1, -3.42990274530345120000e+000) (2, -1.07652522932885520000e+000) (3, -5.02984263329467750000e+000) (4, 1.59645219672137220000e+001) (5, 7.31267941005045550000e-001) (6, 1.06169558697782040000e+000) (7, -1.30629615448270880000e+001) (8, -4.25503995536269940000e-002) (0, -9.37187801005181200000e-003) (1, 1.30308406015443730000e+001) (2, 1.86524909690994220000e+000) (3, -2.04078884643003030000e+001) (4, -2.87662658307079950000e+000) (5, 6.53772208408269600000e+000) (6, 1.33778170426932470000e+001) (7, -8.82832689507267960000e+000) (8, 5.75426301477006800000e-001) (0, 4.69725305779347570000e+000) (1, 4.46177402675737300000e-001) (2, 2.05731531345668420000e+000) (3, 8.89042005128985120000e+000) (4, -1.68505649729218940000e+001) (5, -6.48060323503605320000e+000) (6, -2.01514349601463700000e+000) (7, 3.54168262812432790000e+000) (8, -5.09807703687565010000e-001) (0, -1.89462110617733240000e-002) (1, -9.61913709025437600000e-001) (2, 2.66062533776275590000e-001) (3, -3.84994021649646800000e+000) (4, 7.07695336418962920000e+000) (5, 1.51428654760903990000e+000) (6, 6.61869004879232610000e-001) (7, -6.45801566111140520000e+000) (8, 1.04247816282356230000e-001) (0, -1.86537583758050910000e-001) (1, 2.61044174731725750000e-001) (2, 5.12808479088229570000e-001) (3, 1.58083532868563160000e+000) (4, 1.29462192113979960000e+000) (5, -1.42014376619005640000e+000) (6, 1.87716866447466880000e+000) (7, -4.15514291245186850000e-001) (8, 1.19069274072390610000e-001) (0, -5.02919485198469850000e-001) (1, 1.11833171042390990000e+000) (2, 3.12138757736429540000e+000) (3, -8.66066563458618250000e+000) (4, 6.75407784856985940000e+000) (5, 1.21326788320171400000e+001) (6, 2.05392604249373530000e+000) (7, -3.03408016052377370000e+000) (8, 6.47736217096550270000e-001) (9, -4.03297498012211530000e+000) (10, 1.91504011586618650000e+000) (11, -7.13673811824952930000e-001) (12, 2.96071575303796850000e-001) (13, -1.80786105187780890000e+000) (14, 1.27303512962421350000e+000) (15, -1.53858573689491030000e+000) (16, 1.19343721587502410000e-001) (17, 3.51393917975840340000e+000) (18, -8.75378043353035150000e-001) (19, 4.72821389090020970000e-001) (9, 2.70733800174532040000e+000) (10, -1.49378258135427950000e+000) (11, 5.73915720435285160000e-001) (12, -1.65274635110442690000e-001) (13, 2.95709154823854290000e-001) (14, -1.11984628305331580000e+000) (15, 6.40381013528012470000e-001) (16, 1.09102013927878420000e+000) (17, -3.04540484026663410000e+000) (18, 6.87858921928077400000e-001) (19, 7.53001576238298550000e-001) (9, 2.01417185489976800000e+000) (10, -1.18612186092547380000e+000) (11, 6.71376029360784440000e-001) (12, 4.33050373262773960000e-001) (13, 2.75320543451397490000e+000) (14, -1.02817207564775860000e+000) (15, 2.17340194720287580000e+000) (16, -3.01307868133151620000e+000) (17, -8.50417895527981530000e-001) (18, 2.25100448571665760000e+000) (19, 7.01904670795995500000e-001) (9, 4.03564507840483520000e+000) (10, -1.62168231192641990000e+000) (11, 8.42753371074479670000e-001) (12, 2.47982582503701450000e-001) (13, -6.05879839202549840000e-001) (14, -1.58769614621174290000e+000) (15, 1.56807740436069780000e+000) (16, 4.85138828941396040000e+000) (17, -1.14267225727991480000e+000) (18, 1.96419097179319160000e-001) (19, 8.23870423002127870000e-001) (9, 5.08116756953098480000e+000) (10, -2.86662867325721990000e-001) (11, -1.58440458652884890000e-001) (12, 1.50707684059464800000e+000) (13, 2.19648464207116720000e+000) (14, -1.54658253978235090000e+000) (15, 2.30410242024338000000e+000) (16, -1.92093550534731820000e-001) (17, -2.95341266411391600000e+000) (18, 1.55498379523015080000e+000) (19, 1.27461823848761610000e+000) 
