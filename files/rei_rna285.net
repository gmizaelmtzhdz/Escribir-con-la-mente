FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -7.82205841425681390000e-001) (1, 1.05632050048091910000e+001) (2, -1.79886769311754380000e+000) (3, -4.80529046543469640000e+000) (4, -1.20922152007197390000e-001) (5, -5.08106600521820080000e+000) (6, 5.26821880254301610000e+000) (7, -6.09573946391322340000e+000) (8, 9.02004600316062780000e-001) (0, 9.20935885737524500000e-001) (1, -2.87821018136857230000e+000) (2, 2.95963695597796280000e-001) (3, -2.66986584484691440000e+000) (4, 6.49616291511423420000e+000) (5, 1.24650006379688570000e-001) (6, 2.11242501276789030000e+000) (7, -1.09641141777191890000e+001) (8, -1.11760067317497980000e-001) (0, 8.48323106732342500000e+000) (1, -4.55818662267375350000e+000) (2, 1.13696112689788410000e+000) (3, 1.36334752604011930000e+001) (4, 1.57257215278463640000e+001) (5, -3.90981083473258830000e+001) (6, 3.04588579350719510000e+001) (7, -1.52236422269031400000e+001) (8, 3.79862825157985140000e-001) (0, 2.74167391114585750000e+000) (1, 8.08462298954963290000e+000) (2, -1.08627969802782530000e+001) (3, 1.15177322981696190000e+001) (4, -1.16498550989007670000e+001) (5, -1.40220168283542550000e+001) (6, 5.95157500135283350000e+000) (7, 3.64032400659590750000e+001) (8, 8.74805479189316950000e-001) (0, 3.84775732389627830000e+000) (1, 1.96791808863093930000e+001) (2, -2.08914258531402950000e+000) (3, -4.78302061976340060000e+001) (4, -4.93722114079882330000e+000) (5, 2.09228947903004680000e+001) (6, 4.34763552222792600000e+001) (7, -3.02235677179641020000e+001) (8, 1.46373178331367290000e-001) (0, 7.77457290600253700000e+000) (1, -3.41883965499513520000e+000) (2, -3.80438766520026080000e+000) (3, 3.97742202323097020000e+001) (4, -4.05105151139483600000e+000) (5, -4.65782679456416700000e+001) (6, 1.83957799049563310000e+001) (7, 3.52423298443368860000e+001) (8, 2.43547693422177890000e-001) (0, 9.30891855782082890000e-001) (1, -3.05819521168413510000e+000) (2, -2.42155505246032620000e-002) (3, -6.29553328928764030000e-001) (4, 8.35365192425126320000e+000) (5, -3.37728508774485100000e+000) (6, 3.19988634154445470000e+000) (7, -8.65786854101215120000e+000) (8, 5.77171780019929860000e-001) (0, 1.54977597020618310000e+000) (1, -6.44259348396732710000e+000) (2, -4.92121933611551650000e-001) (3, 8.74201781704082850000e+000) (4, 7.18958924106849250000e-001) (5, -3.94166060850713680000e+000) (6, 2.16200583003784800000e+000) (7, -2.03013739269746550000e+000) (8, -9.66871762637797890000e-002) (0, 6.27711844491577690000e-001) (1, -5.80172501598850050000e+000) (2, 3.13449236905059210000e+000) (3, 2.50577671460700470000e+000) (4, -2.19684508635835570000e+000) (5, 4.00254483298091920000e+000) (6, 1.48185480922300710000e+000) (7, 5.70708101558685590000e+000) (8, 2.71310540008261320000e-001) (0, -1.94500737533669870000e-001) (1, -3.08495584470662590000e+000) (2, 5.32868216882490130000e+000) (3, -2.87961000725564990000e+001) (4, 1.60955853052242940000e+001) (5, 3.31162846112463000000e+001) (6, 6.01262776642149000000e+000) (7, -6.16458281299957460000e+000) (8, 1.87387085193674640000e+000) (9, -3.66496987928881580000e-001) (10, -3.20991084145477010000e+000) (11, -5.14712797307448230000e-001) (12, -5.97357957806149750000e-001) (13, 3.92385542566433990000e-001) (14, 2.45557750550326050000e-001) (15, 3.43841213720082140000e+000) (16, 1.76402180403256140000e-002) (17, -9.73201529973738290000e-002) (18, -7.10084424164420410000e-001) (19, 4.50299504651113620000e-001) (9, 7.21115519859672150000e-001) (10, 2.21584850026374940000e+000) (11, 2.51611837891533020000e-001) (12, 8.16610232251524740000e-001) (13, -3.94005367775696500000e-001) (14, -5.09037245933164460000e-001) (15, -1.54186853722897580000e+000) (16, -5.92602086221153290000e-001) (17, 9.65269196525663230000e-001) (18, 2.52720438364461450000e-001) (19, 4.85963693323543330000e-001) (9, 1.30139980485654850000e+000) (10, 5.75282699868980060000e-001) (11, 5.18621654671143410000e-001) (12, 1.50990174908449790000e-001) (13, -3.69358295540158700000e-001) (14, -5.96200560455134590000e-001) (15, -2.61133667640470610000e+000) (16, 1.88351735971679310000e+000) (17, -2.96587673264106620000e-001) (18, 1.16534637253854160000e+000) (19, 4.62501011207645700000e-001) (9, 6.90156657480888610000e-001) (10, 4.47399332565745310000e+000) (11, 6.56957632751463460000e-001) (12, 1.51263055405719800000e+000) (13, -5.90231643326280090000e-001) (14, -7.94951008633312030000e-001) (15, -2.02048502464954760000e+000) (16, -2.13470523269817880000e+000) (17, 2.58613896248200610000e+000) (18, -6.12425228967173000000e-001) (19, 9.31192123721764960000e-001) (9, -5.65932674105240170000e-001) (10, 2.65991952158275380000e+000) (11, 1.70827180151845950000e+000) (12, 1.52187920082816830000e+000) (13, -7.57131816334809640000e-001) (14, -1.45288871633444460000e+000) (15, -3.02555949579946050000e+000) (16, -9.55211255902284170000e-001) (17, 1.06659884068943810000e-001) (18, 7.50082570071175960000e-001) (19, 1.01235085257360250000e+000) 
