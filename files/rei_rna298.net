FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 9.50488015542980790000e-001) (1, -2.45005845242582820000e+000) (2, 1.29606837257244520000e+001) (3, 3.27865011559672720000e+001) (4, -5.65747330178149070000e+001) (5, -1.50516121578331600000e+001) (6, -9.63049460309903970000e+000) (7, 7.71404208238306670000e+000) (8, 3.74978338609297360000e-001) (0, 1.31985975241455660000e+000) (1, 2.28635468421500970000e+001) (2, 9.38966248633303020000e+000) (3, -3.81977298423080640000e+001) (4, -4.00987556366014740000e+001) (5, 1.34937497531203580000e+001) (6, -1.49285434267880390000e+001) (7, 3.40396373076260160000e+001) (8, 6.91581575003541340000e-001) (0, 7.53017236934637180000e-001) (1, 1.18217821081671580000e+001) (2, -4.57910678773683700000e+000) (3, -1.25690979216212970000e+000) (4, 2.60981611856093250000e-001) (5, -1.23989629559013340000e+001) (6, 6.11595060985644960000e+000) (7, -6.81740451165722240000e-001) (8, 1.01179928040914760000e+000) (0, 3.33828230384577470000e+000) (1, -4.52142416384067050000e+000) (2, -1.90034955620500460000e+000) (3, 2.11678782157781990000e-001) (4, 3.54786764589165600000e+001) (5, -1.12775680249030880000e+001) (6, 1.96983092094634320000e+001) (7, -3.59770845378292920000e+001) (8, -2.29622949314183670000e-001) (0, -1.62407723774583430000e+000) (1, -7.56729725320385160000e+000) (2, -9.09195883780978420000e+000) (3, 5.60484989772766880000e+000) (4, 4.58759366552775210000e+001) (5, -8.65894163493559970000e-001) (6, 1.01397886430688630000e+001) (7, -1.60592793828062630000e+001) (8, -2.17203270368031080000e-001) (0, 1.22635174074653470000e+001) (1, 8.10622465456459550000e+000) (2, -9.58834940385622580000e+000) (3, 7.82581125487856880000e+000) (4, 2.38817523284509400000e+001) (5, -3.92480148254822440000e+001) (6, 2.87617853347732470000e+001) (7, -1.55787392088208080000e+001) (8, 3.84309616488921340000e-002) (0, 1.26794799715916100000e+000) (1, 3.37645665458481890000e+000) (2, 5.21471321938712710000e-001) (3, 3.05750919356132080000e+000) (4, -7.16430254073420420000e+000) (5, -8.94283359068955620000e-001) (6, -6.47905817818854920000e-001) (7, 4.11357171523817920000e+000) (8, -1.93512577802560070000e-001) (0, 7.58616234519766050000e+000) (1, -1.04128269050695540000e+001) (2, 2.02444754508149350000e+001) (3, -1.32282874330654660000e+001) (4, 3.23253579929646830000e+001) (5, -1.19045271116625690000e+001) (6, 1.70899844474404790000e+001) (7, -6.89339828307697220000e+001) (8, 8.15915857998808060000e-001) (0, 5.63988017688861980000e-001) (1, -2.52104335960755140000e+000) (2, 1.40378591577940990000e+000) (3, -3.54686479085197750000e+000) (4, 5.35845461632244820000e+000) (5, 3.10909502273295410000e+000) (6, 2.89966088876410840000e+000) (7, -8.60985074862139040000e+000) (8, 6.19230328828615680000e-003) (0, 1.06322219468492880000e+001) (1, 1.44247445586959220000e+001) (2, 9.20349857667873290000e+000) (3, 2.74201960285233910000e+000) (4, -1.01098190354599740000e+001) (5, -2.14765463191324740000e+001) (6, 2.20568934996490570000e+001) (7, -3.21207319172108970000e+001) (8, 1.41380582632991520000e-001) (9, 3.05656267933364700000e-001) (10, 4.00307791230860800000e-001) (11, -2.44152683521646350000e-001) (12, 1.02632260093738470000e+000) (13, 2.73350149516520370000e-001) (14, -3.53171136020384300000e-001) (15, -7.02820213542782240000e-001) (16, -3.77061315884751840000e-001) (17, -8.22998118956476790000e-001) (18, 1.87682166112179190000e-001) (19, 7.25840893506568660000e-001) (9, -3.39594040725838710000e-001) (10, -3.96222825447013370000e-001) (11, 6.42693406472549130000e-001) (12, -9.21243816263555340000e-001) (13, -1.89937692143631260000e-001) (14, -3.51956930645045480000e-002) (15, 5.99836712074337750000e-001) (16, 2.29917837575305120000e-001) (17, 1.08917090642182470000e+000) (18, -4.59505157782831710000e-002) (19, 5.98536659527984850000e-001) (9, -9.52462420184156610000e-001) (10, -1.02282896186990340000e+000) (11, 1.01976379263951690000e-001) (12, -6.76047669903418690000e-001) (13, -1.09900202729012110000e+000) (14, -5.27407589967535560000e-001) (15, 3.73965044142899160000e-001) (16, 2.06632680121650370000e-001) (17, -9.42469006308570000000e-001) (18, 6.21681046734799850000e-001) (19, 1.18034702865286060000e+000) (9, 9.16681305357325280000e-001) (10, 5.32885677928989670000e-001) (11, 1.22427387935064940000e+000) (12, -1.68399117980012920000e+000) (13, 1.77356735701349270000e+000) (14, 8.49092879634004930000e-001) (15, 1.91461996379169450000e+000) (16, 6.60898507448670620000e-001) (17, 3.95548449668368460000e+000) (18, -1.08171213236368600000e+000) (19, 9.47788188220518720000e-002) (9, -3.05236959759583450000e-002) (10, -8.13032429911441510000e-002) (11, 1.36318123179475170000e-001) (12, -1.18403031361832340000e+000) (13, 4.35208686059501250000e-001) (14, 6.89194420888344370000e-001) (15, 1.19714222006895680000e+000) (16, 8.31098512248944600000e-001) (17, 1.16805180198184270000e-001) (18, -7.29991594276337090000e-001) (19, 7.62773609169498990000e-001) 
