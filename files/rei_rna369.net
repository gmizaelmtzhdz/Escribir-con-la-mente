FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.36708340447779030000e+001) (1, -7.20675925615598910000e+001) (2, 6.99623874092761330000e+001) (3, 2.62556210819076060000e+001) (4, -9.11789856889234190000e+001) (5, -8.68466655646783610000e+001) (6, 6.60833895834902880000e+001) (7, -5.35067468503274100000e+001) (8, 6.12962955375165030000e+000) (0, 7.83080603445314960000e+000) (1, 4.83262525355820000000e+001) (2, -5.19458168072396160000e+001) (3, -2.87507173706916180000e+001) (4, 5.63631955763780180000e+001) (5, 7.55752266339452350000e+001) (6, -3.17811971701452900000e+001) (7, 1.83311259603718960000e+001) (8, -4.19834053327053610000e+000) (0, -1.12758321135831290000e+000) (1, -2.50810898622093560000e+000) (2, 2.20553668359434370000e+000) (3, 8.01035014551279190000e+000) (4, -4.35417306855886380000e+000) (5, -3.84645164282775420000e+000) (6, 7.38412628168178820000e-002) (7, -1.16757729163795760000e+000) (8, 1.09962528982789530000e+000) (0, 5.94768043621691160000e+002) (1, -2.29020849622006300000e+002) (2, 2.37841832603372920000e+002) (3, 6.98319450088028330000e+001) (4, 5.49396348864395800000e+002) (5, -1.50000000000000000000e+003) (6, 1.09501473244422100000e+003) (7, -1.28108791311691450000e+003) (8, 2.21659646893387960000e+001) (0, 6.42289459677049020000e+000) (1, -1.01281803345333960000e+002) (2, 2.85873967047541610000e+002) (3, -1.11524751950422630000e+002) (4, -1.31740646999197590000e+002) (5, 6.24337862074323990000e+002) (6, -1.83891481465983840000e+002) (7, -2.02914450406173330000e+002) (8, 2.04617331599647340000e+001) (0, 1.50000000000000000000e+003) (1, -6.70366479590831890000e+002) (2, -5.81464286636576050000e+002) (3, -7.10683930655085870000e+002) (4, 1.50000000000000000000e+003) (5, 1.49844217146793810000e+003) (6, 9.39119621975670380000e+002) (7, -1.50000000000000000000e+003) (8, 7.46945082645472100000e+001) (0, 2.25422706038609990000e+001) (1, -7.42497554674683470000e+001) (2, -6.49400928024207240000e+000) (3, -1.09599350575873390000e+002) (4, 7.50442657427575990000e+000) (5, 1.95585179150605310000e+002) (6, 5.20677484356779130000e+001) (7, 1.22503199279183630000e+002) (8, 6.69384380945872430000e+000) (0, 9.14428723701180960000e+001) (1, -4.46926915580967940000e+002) (2, 2.60706487097671920000e+002) (3, -2.74574804362668660000e+002) (4, -1.55109197106544340000e+002) (5, 1.50000000000000000000e+003) (6, -4.07538898159290230000e+002) (7, 4.19009493754532660000e+001) (8, 2.83098187887530590000e+001) (0, 1.58753261780090020000e+000) (1, 9.51285136914957800000e+000) (2, 8.58896775580941170000e+000) (3, -5.67103419971650380000e+001) (4, -7.00488897802425560000e+000) (5, 1.65056593562893820000e+001) (6, 9.08270726439264140000e+001) (7, -8.32762005014228070000e+001) (8, 2.20949992870897740000e+000) (0, -2.00595853718587110000e+002) (1, 1.50000000000000000000e+003) (2, -2.89124246360170050000e+002) (3, 1.04006214449348160000e+003) (4, -6.78190366665492430000e+002) (5, 6.75293017868536250000e+002) (6, -1.43482725772409640000e+003) (7, 1.50000000000000000000e+003) (8, 1.42474863232863160000e+002) (9, -2.96983575700405570000e-001) (10, -3.19610488057144590000e-001) (11, 4.43156694701762330000e-001) (12, -1.07952785334117530000e-001) (13, -8.77516945189674050000e-001) (14, 1.60945579393768190000e+000) (15, -1.28334816713799600000e+000) (16, 4.83344049368450930000e-001) (17, 2.33252407527252510000e-001) (18, -2.72611132689888460000e-001) (19, 6.27987929158719370000e-001) (9, 4.24742397124520050000e-001) (10, 4.10569086540555240000e-001) (11, -3.61951458971526310000e-001) (12, -4.39697437312571140000e-003) (13, 5.37731045904929480000e-001) (14, -1.82047709197810900000e+000) (15, 7.96759460722441530000e-001) (16, -4.57988441578490500000e-001) (17, -1.44513511108335210000e-001) (18, 4.62165091542254770000e-001) (19, 1.55800416974754150000e+000) (9, 6.45624355945903170000e-001) (10, 8.36954806078840320000e-001) (11, 1.00167394791682880000e+000) (12, 6.18880765558109320000e-002) (13, 1.01516905776205290000e-001) (14, -2.19276144016507990000e+000) (15, 9.92714105711928970000e-001) (16, -4.65517531371479940000e-001) (17, -9.72576070426556110000e-002) (18, 2.20734548739841100000e-002) (19, 2.18383802546997560000e+000) (9, 2.23119317103590090000e-001) (10, 9.87921962497645690000e-002) (11, -1.17529148606170700000e+000) (12, 9.84927847173940050000e-002) (13, 7.53829540942218660000e-001) (14, -1.35669317147293200000e+000) (15, 3.12925508370089090000e-002) (16, -1.48861307879728040000e-001) (17, -3.06392113493300760000e-001) (18, -1.88223919891246360000e+000) (19, 4.21097629863111320000e+000) (9, 5.53112451013984650000e-001) (10, 5.69206981062720720000e-001) (11, -4.62288699407269740000e-001) (12, 1.28721618303688530000e-001) (13, 2.17298161114514280000e-001) (14, 2.01962948829711390000e-001) (15, 3.00424536908023400000e-001) (16, 9.42806782567076050000e-004) (17, -3.51152488705774200000e-001) (18, 8.04601673222289510000e-002) (19, 6.26447772666467450000e-001) 
