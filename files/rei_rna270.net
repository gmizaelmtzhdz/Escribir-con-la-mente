FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.68134529110057100000e-001) (1, 6.50036935475792710000e+000) (2, -1.25528844048376250000e+001) (3, 1.44088470914165030000e+001) (4, -4.19384346808447890000e+000) (5, -2.70611832876268150000e+000) (6, 6.02095015250971750000e-001) (7, 3.00889007168637440000e+001) (8, -8.04089165128583220000e-002) (0, -6.31905099329080340000e-001) (1, -7.57736316286044990000e-001) (2, -4.40383534149102140000e-001) (3, 2.65400089456679830000e+000) (4, -9.55657864657984410000e-001) (5, 9.62092019790199980000e-001) (6, 1.75585501189415870000e+000) (7, 7.74520453541939320000e-001) (8, -3.69487154425387490000e-002) (0, 2.34197497461005580000e+000) (1, -3.60600104325704330000e+000) (2, 7.91243854175217700000e-001) (3, -5.64026394429831960000e+000) (4, 8.12903957595289480000e+000) (5, 6.86648025388025470000e+000) (6, 7.12142805830066640000e+000) (7, -2.36396285664985540000e+000) (8, 2.12706589985378950000e-001) (0, 7.97225197950881800000e+000) (1, 1.25045205934678360000e+000) (2, 7.10069052793526550000e+000) (3, -8.84098864512652050000e+000) (4, 1.43235201855881190000e+001) (5, -5.32317512048418280000e+001) (6, 2.19236051369712860000e+001) (7, -1.73375648864663670000e+001) (8, -5.02838578508778110000e-001) (0, -7.42300438232962430000e-001) (1, -8.25241446677897810000e+000) (2, 4.69077632030486670000e+000) (3, -2.91857297527866160000e+000) (4, 8.57626764336239940000e+000) (5, -1.21646659809167570000e+001) (6, -1.29325276845759160000e+001) (7, -3.48080454787094170000e+001) (8, 3.69489406767320390000e-001) (0, 2.73033564778445200000e+000) (1, 9.51018736647921580000e-001) (2, 7.99546150492756350000e-001) (3, -5.10364855492509490000e+000) (4, -4.15493076710218290000e-001) (5, 1.30641041966548730000e+000) (6, -1.22658072671508900000e+001) (7, 3.87826434529056300000e+000) (8, 4.38845641640776440000e-001) (0, -3.72329743566299820000e+000) (1, -5.27321337942346260000e+000) (2, 4.44701529791139360000e-001) (3, 2.29250331361647820000e+001) (4, -4.85423940940984980000e+000) (5, -2.58026645583452880000e+001) (6, 1.35007079748067760000e+001) (7, 2.13492533855202500000e+000) (8, -2.72109697408008250000e-002) (0, -1.01119400867225950000e+000) (1, -4.98306808506904900000e-001) (2, 1.03157577366283450000e+001) (3, -1.52025582623659880000e+001) (4, 4.62127187450769840000e+000) (5, -2.37813960525998520000e+000) (6, 1.15717187492796130000e+001) (7, -2.70423264362949920000e+001) (8, -1.19387008706164090000e-001) (0, 3.39952679313385350000e+000) (1, -8.37576689075842750000e+000) (2, 2.80412990700264950000e+000) (3, 1.49675580579585880000e+001) (4, -6.27207931091075110000e+000) (5, -9.76277632719482110000e+000) (6, -5.55964042236667840000e+000) (7, 1.01468383007346060000e+001) (8, 8.39620303356682810000e-001) (0, -1.15150009182187610000e+000) (1, -3.48158527613283750000e-001) (2, -1.79380859879111320000e+000) (3, 1.71297684018978630000e+001) (4, -7.60476738627725530000e+000) (5, -3.42090825555333420000e+001) (6, -1.38947231751861170000e+001) (7, 3.26205687909378740000e+000) (8, 3.56690770631935550000e-001) (9, -1.93836972647630070000e+000) (10, -1.35014977406629730000e+000) (11, -3.71453019402498250000e-001) (12, 3.80958040716990190000e-001) (13, -6.90844755833614270000e-001) (14, -1.33574291774323610000e+000) (15, -4.68071033651006470000e-002) (16, -1.92351760004412390000e+000) (17, -5.57815699207109720000e-001) (18, 9.95341180636633150000e-002) (19, 1.07479502953262120000e+000) (9, 1.71302228286632310000e+000) (10, -4.00389473392377020000e-001) (11, 3.89187374395386810000e-001) (12, -5.16118894153347440000e-001) (13, 6.51607221411014240000e-001) (14, 9.90920684618078030000e-001) (15, 2.11874697584514240000e-001) (16, 1.61774755564088200000e+000) (17, 2.70040314978908070000e-001) (18, -1.50623348146070280000e-001) (19, 4.44691992507480760000e-001) (9, 1.58815889091439180000e+000) (10, 3.11805308197048790000e+000) (11, -8.46192380423496200000e-001) (12, -6.39511283477675880000e-002) (13, 1.01812758683619900000e+000) (14, 1.62387679542458050000e+000) (15, 3.99905876754516280000e-001) (16, 1.30518627388772490000e+000) (17, 2.44771582619840440000e-001) (18, -1.05782934395761010000e+000) (19, 8.35730241958199450000e-001) (9, 9.53434807188016210000e-001) (10, -2.18984133524919230000e+000) (11, 2.59332379601218890000e+000) (12, -7.46815329297198180000e-001) (13, -3.35035168733309070000e-001) (14, 3.72062313295280280000e-001) (15, 4.33876974011601290000e-002) (16, 1.44842630718914940000e+000) (17, 1.20066459326656200000e-001) (18, 1.58957487320614830000e+000) (19, 3.64646836335636830000e-001) (9, 8.91155415529972130000e-001) (10, 7.34543003583038260000e+000) (11, 2.05862974673133920000e+000) (12, -1.48957984578124060000e-001) (13, 5.43645682071622780000e-001) (14, 5.58278251491878220000e+000) (15, 2.12514764148949280000e+000) (16, 8.36049557895301890000e-001) (17, -1.96257597032664390000e+000) (18, -9.82941316241170150000e-002) (19, 6.67031193559021410000e-001) 
