FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.54023888369217850000e+000) (1, 2.81366012099837400000e+000) (2, -1.22555995528592710000e+000) (3, 1.40366417582473610000e+001) (4, -8.29104200595427270000e+000) (5, -1.12200393125064540000e+001) (6, 7.11701361576443590000e-001) (7, 5.18241388748119860000e+001) (8, -1.06910821311444430000e+000) (0, 7.55940902638299850000e+000) (1, -1.60674832434439630000e+001) (2, 7.74869507977424820000e+000) (3, 3.90671263613315460000e+001) (4, -2.79717974566868700000e-001) (5, -3.99769888489209180000e+001) (6, 1.21488482479460520000e+001) (7, -1.47193006024466500000e-001) (8, -5.70355612183566120000e-001) (0, 4.73243797460700040000e+000) (1, -4.58287330474307630000e+000) (2, 2.95928282321359460000e+000) (3, 1.54257172947346040000e+001) (4, -2.01964476457489790000e+001) (5, -1.86247380535811220000e+001) (6, 3.08080414960121730000e+000) (7, -2.69551877062223040000e+001) (8, 7.13644862739265810000e-002) (0, -8.79086171079105250000e-001) (1, -8.75074461680914690000e+000) (2, 5.21779248265138220000e+000) (3, 1.77120635506144450000e+000) (4, 1.76889009294838260000e+000) (5, -8.16243081884358230000e-001) (6, 2.83862239377563120000e+000) (7, -3.91130297714846180000e+000) (8, -9.97253731023627770000e-002) (0, -5.01639617264151410000e-001) (1, -1.10141202508374200000e+000) (2, 3.66631511930266680000e+000) (3, -2.39447593862241840000e+000) (4, 1.42048699345101090000e+000) (5, 1.19911371672277630000e+000) (6, 2.17153423232366860000e+000) (7, -6.27749578940119870000e+000) (8, -2.73483563253921040000e-001) (0, -1.09424686122396460000e+000) (1, -1.27225900879213580000e+001) (2, -2.75360499703067370000e+000) (3, -3.26773319559397720000e+000) (4, 8.22184801978561270000e+000) (5, 1.36640761247352800000e+001) (6, -1.38685128832843100000e+000) (7, 1.04723804311378750000e+001) (8, 7.19499617360656600000e-001) (0, 2.54889528574153210000e+000) (1, -1.28377883712898130000e+001) (2, -2.01619744415363180000e-001) (3, 1.67849918995547820000e+001) (4, 2.04287760236112240000e+001) (5, -1.57485213443192360000e+001) (6, 1.43072840135293900000e+001) (7, -1.12126348169079040000e+001) (8, 2.91105366135819170000e-001) (0, -1.38288369092674230000e+000) (1, 8.30191881459910740000e-001) (2, 1.66015682618405160000e+000) (3, -8.54495423231066020000e+000) (4, 4.54268524250499620000e+000) (5, 6.80687560211734420000e+000) (6, -1.36349063040876150000e+000) (7, -4.09745172719715000000e+000) (8, -2.39437912462538070000e-001) (0, -4.62027005007184770000e+000) (1, -1.95599591022213670000e+001) (2, 5.03913510462851470000e+000) (3, 1.22479527466709490000e+001) (4, 9.52151260619885780000e+000) (5, -1.25249077598736700000e+001) (6, -9.64552669192181790000e+000) (7, 1.74658374074747410000e+001) (8, 5.74641293240596210000e-001) (0, 1.19949609313805430000e+001) (1, 1.24358642997255300000e+001) (2, 5.83605231371461470000e+000) (3, 6.48599411958304110000e+000) (4, -4.60874204490074320000e+001) (5, -1.29198366093266920000e+001) (6, 4.04700707986297290000e+000) (7, -1.01339218860786420000e+001) (8, -7.57546074940998790000e-001) (9, 1.48642751915255280000e-001) (10, -2.55117115688028530000e-001) (11, -7.18072377076180710000e-002) (12, 2.48642234474603230000e+000) (13, -3.28024768218306930000e+000) (14, -9.32399888342740900000e-001) (15, 3.04312232477066350000e-001) (16, 9.62751703246708780000e-001) (17, -3.78507661901490320000e-001) (18, -1.00841419672152250000e-001) (19, 7.05957058227288490000e-001) (9, -5.83337989675860660000e-002) (10, 2.56640127087071870000e-002) (11, 1.60104304082970740000e-001) (12, -2.89412951476683490000e+000) (13, 4.39850414996315920000e+000) (14, 9.97051797342775160000e-001) (15, -3.27414103133243260000e-001) (16, -1.56663783437660850000e+000) (17, 4.51472172113533690000e-001) (18, -4.67400323024738040000e-002) (19, 6.69964811467752110000e-001) (9, -6.02476612814682900000e-001) (10, 1.93573370790581650000e-002) (11, -5.15751584252546970000e-001) (12, -2.36845290613841280000e+000) (13, 4.71713154925393760000e+000) (14, 8.27108502865912640000e-001) (15, -2.62374090860728100000e-001) (16, -3.65747753806369010000e+000) (17, 3.54571097606704410000e-001) (18, 1.84806284906030770000e-001) (19, 5.63476294476286670000e-001) (9, 6.24600528811284360000e-001) (10, -1.04428351257603770000e+000) (11, 8.73013618780785210000e-001) (12, -4.55594081004648820000e+000) (13, 7.15969165291385680000e+000) (14, 1.09782400262541710000e+000) (15, 9.64569823255286510000e-001) (16, -1.73754103075137150000e+000) (17, 1.31642465410246530000e+000) (18, 2.83279474140938130000e-001) (19, 7.95875049061149810000e-001) (9, -4.09236752494554320000e-001) (10, -8.22192378268250870000e-001) (11, -5.25687831570231470000e-001) (12, -4.32102295095265450000e+000) (13, 5.34273871468734280000e+000) (14, 8.95944789711031310000e-001) (15, 1.35009489069936350000e+000) (16, -2.37128949251666920000e+000) (17, 1.70725992977712520000e+000) (18, 1.19740327419351830000e+000) (19, 3.93480811843166130000e-001) 
