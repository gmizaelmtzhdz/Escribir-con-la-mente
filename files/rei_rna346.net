FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.55152969277589530000e+001) (1, 1.34278651265750400000e+002) (2, -5.16264352105802400000e+001) (3, -4.98038847730367560000e+001) (4, 7.29231713584132140000e+001) (5, -1.07568097951690930000e+002) (6, 7.11722734635185080000e+001) (7, -5.77408432444404840000e+001) (8, 1.87494925887429460000e+001) (0, 1.05299913574900600000e+001) (1, -3.16896918565431560000e-001) (2, 1.42307492157608260000e+001) (3, 1.33973918855149190000e+001) (4, -4.95573999725923360000e+001) (5, -1.40308100201112980000e+001) (6, -2.61491507981537150000e+000) (7, 7.12063813837227940000e-001) (8, -5.84043678651401390000e-001) (0, -3.78456607201607430000e+000) (1, 4.28922737899187380000e+000) (2, 1.98415053336645930000e+000) (3, -2.34672015444427800000e+001) (4, 1.55621348993763620000e+001) (5, 1.22242803756042640000e+000) (6, 1.82166458392410040000e+001) (7, -2.36567461856791330000e+001) (8, -1.22733228108495380000e+000) (0, 1.66189961073633260000e+001) (1, -5.05576385205431490000e+000) (2, 1.08663415708070570000e+001) (3, 5.55485068780724020000e+001) (4, -1.16256168080601850000e+001) (5, -6.21388115142018830000e+001) (6, 2.24645980247401020000e+001) (7, -1.17654446847083540000e+001) (8, 1.82725372361957520000e-001) (0, 8.93647715109492040000e-001) (1, -4.98090184420160560000e-001) (2, 1.05609724277914820000e+000) (3, -1.08254851678639800000e+000) (4, -1.84622221287038600000e+000) (5, 3.82324266991907670000e+000) (6, -3.66244909680242300000e+000) (7, 1.91441281630086200000e+000) (8, -1.53118850894863410000e+000) (0, 1.29116957876477640000e+001) (1, 3.81384358707402750000e+000) (2, -3.68758678501836320000e+000) (3, 4.32155697866804620000e+001) (4, -2.35785229827812910000e+001) (5, -4.35484501037289110000e+001) (6, 4.71355854349279560000e+000) (7, 5.04533106807066720000e+001) (8, -9.16766455549259950000e-002) (0, 7.04051064853281170000e+000) (1, 1.36260539763404460000e+000) (2, -1.26070289629951220000e+001) (3, 5.65390836946266120000e+001) (4, -3.47643601396556930000e+001) (5, -2.68520014664682340000e+001) (6, -2.18460348319986610000e+001) (7, 6.87302154259731140000e+001) (8, 2.79602191573504520000e+000) (0, 1.83922729047638200000e+000) (1, 1.66162787011798510000e+001) (2, 4.63816827292211900000e+000) (3, -6.03945133113977520000e+001) (4, 1.64704547947132560000e+000) (5, 2.82351745705285890000e+001) (6, 2.37300399605256550000e+001) (7, -2.11193362527202060000e+001) (8, 1.05746925161799490000e+000) (0, 5.90347937020615630000e+001) (1, -5.90122286654291980000e+001) (2, 2.25536868633164930000e+001) (3, 1.28834832350223790000e+002) (4, 9.32336554705265000000e+001) (5, -1.73687371961508090000e+002) (6, 6.61713381963829050000e+001) (7, -1.35208207927866430000e+002) (8, 1.51091436653723310000e+000) (0, -5.30940607409656540000e+000) (1, 8.00096287849545180000e+000) (2, -1.74408743722052650000e+001) (3, -2.99016937262982690000e+001) (4, 3.98884968937231650000e+001) (5, 1.84928787419811660000e+001) (6, 3.58027679717034040000e+000) (7, 1.76760169547558480000e+001) (8, 3.57863211600583870000e-001) (9, -5.39486636592560800000e-001) (10, -2.58930512862528990000e-001) (11, -9.48558152079897020000e-001) (12, -1.33414096956166990000e-001) (13, -4.28702287644743850000e+000) (14, 2.21870020069543290000e-001) (15, -7.13950282567972990000e-001) (16, 3.01495169417024980000e-001) (17, -6.80583638771678790000e-004) (18, -2.62702021145612590000e-001) (19, -1.45221412643672810000e+000) (9, 5.09045029463480740000e-001) (10, 1.98609894824300030000e-001) (11, 1.31194117638656160000e+000) (12, 8.09030161287220830000e-002) (13, 4.88461371870071390000e+000) (14, -2.64021183158435980000e-001) (15, 9.39861124171481490000e-001) (16, -3.80496972819950260000e-001) (17, -8.61224642438469660000e-002) (18, 2.38388269319957270000e-001) (19, 3.35011399202340730000e+000) (9, 1.36518604953461210000e-001) (10, 6.25054693795303760000e-001) (11, 1.07068430555131780000e+000) (12, 5.83319579851013790000e-001) (13, 2.29034669078170780000e+000) (14, -8.48514530883818340000e-001) (15, 1.05813700807457840000e+000) (16, -5.07236326777424810000e-001) (17, -1.76262219374106410000e-001) (18, 6.33510922051031990000e-001) (19, 2.23264473131777620000e+000) (9, 7.11931271843508680000e-001) (10, 1.20098239934094270000e-001) (11, 1.58910006128061650000e+000) (12, -1.33631925097370470000e+000) (13, 5.96997252723026510000e+000) (14, 9.42261694836428850000e-001) (15, 1.57883467699051480000e-001) (16, -4.52511814143034150000e-001) (17, 5.08605435887882760000e-001) (18, -2.38361993855686930000e-001) (19, 4.71524702819052610000e+000) (9, -2.81052487510867960000e-002) (10, 1.04306518396681350000e+000) (11, 1.42495887046568040000e+000) (12, -1.14484896992364290000e-001) (13, 3.10887910662924980000e+000) (14, -3.90569265815092330000e-001) (15, 9.10184682889882190000e-001) (16, -7.97013142795371170000e-001) (17, 2.10752143455946700000e-001) (18, 1.00053549169590240000e+000) (19, 3.31234628225081010000e+000) 
