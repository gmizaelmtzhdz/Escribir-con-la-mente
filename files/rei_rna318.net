FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -9.36359895487444400000e+000) (1, -1.60349270558918920000e+001) (2, -7.35119868920560830000e+000) (3, -1.40560082828132980000e-001) (4, 1.14700660362695630000e+001) (5, 9.04168457387723200000e+000) (6, 1.23815935065601290000e+001) (7, 3.32226630828373150000e+001) (8, 1.06834655975058100000e+000) (0, 4.16257787592670430000e+000) (1, 3.83579055355173360000e+000) (2, 1.14358991181019310000e+001) (3, 9.54882502699061500000e+000) (4, -5.05745489690552650000e+001) (5, 5.40566086859732310000e+000) (6, -2.65134678080398770000e+001) (7, 1.00373995238866480000e+002) (8, -1.01200995803110240000e+000) (0, 3.76332382039749770000e+000) (1, -6.57032396192229660000e+000) (2, 1.72993196069333410000e+000) (3, -1.09026146881572480000e+001) (4, 2.20827894859634320000e+000) (5, -2.64161046682728310000e+000) (6, -1.15154196074002680000e+000) (7, 1.38271289406603020000e+001) (8, 1.61327308254251740000e+000) (0, 1.36624675366353900000e+000) (1, 1.05851678864872190000e+000) (2, 5.62847181023098610000e-001) (3, -3.14262994197196430000e+000) (4, 9.32043148436737520000e-001) (5, -3.37460896570102300000e+000) (6, 5.03379157063227200000e+000) (7, -5.85287092217491800000e+000) (8, 5.95322223663092620000e-001) (0, -9.73069929398107720000e+000) (1, 1.02746322047156190000e+001) (2, -7.97766556278502570000e+000) (3, -3.10385712099222030000e+000) (4, 3.19282520813778700000e+000) (5, 1.94943326685776730000e+001) (6, -4.95763081749792060000e-001) (7, 3.23782800510691970000e+001) (8, 3.03359224435291730000e-001) (0, 1.22162156633400690000e+001) (1, -2.35607539267668070000e+001) (2, 1.43263237714673310000e+001) (3, -8.22463308264022250000e+000) (4, 1.20022995465964910000e+001) (5, -1.30478971928968410000e+001) (6, -2.08302566144095780000e+001) (7, -2.27814379398647550000e+001) (8, 6.07396008708054880000e-001) (0, -2.83968529337324250000e-001) (1, -5.69549910883392350000e-001) (2, -3.00844832669141640000e-001) (3, 2.76930106265215190000e+000) (4, -1.54566135295404820000e+000) (5, -8.05038682603242290000e-001) (6, 9.45560163595884910000e-001) (7, 1.00237817002105150000e+000) (8, -2.12084584975375500000e-001) (0, -8.69995932275082670000e+000) (1, 4.05640187420881690000e-002) (2, -1.21383446110726840000e+001) (3, 8.63576628644632650000e+000) (4, 5.09350584710988310000e+000) (5, -1.28015828131848020000e+000) (6, 2.61532972968284380000e+001) (7, 6.15932487455726460000e+000) (8, 1.28762762091420760000e-001) (0, 1.20526633199133570000e+001) (1, -3.08014295514717420000e+000) (2, 1.33436160424436320000e+001) (3, 1.52670309082352600000e+001) (4, -3.34445982653601560000e+001) (5, -1.71849467009805820000e+001) (6, -1.24993977334304950000e+001) (7, -1.95614505460993870000e+001) (8, -1.05008825888158300000e+000) (0, 6.67465109928477630000e-001) (1, 4.81619530129551790000e+000) (2, -4.78918227683379110000e-001) (3, -1.20558459799326110000e+000) (4, 1.16603289243452690000e+000) (5, -1.48526508394830350000e+000) (6, 1.94016860600500270000e+000) (7, -7.20942291636759510000e+000) (8, -8.43960599949163810000e-002) (9, -9.37706517989349120000e-001) (10, 1.70175381919651540000e-001) (11, -1.02528283465633590000e+000) (12, 1.89864826434105270000e+000) (13, 4.83276893538363280000e-001) (14, 5.79319899024776870000e-001) (15, -4.49119946592478840000e-001) (16, 7.31501041459510230000e-001) (17, -3.25631085187250090000e-001) (18, -2.35302535488389710000e+000) (19, 6.24435552039744550000e-001) (9, 7.60010429049176590000e-001) (10, -2.36072207381046780000e-001) (11, 7.56182750661774540000e-001) (12, -9.01966702394464640000e-001) (13, 2.07095307720585970000e-003) (14, -4.80104300153465500000e-001) (15, 1.16726888993780360000e-001) (16, -7.42218471274552650000e-001) (17, 3.53231022057124530000e-001) (18, 1.34097112253766240000e+000) (19, 5.63656305203028900000e-001) (9, 1.02730653969751900000e+000) (10, -4.31102400898972280000e-001) (11, 1.11102918934101980000e+000) (12, 8.31095345441520140000e-002) (13, 7.84565653988843260000e-001) (14, -2.48214040075384200000e-001) (15, 6.13244798704292200000e+000) (16, -1.24971569237562430000e+000) (17, 6.60081548133303890000e-001) (18, 2.30801695689271820000e+000) (19, 6.31647927054578730000e-001) (9, 3.23161051874108980000e-001) (10, -2.31038732333433970000e-002) (11, 7.10181578022636150000e-001) (12, -9.58149016558678900000e-001) (13, 1.18587776245838830000e+000) (14, 8.06172824777114050000e-001) (15, -1.23332290657114020000e+000) (16, 8.75282959606766500000e-001) (17, 1.22493941389206170000e+000) (18, 2.24012971857011410000e+000) (19, 7.80618971512990530000e-001) (9, -7.81933952334921580000e-001) (10, -2.85924231464196650000e-001) (11, 2.01910604796510110000e+000) (12, -8.79081816835835860000e-001) (13, 1.81350219489606920000e+000) (14, 1.16927136910651550000e+000) (15, 5.62675166867922980000e+000) (16, 7.28547857548151100000e-001) (17, 5.03296823544820530000e-001) (18, 1.60854366335404710000e+000) (19, 5.36145827684100680000e-001) 
