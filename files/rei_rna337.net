FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.37687226871624350000e-001) (1, -1.22089792843184490000e+000) (2, -3.13588316680024490000e+000) (3, 2.36134340961125090000e+000) (4, -1.19717598984066710000e+000) (5, -1.53307782037541580000e+000) (6, -5.28119502138059470000e-001) (7, 2.90541129786754970000e+000) (8, 2.39421560785253400000e-001) (0, 8.15631093205819190000e+000) (1, -3.47203297767581010000e+000) (2, 1.52695750475514970000e+001) (3, 1.59442782682515500000e+001) (4, -3.13943979021676430000e+001) (5, -6.35376635958853870000e+000) (6, 1.68735942920922090000e-001) (7, -2.06878207938319920000e+001) (8, -1.11339330578934040000e+000) (0, 4.32294754150694430000e+000) (1, -1.05160741460740150000e+001) (2, -4.45831541689427000000e+000) (3, -1.51906324311927610000e+000) (4, -9.58358428760509450000e-002) (5, -2.73457472612619630000e+000) (6, 1.79105540491587870000e+001) (7, -1.56944541575160570000e+001) (8, 4.64697299929852700000e-001) (0, 8.70075897448726640000e+000) (1, 1.77188075071538040000e+000) (2, 4.71947668915863970000e+000) (3, -7.02542353341228680000e+000) (4, -2.28808715782146270000e+001) (5, 1.30268561323025730000e+001) (6, 8.71729320776446310000e+000) (7, -1.41412641151433100000e+001) (8, -8.65734501002263570000e-001) (0, 2.02855425033736440000e+000) (1, 1.77587371832550620000e+000) (2, -1.53817368663746490000e+001) (3, 1.44587021564910820000e+001) (4, 1.79312203529088240000e+001) (5, -2.39879616634927830000e+001) (6, 1.28268823383447010000e+001) (7, 7.57390104780057440000e+000) (8, -1.36952205460820280000e+000) (0, 3.71263323519816300000e+000) (1, 2.77101371760099370000e+000) (2, 9.00834591852030960000e-001) (3, 1.17294886484738100000e+001) (4, 8.66112016760799360000e+000) (5, -2.21230961055800820000e+001) (6, 1.17115861380616020000e+001) (7, -9.33530952773507220000e+000) (8, -5.12263401842367290000e-001) (0, 6.42978599032634970000e+000) (1, 6.68419347555004340000e+000) (2, -8.29922381751764250000e+000) (3, 8.45797617028915210000e+000) (4, 1.61357379353514790000e+001) (5, -2.62024757232879790000e+001) (6, 9.82258905947676550000e+000) (7, 4.27162422095622320000e+000) (8, 6.70470973194096320000e-001) (0, -2.47479368789692080000e+000) (1, -5.39306445529645660000e+001) (2, 6.79504769361932400000e+001) (3, -9.84485713921347380000e+001) (4, 5.59345735903236020000e+001) (5, 2.64589346545528880000e+002) (6, 1.16765575136140480000e+001) (7, -6.62451173347392770000e+001) (8, 7.64600518326671090000e+000) (0, 6.90294735224446490000e+000) (1, 3.90180698570269660000e+001) (2, -7.10169804074549300000e+000) (3, 1.43758849466159750000e+000) (4, -2.52786504094779230000e+001) (5, 4.41896098217636890000e+000) (6, -5.93516011660280540000e+000) (7, 3.91206494535578670000e+001) (8, -1.61635042916981630000e+000) (0, 2.10244476162667350000e+000) (1, 7.59859234294197260000e+000) (2, -3.21883662338785200000e+000) (3, 7.61880632112575280000e+000) (4, -5.06016335507365870000e+000) (5, -1.14751594608195900000e+001) (6, 4.41309254758315460000e+000) (7, -9.47473503757217620000e-001) (8, 6.73724041791465830000e-001) (9, 1.29732471224825010000e+000) (10, -3.47543926015187910000e-001) (11, 4.63654331711385870000e-001) (12, -2.48536734784618600000e-001) (13, -6.47594844385464890000e-001) (14, 1.28129471447340860000e+000) (15, -8.13010758626790400000e-001) (16, -9.19535070998632080000e-001) (17, 3.66923901374034580000e-001) (18, -5.28716093578632140000e-001) (19, 1.56482894439335630000e+000) (9, -2.43287511261633820000e+000) (10, 3.36226466637133850000e-001) (11, -1.84988343565229730000e-002) (12, -1.38994155211730140000e-001) (13, 7.08651676359437040000e-001) (14, -1.58735275564632670000e+000) (15, 4.15903344816663910000e-001) (16, 4.09550381672764750000e-001) (17, -1.89345590023939140000e-001) (18, 9.12072291214958810000e-001) (19, 3.39578967601786300000e-001) (9, 2.85004668269362440000e-001) (10, -2.46918104691302790000e-001) (11, -6.89752842136852400000e-001) (12, 6.78203038034373980000e-001) (13, 4.82931203290472120000e-001) (14, -1.66205364977537730000e-003) (15, -5.67099220206485180000e-001) (16, 5.45866512437246600000e-001) (17, -3.90807900467891540000e-001) (18, 7.56100074517941370000e-001) (19, 7.33545543681730190000e-001) (9, -6.03958532430715510000e+000) (10, 1.54219258715216510000e+000) (11, 9.57249952810764420000e-001) (12, -1.46969307742669650000e+000) (13, 1.32682533045442550000e+000) (14, -3.48523247659679790000e+000) (15, 1.32507338272982200000e+000) (16, 1.59366862077158560000e-001) (17, 7.36924423087058490000e-002) (18, 1.16250861338580140000e+000) (19, 7.13490075575131330000e-001) (9, 1.08281351795534730000e+000) (10, -1.58021954526382650000e-001) (11, -1.21277683158736640000e+000) (12, 1.01460543888008940000e+000) (13, 5.17156445893899860000e-001) (14, -1.38005384562803310000e-001) (15, 6.64657003047744670000e-001) (16, 8.83836537327582380000e-001) (17, -6.30885917490077270000e-001) (18, -1.28098782645823390000e-001) (19, 3.44208033213889320000e-001) 
