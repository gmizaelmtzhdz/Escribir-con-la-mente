FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 9.33726010105382500000e-002) (1, 1.96636499811135760000e+001) (2, -8.14153405954604100000e+000) (3, -1.52354933746874450000e+001) (4, 6.69895833691938170000e-001) (5, -4.20651241788436450000e+000) (6, 3.33427137651993010000e+000) (7, -4.50818179595885480000e+000) (8, 2.11654439401317870000e+000) (0, 1.98968647175777090000e+000) (1, 1.00956251973144080000e+001) (2, 2.22600446590597030000e+000) (3, -8.75912004319604590000e-001) (4, -8.67218240061786010000e+000) (5, 1.18957382558864010000e-001) (6, -7.05585374915555170000e+000) (7, 4.74913428588568820000e+000) (8, -4.43852717311705720000e-001) (0, -7.20017882790841780000e-001) (1, -6.71681296656421710000e+000) (2, 4.28461711007606370000e+000) (3, -3.26961274548338210000e+001) (4, 1.29794579880600040000e+001) (5, 7.98263139846818750000e+001) (6, 5.82101270411102420000e+000) (7, -1.26529689716812830000e+001) (8, 3.04586742587051070000e+000) (0, 9.67862372879305100000e-001) (1, 1.23777720481762760000e+001) (2, 5.02450573363372620000e-001) (3, -1.99780774544223300000e+001) (4, -8.95034010774730770000e-001) (5, 5.75453523670688850000e+000) (6, 1.61292380050163860000e+001) (7, -1.34154508177507930000e+001) (8, 4.96319259621831880000e-001) (0, 2.77432686645622210000e-001) (1, 1.31680868067863110000e+001) (2, -1.16299298046092560000e+000) (3, -8.43692127597781290000e+000) (4, -7.12043239626933060000e-001) (5, -8.67214021850708620000e-001) (6, 3.95336977284525080000e+000) (7, -5.19319788245097860000e+000) (8, 1.64697683482846720000e-001) (0, -2.99994362079122650000e+000) (1, 1.40395121097701820000e+001) (2, -5.43196429115479780000e+000) (3, -2.70407482851135760000e+001) (4, 8.60725806189866560000e+000) (5, 2.21668979198115860000e+001) (6, 8.33465793712663760000e+000) (7, -4.44836134075113490000e+001) (8, -2.97270599334036540000e-001) (0, -5.36668087292738960000e-001) (1, -1.96913503275062380000e-001) (2, 2.61574348506416410000e+000) (3, 9.62562961980743760000e-001) (4, 2.82998921652652860000e+000) (5, -5.00529395548092730000e+000) (6, 8.89713001049678450000e+000) (7, 6.35285903593492240000e-001) (8, -3.06206256370524180000e-001) (0, 2.94424920325498270000e-001) (1, 1.30651241328268290000e+000) (2, -1.02055613864106330000e+000) (3, 5.26140488376968120000e+000) (4, -2.66094841715639950000e+000) (5, -4.71395052723773400000e+000) (6, -3.88536669861919440000e+000) (7, 4.32313859247298100000e+000) (8, 1.51163155846622490000e-001) (0, 2.54381680834624200000e+000) (1, 7.24323714069326940000e-001) (2, 2.42040168563377870000e+000) (3, -1.05491723805204900000e-001) (4, -1.00034458331954600000e+001) (5, 4.92352318138485060000e+000) (6, -8.76327286537559050000e+000) (7, 5.39751112801165340000e+000) (8, -1.61714387813446020000e-001) (0, 1.17431325440215880000e+001) (1, -1.81334495133766050000e+000) (2, -3.22197005475760750000e+001) (3, 9.79507483164549520000e+000) (4, 3.82803738841050600000e+001) (5, -1.54775569020003050000e+002) (6, 9.58475759377503210000e+001) (7, 1.03497499402037500000e+001) (8, 8.65241946278217040000e-001) (9, 5.32609416025269460000e-001) (10, 2.13843159163841620000e+000) (11, -1.01176082519500100000e+000) (12, 1.34507110091377880000e+000) (13, -3.16319343237261340000e+000) (14, 3.70714414729580260000e-003) (15, -2.33988121257881180000e-001) (16, -4.91448020088486250000e-002) (17, -1.97495860057103670000e+000) (18, -6.66416419583201890000e-002) (19, 1.30205583444766830000e+000) (9, 7.71099212413778430000e-001) (10, -8.79615970663369050000e-001) (11, 9.28435005786431980000e-002) (12, -9.65721148497006850000e-001) (13, 9.41132976326523710000e-001) (14, 1.13851184907757630000e-001) (15, 7.60781423921795370000e-001) (16, -6.56923304298443480000e-001) (17, 1.12458810270931850000e+000) (18, -7.92511384439684860000e-002) (19, 4.50659473347601150000e-001) (9, 1.29221782543038590000e-001) (10, -2.82777124263987820000e+000) (11, 1.05859953236810740000e+000) (12, -8.91006340022613700000e-001) (13, 2.03375012238026810000e+000) (14, 5.96649754103622310000e-001) (15, 2.14362369386609290000e+000) (16, 3.02572984630080780000e+000) (17, 2.73886895859054750000e+000) (18, -7.44488387697638810000e-002) (19, -1.65101313527329240000e-001) (9, 2.18959052959287050000e-001) (10, -2.25469121025804010000e+000) (11, -4.42111047667800790000e-001) (12, -2.13636514606295740000e+000) (13, 3.35347069307846010000e+000) (14, -2.75365128341728310000e-002) (15, 8.95722170848303740000e-001) (16, -2.39693790331755840000e+000) (17, 2.68812293835214880000e+000) (18, 8.05702229301712010000e-002) (19, 1.53305532355277220000e+000) (9, 2.14293851438409130000e+000) (10, 3.53056611070762960000e+000) (11, 1.33828377404264700000e+000) (12, -1.41338171886690600000e+000) (13, -4.03926137498336500000e+000) (14, 1.12475081998252200000e+000) (15, 1.70176216248293640000e+000) (16, -2.09121666526520930000e+000) (17, -7.04235922199833890000e-001) (18, 3.00485864732696390000e-001) (19, 1.16922939783639180000e-001) 
