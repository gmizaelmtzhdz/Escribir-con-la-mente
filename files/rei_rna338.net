FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.99236006328518190000e+000) (1, 6.55800945870281930000e-001) (2, -4.41254209343825550000e+000) (3, -7.48264361363909810000e+000) (4, 4.67848968732534050000e+000) (5, 4.33591175636455260000e+000) (6, -2.40148155502647850000e+000) (7, -4.05263921626288600000e-001) (8, -4.29429861301649170000e-001) (0, 1.60785292882138360000e+000) (1, 2.27362132805064900000e+001) (2, 4.14955679197803420000e+001) (3, -9.54339034029255020000e+000) (4, -3.85145514343004080000e+001) (5, 6.40407650068868290000e+001) (6, 8.70636970936613610000e+000) (7, -1.41747635732338960000e+001) (8, 1.61006187174181940000e+000) (0, 8.95083850500014490000e-001) (1, 2.19624335175862880000e+000) (2, 5.06775883149104360000e+000) (3, 9.70088382400323470000e+000) (4, 1.25384096070994850000e+001) (5, -6.95373119953291850000e+000) (6, 2.13913977439057090000e+000) (7, -2.12855135641794640000e+001) (8, 1.79215307964304290000e-001) (0, 1.58616220642724820000e-001) (1, -5.13800064065814470000e-001) (2, 5.55688679730795610000e+000) (3, -2.12682113425933790000e+001) (4, 1.74288047951966550000e+001) (5, 3.72483189600338420000e+001) (6, 2.29215356973156790000e-001) (7, -5.72865364517215170000e+000) (8, 3.90397639523869190000e-001) (0, 2.20431747077896790000e+000) (1, 1.27075638222139700000e+001) (2, 8.54536891677880920000e+000) (3, -5.39764751642412720000e+001) (4, -4.43577473887018230000e+000) (5, 3.09434290737379310000e+001) (6, 2.91652034212261030000e+001) (7, -2.12484820379922540000e+001) (8, 9.02092405175688560000e-001) (0, 9.16165298351556250000e+000) (1, -1.35017063542910750000e+001) (2, 1.73197981360334230000e+001) (3, -1.91090858900333880000e+001) (4, 1.47790442261560440000e+001) (5, -4.42018659627053090000e+000) (6, 2.46122369255112310000e+000) (7, 1.97198314321236250000e+000) (8, 4.77985663984762610000e-001) (0, 2.62160123161400670000e+000) (1, -2.45722058628488640000e+000) (2, 7.13925880881328730000e+000) (3, 4.48938181558429770000e+000) (4, 2.16020450400842140000e+001) (5, 1.13472850835946250000e+000) (6, -7.37836926811799550000e+000) (7, -4.70244850202494650000e+000) (8, -5.13003051741805600000e-001) (0, 7.48625327109210590000e-001) (1, 1.04154180575047620000e+000) (2, 7.31922592466447640000e-001) (3, -1.41324725513986120000e+000) (4, -1.93696785090103570000e+000) (5, 1.08688721537421910000e+000) (6, 1.19505162394153040000e-001) (7, 1.77684760695695230000e+000) (8, 1.28427179686529700000e-001) (0, 6.87608359518158910000e-001) (1, 3.41338675434851630000e-001) (2, 9.15267677730845270000e-001) (3, 5.58303094661149490000e+000) (4, -5.19258447049609990000e+000) (5, -3.21530624993015830000e+000) (6, 1.29412466349730380000e+000) (7, 3.78194265010737980000e+000) (8, -3.81967911344192610000e-002) (0, 1.20983672587533050000e-001) (1, -1.07952243132113480000e-001) (2, -7.77125646159865460000e-001) (3, 2.05841316824972460000e+000) (4, -3.92216177134517350000e+000) (5, -5.15914423135781950000e-001) (6, -1.97732452986980540000e+000) (7, 7.89276659273258120000e+000) (8, -2.36328939186776610000e-001) (9, 1.44081920718654640000e+000) (10, 2.58679412457892220000e-001) (11, -1.20814853712351680000e+000) (12, -6.03835626508534060000e-001) (13, 3.88894429998399460000e-001) (14, -1.92928295336046000000e-001) (15, 1.22546128335644220000e+000) (16, -2.46110695048358120000e+000) (17, 3.58166001671820310000e+000) (18, -2.92704928087961760000e+000) (19, 9.73207660375532630000e-001) (9, 4.26742555707685770000e-001) (10, 1.94052420321770220000e-001) (11, 4.06762844271652710000e-001) (12, 4.44706840189090900000e-001) (13, -5.10457435076363650000e-001) (14, 1.14789822609197480000e-001) (15, -7.15620261157912110000e-001) (16, 2.90151069092155020000e+000) (17, -1.14599469744207450000e+000) (18, 9.91238015588585960000e-002) (19, 5.00842010198274230000e-001) (9, 1.07070922796317690000e+000) (10, -4.80418163873510000000e-002) (11, 1.53796059475133080000e+000) (12, 9.33116036616257970000e-001) (13, -4.27093488473335170000e-001) (14, 4.61570515196284060000e-001) (15, -1.47030427437219900000e+000) (16, 1.13547553661306110000e+000) (17, 5.39636722574775800000e-001) (18, 1.77113165329632130000e+000) (19, 7.46367878283316080000e-001) (9, 2.86769269972084780000e+000) (10, 5.56378700532786930000e-001) (11, -1.29767626896917190000e+000) (12, -4.09446899152185410000e-001) (13, -6.42091120682126040000e-001) (14, 3.51567374243586750000e-001) (15, 5.14682487904130070000e-001) (16, 3.19463621187883760000e+000) (17, 3.98208707069240920000e+000) (18, -6.12253173188177780000e+000) (19, 9.59227651881492840000e-001) (9, 5.07061067579251290000e-001) (10, -7.72541806159899090000e-001) (11, 2.07051723211449580000e+000) (12, 8.88500090433766760000e-001) (13, -5.46271004509270910000e-001) (14, 6.11447748461826590000e-001) (15, -1.48930987011743590000e+000) (16, 2.61986112270923680000e+000) (17, -1.85095131411332650000e+000) (18, 3.93585828138239700000e+000) (19, 1.35641358737158630000e+000) 
