FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.45948746777716830000e+000) (1, -1.01425728999017530000e+001) (2, 1.77759931439663850000e+001) (3, -1.44013821613613170000e+001) (4, 2.21684735379155780000e+001) (5, -6.13059810534380970000e-001) (6, 9.19688550449458650000e+000) (7, -4.88485394099869980000e+001) (8, 1.14605119846739910000e+000) (0, 3.71991488264515490000e+000) (1, -4.69874458076614760000e+000) (2, 7.20692793622309400000e+000) (3, -1.44629623094952070000e+001) (4, 5.23945127986329600000e+001) (5, -1.94061089893179500000e+001) (6, 1.28226375416086300000e+001) (7, -4.77138226499220080000e+001) (8, -5.90279599756205360000e-001) (0, 1.52046425788375710000e-001) (1, -2.36409025935870210000e+000) (2, 2.00852206795222310000e+000) (3, 2.35913164323587710000e+000) (4, -2.05975282297509390000e+000) (5, -3.17341180438605170000e+000) (6, 6.70757684118903690000e-001) (7, 7.53424904934526740000e-001) (8, -4.78845805152469490000e-001) (0, 1.50000000000000000000e+003) (1, 1.90337223542672970000e+002) (2, 1.50000000000000000000e+003) (3, 2.11981128325935170000e+002) (4, -1.31083413851381310000e+003) (5, -8.74276392208530410000e+002) (6, 9.18791299421278950000e+002) (7, 1.50000000000000000000e+003) (8, 1.83444081018816160000e+001) (0, -9.88397475822272470000e+001) (1, 4.92894745728837850000e+002) (2, 5.31596662117386170000e+001) (3, -1.50000000000000000000e+003) (4, 3.50382826891145670000e+002) (5, 1.15142614355131580000e+003) (6, -2.13555769301202160000e+002) (7, -1.60092163148399490000e+002) (8, -6.66019833971409130000e+001) (0, 6.05690714165268460000e+001) (1, -3.56112430071689350000e+002) (2, -1.62624381240871000000e+002) (3, 9.44439731408692640000e+002) (4, 2.18313095469665540000e+002) (5, -5.02205669989468110000e+002) (6, 6.52168917980432180000e+002) (7, -6.36636785120050720000e+002) (8, 3.29940897967899010000e+001) (0, -2.72458611775791490000e+000) (1, 4.79696228881372020000e+000) (2, -7.58530496941016890000e+000) (3, -7.59371125915770940000e+000) (4, 1.09470417391881780000e+001) (5, 1.63664689423419570000e+001) (6, -5.62484162668884920000e+000) (7, -6.90139937838906370000e-001) (8, 2.00573505931784380000e-001) (0, 1.05283857335572610000e+001) (1, -4.42457308726192360000e+000) (2, 3.75104158877289180000e+001) (3, -2.17330897550709670000e+001) (4, -2.27142098021770910000e+001) (5, 1.54857671399891200000e+001) (6, 2.85861307007106230000e+001) (7, -9.42666685257444210000e+001) (8, 1.38669820508891960000e+000) (0, -3.65490286879997360000e+000) (1, 6.84942856152693010000e-001) (2, -4.55109485208079260000e+000) (3, -1.04723330474386010000e+001) (4, 1.91165864433081400000e+001) (5, 1.95731198733860020000e+001) (6, -4.88799960428198150000e+000) (7, -1.19293598072690710000e+001) (8, 1.37508278730811530000e-001) (0, 1.17465250709315060000e+000) (1, 8.34757054913271370000e+000) (2, -2.76793891578525340000e+000) (3, 2.22665486380176000000e+001) (4, -7.66220619434277670000e+001) (5, 2.18591705822038710000e+000) (6, -1.11140407365054640000e+001) (7, 8.08233181593112700000e+001) (8, 9.32384538234137920000e-001) (9, -9.18858985733490120000e-001) (10, 7.28832526423306650000e-001) (11, 1.81761841261532920000e+000) (12, -3.65273456273304990000e-001) (13, 2.49066733357453470000e-001) (14, 3.60757604355124880000e-001) (15, -3.11775660077718400000e-001) (16, 2.75071354855670470000e-001) (17, 9.30286195630493970000e-001) (18, 5.01105225954590620000e-001) (19, 1.46646185364355540000e+000) (9, 5.92335790830394780000e-001) (10, -6.34117990334767460000e-001) (11, -1.84358061455893240000e+000) (12, 2.54460501821820560000e-001) (13, -3.54873613107108520000e-001) (14, -8.63547522761619720000e-001) (15, -3.45438711284297820000e-001) (16, -1.90973978433148640000e-001) (17, -4.79307002577203170000e-002) (18, -3.70495220136513090000e-001) (19, 5.36708371506641520000e-001) (9, 6.88963169145441200000e-001) (10, -7.20627255850651790000e-001) (11, 2.10159888842796680000e+000) (12, 1.21113459321329110000e-001) (13, -1.40620086958943430000e-001) (14, -2.49939026350220640000e-001) (15, 2.30799237976517670000e+000) (16, -3.47357390129009940000e-002) (17, -1.96078429559516470000e+000) (18, -6.75617865767993540000e-001) (19, 1.13414744590618130000e+000) (9, 1.36917818361733020000e+000) (10, -1.06400140539913050000e+000) (11, -3.11087263418757990000e+000) (12, 1.05424349735748070000e-001) (13, 2.93162508272022120000e-001) (14, 2.50885186393033640000e-001) (15, -7.16353457400051960000e-001) (16, -6.18985030992333480000e-001) (17, -7.04944484891353310000e-001) (18, -6.10195089146502000000e-001) (19, 5.84231535942972770000e-002) (9, 1.71438777012974430000e+000) (10, -9.15393001084560560000e-001) (11, 6.08781719981250100000e+000) (12, -1.00877747566210640000e-001) (13, 5.87394989892027870000e-001) (14, 7.90154279816917410000e-002) (15, 5.55355747153155830000e+000) (16, -3.78778327078563900000e-001) (17, -4.66993493667700040000e+000) (18, -1.05365991779877220000e+000) (19, 2.35923242228634940000e+000) 
