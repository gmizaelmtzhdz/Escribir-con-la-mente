FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.37604728877834860000e+000) (1, 1.73441318378329010000e+001) (2, -8.23257156867310690000e+000) (3, -5.12921716840156990000e+001) (4, -2.90712394898039590000e+000) (5, 2.93124853103203230000e+001) (6, 3.53788635236378330000e+001) (7, -1.44242248585389330000e+001) (8, 2.04454369384004440000e-001) (0, -3.94979364085153330000e-001) (1, -1.34279108136835460000e+000) (2, 2.67968989825743580000e-001) (3, -2.24246002302445110000e+000) (4, 3.62824833319581730000e+000) (5, 5.37867707110909960000e+000) (6, 3.30695668208216680000e+000) (7, -7.76836686046820460000e+000) (8, -1.30158901343290450000e-001) (0, -5.82303701024157760000e+000) (1, 1.10356358138603760000e+000) (2, -2.33341439812900790000e+000) (3, -2.97365212233173570000e+001) (4, -4.01920141167401110000e+000) (5, 3.56974446906688810000e+001) (6, -2.98764646553838540000e+000) (7, -4.68164747894735010000e+000) (8, 3.66738570087535850000e-001) (0, 4.95542272871530450000e+000) (1, -3.82909770812577440000e+000) (2, 6.93336563311813240000e+000) (3, 2.77518765155573130000e+001) (4, -5.02234463096710610000e+001) (5, -7.51713449849854950000e+000) (6, -1.61114849036084280000e+001) (7, 4.76103701544219150000e+001) (8, -1.59315131822150510000e-001) (0, 4.40973305029355970000e+000) (1, 6.92131384256436610000e-001) (2, 3.52294041647128700000e+000) (3, 1.18977210238361660000e+001) (4, -2.69156690981214060000e+001) (5, -9.07940950921983260000e+000) (6, -9.16940876602717720000e-001) (7, 1.16246276300183140000e+000) (8, 6.56598474216234670000e-003) (0, 1.41032586886913780000e+001) (1, -2.60685341415596130000e+001) (2, 7.37427575198055770000e+000) (3, 1.70376470596159460000e+001) (4, 8.41241721454582600000e+001) (5, -1.30612851323599330000e+001) (6, -9.92840436817190590000e+000) (7, -2.20563254341468240000e+001) (8, 2.36465608323639960000e+000) (0, 1.90642405188140530000e+000) (1, 6.03170198132291800000e+000) (2, -9.98878254725625680000e+000) (3, 1.09545142483715520000e+001) (4, 6.38054463426330010000e+000) (5, -2.46671468830460690000e+001) (6, 9.02783447933996360000e+000) (7, 1.22054033578711180000e+001) (8, 2.67115538657883120000e-001) (0, -2.02129553574905610000e+000) (1, -1.16496212936754850000e+000) (2, -3.08262191062315430000e+000) (3, -8.71833093351638940000e+000) (4, 1.16302483777420670000e+001) (5, 1.32759124157888340000e+001) (6, 2.23870804039323710000e+000) (7, 5.71636631777577970000e+000) (8, 5.03457551820339980000e-002) (0, -9.57778019139923080000e-002) (1, 1.76285554414215670000e-001) (2, 1.09686066885896660000e+000) (3, -3.47593404022049370000e+000) (4, -6.79993840132652740000e-001) (5, 2.81620636907306390000e+000) (6, -3.36903540838852280000e+000) (7, 3.18599698099666200000e+000) (8, -1.24946236183433120000e-001) (0, 2.99773510179244460000e-002) (1, -1.67214810961014260000e-001) (2, 2.20227568224283000000e+000) (3, -2.36961485279144710000e+000) (4, 6.43118173893097110000e+000) (5, 1.01433998587198790000e+000) (6, 4.80145193099493820000e+000) (7, -1.12610058606777790000e+001) (8, -4.54842436152911260000e-001) (9, 2.72592002482041240000e-001) (10, -8.63418911402769720000e-001) (11, -1.58553400851412090000e-001) (12, 3.37129395221908100000e-001) (13, -1.12706914765384920000e+000) (14, -1.18241127252932520000e-001) (15, -5.99764820121367670000e-001) (16, -7.57966365054162370000e-001) (17, -2.60355289206576000000e+000) (18, -9.75949189531191970000e-002) (19, 5.62930557284843870000e-001) (9, -3.71812190508397260000e-001) (10, -6.33843160899521970000e-001) (11, 5.08220096005092330000e-001) (12, -3.76102947745744150000e-001) (13, 1.29573807018816270000e+000) (14, -8.21981921253596700000e-002) (15, 5.93958967540185620000e-001) (16, 1.16031539036916940000e+000) (17, 2.00206900760243340000e+000) (18, 1.00385566505406620000e+000) (19, 1.06060254390338100000e+000) (9, -3.80282375267165800000e-001) (10, -2.91762411768401230000e+000) (11, 3.11681699240787260000e-001) (12, -7.47924657215275350000e-001) (13, 2.02169670341098670000e+000) (14, -1.77043485953532700000e-001) (15, -1.90203226712792190000e-001) (16, 2.19378026539469580000e+000) (17, -9.61643687197203280000e-001) (18, 1.03013426216802830000e+000) (19, 1.06856221709542300000e+000) (9, -5.86548472676920560000e-001) (10, -1.11365255939480280000e-001) (11, 1.75078027580880650000e+000) (12, 4.43982293769822840000e-001) (13, 1.14020249388211780000e+000) (14, 1.75686069861232500000e+000) (15, 2.04310318125003750000e+000) (16, 5.09202335099539830000e-001) (17, 3.25145165434637250000e+000) (18, 3.67538541240551540000e+000) (19, 9.81031460758477640000e-003) (9, -7.13352212943676460000e-001) (10, -9.25049808652894880000e-001) (11, 2.43977672032451770000e-001) (12, -1.18767754024288360000e+000) (13, 3.07152993046072930000e+000) (14, 3.36772381110987900000e-001) (15, 7.38522167099576740000e-001) (16, 2.81696549130623670000e+000) (17, 3.34484410075522250000e+000) (18, 5.71381747796625210000e-001) (19, 8.44487257819593550000e-001) 
