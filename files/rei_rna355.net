FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.02776103038659410000e+000) (1, 5.58709724518293530000e+000) (2, 4.62766217509749020000e+000) (3, 3.91457491423963110000e+000) (4, -3.13275815619505590000e+001) (5, 5.60706663836994680000e+000) (6, -2.55787095151314220000e+001) (7, 3.17042224857643720000e+001) (8, 1.41075952320727620000e-001) (0, 1.19264000684482470000e+003) (1, 1.50000000000000000000e+003) (2, -8.12421018466946180000e+002) (3, 6.72940904776817550000e+002) (4, -1.13545749369376590000e+003) (5, -1.35792765277984560000e+003) (6, 1.50000000000000000000e+003) (7, 7.79511613458125790000e+002) (8, 8.47930859608846390000e+001) (0, 2.55463238464988080000e+001) (1, 4.95569467910545640000e+001) (2, 2.82421956978605240000e+000) (3, 1.79188348183692200000e+001) (4, -1.04365734413489490000e+002) (5, -3.86998366497525970000e+000) (6, 4.92893336002768910000e-001) (7, -6.89341626457361510000e+001) (8, -2.28501711399804330000e+000) (0, 3.17720543258218500000e+000) (1, -3.16188815634367510000e+000) (2, -1.87524420007733960000e+001) (3, 1.25006601945806230000e+001) (4, -9.31285307912191130000e+000) (5, -1.43418691537676550000e+001) (6, 3.79232177081406880000e+000) (7, -3.66905007273189330000e+000) (8, 4.63727858596051920000e-001) (0, -1.53946209580872660000e-001) (1, 5.54582373408839650000e-001) (2, 1.84139907663433840000e+000) (3, -3.92152524923157930000e+000) (4, 2.69706822665710890000e+000) (5, 2.72439000177325410000e+000) (6, 1.12674023650951180000e+000) (7, -3.51691785522833510000e+000) (8, 4.50826777821450360000e-001) (0, 1.82241558979179460000e+000) (1, -4.36291553268520980000e+000) (2, -5.26317501877651230000e+000) (3, -7.10717424828940180000e-001) (4, 2.48418651980188830000e+001) (5, -2.55498075690065600000e+000) (6, 1.65906564372952020000e+001) (7, -1.41998332195990520000e+001) (8, -2.15215767113425100000e-002) (0, 9.89718276725780480000e+000) (1, 3.17229277196317980000e+001) (2, 4.48221824046867990000e+001) (3, -1.97196520754044900000e+001) (4, -5.19435417317730060000e+000) (5, 6.16315598028060590000e+001) (6, -2.65932094752390080000e+000) (7, -2.23355306873141830000e+001) (8, -2.80515791530597180000e+000) (0, 6.71462755422821540000e+000) (1, -9.75446815752850860000e+000) (2, 2.06517633628949680000e+001) (3, -1.24149336486206380000e+001) (4, 2.76307435341644410000e+001) (5, -1.19479100399779220000e+001) (6, 2.47824857853884990000e+001) (7, -6.97824114373916020000e+001) (8, 1.03466377885991980000e+000) (0, -2.08724162561579940000e+001) (1, -9.43692202008640920000e+001) (2, -3.05748883090958320000e+002) (3, -2.40343659620107670000e+002) (4, -5.01711800447049970000e+001) (5, 4.05609826273905530000e+002) (6, -7.35611081107363250000e+002) (7, 6.20303335246845340000e+002) (8, 6.35449838638965470000e+001) (0, -1.05907636186572150000e+000) (1, 1.53363375104154920000e+000) (2, 6.03312301307600580000e+000) (3, -7.83310663192342640000e+000) (4, 1.19300511457958100000e+001) (5, 9.51202921926407360000e+000) (6, 3.55389219798911470000e+000) (7, -4.25459088342339960000e+000) (8, 1.99321512104823570000e-001) (9, -1.42167938004874040000e+000) (10, -1.72824419128553620000e+000) (11, -4.71141312869591960000e-002) (12, -6.03446625650436940000e-001) (13, -6.62978654881806300000e-001) (14, -1.21034192157606850000e+000) (15, 2.39187813159736990000e-002) (16, -3.72699011263666000000e-001) (17, -8.92993195363792070000e-002) (18, -9.84351628773750260000e-001) (19, 2.98452695633741220000e+000) (9, 1.35179687324157530000e+000) (10, 6.21333984628861250000e-001) (11, -5.78560294183105630000e-002) (12, 5.58559706680978540000e-001) (13, 1.55752104377346060000e+000) (14, 1.13754912722044390000e+000) (15, 6.76855680081950030000e-003) (16, 2.42775252233238650000e-001) (17, 7.50954565170503100000e-002) (18, 6.17395955344440360000e-001) (19, -5.64903764599464230000e-001) (9, 8.55156107990083570000e-001) (10, 3.22367919027407360000e-001) (11, -1.14524291704467890000e-001) (12, 1.62546754311066180000e+000) (13, -2.37923104153527110000e+000) (14, -4.00915561393623670000e-001) (15, 2.82425878811679890000e-002) (16, 5.08044295098929010000e-001) (17, -5.68677018290123310000e-002) (18, 3.65408735837724170000e+000) (19, 1.87380364037807780000e-001) (9, 2.69690692131186130000e+000) (10, 3.11527191622825940000e-001) (11, 3.82575501765446900000e-002) (12, -2.27412970955649270000e-001) (13, 3.41588923287301280000e+000) (14, 3.45064855917443980000e+000) (15, -3.39377167101891640000e-002) (16, 4.62468663458332930000e-001) (17, -7.21951128747232580000e-002) (18, -1.78186552284560150000e+000) (19, -3.00126354036700340000e-002) (9, 2.17469974001392830000e+000) (10, -4.09760337224455100000e-001) (11, 4.89212027995869380000e-001) (12, -4.98871899132556750000e-001) (13, -1.90710499111899120000e+000) (14, 2.73861187189614520000e+000) (15, -5.53793206819696900000e-001) (16, 6.68704353088564350000e-001) (17, 4.02753360145903630000e-001) (18, 1.12801251384783230000e+000) (19, 9.00640871702725000000e-001) 
