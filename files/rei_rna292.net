FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -6.73279543959739660000e-001) (1, 1.45705969938291300000e+000) (2, 6.12975764344005740000e+000) (3, 1.38017056155316450000e-001) (4, -1.88378099701356730000e+001) (5, 9.75317040850961800000e+000) (6, -1.34015203834745670000e+001) (7, 2.58462046479162700000e+001) (8, 9.87078534328620360000e-001) (0, -1.14381059708818860000e-002) (1, -1.30770312037238960000e-001) (2, 8.95978703704863100000e-001) (3, -1.23977404160024780000e+000) (4, -1.25563297136585320000e+000) (5, 2.79669382609283050000e+000) (6, -1.66181432814846120000e+000) (7, 3.95402238195942110000e-002) (8, -1.32292683794346280000e-001) (0, 8.59120523685806780000e+000) (1, -1.11037346048600380000e+000) (2, 6.27829018134531220000e+000) (3, 1.30082685901262280000e+001) (4, -3.34282971757039750000e+001) (5, -5.53118693744229260000e+000) (6, -3.98411834609918270000e+000) (7, -1.57795622251429930000e+001) (8, -6.28326762546096100000e-001) (0, 1.07149588489460330000e+001) (1, 1.88924827890802760000e+001) (2, -9.29633614999471190000e+000) (3, 1.50372964785821320000e+001) (4, 6.70117985505445990000e+000) (5, -1.50504135355553570000e+001) (6, -2.61013259788721860000e+001) (7, -2.04635326293035080000e+001) (8, -1.04340389275527960000e+000) (0, -1.11140475190930640000e+000) (1, -1.60653578722293580000e+000) (2, 1.51554021173568000000e+000) (3, -6.90051576199004480000e+000) (4, 9.56922142389782590000e+000) (5, 8.52143780024751680000e+000) (6, 3.23508762748816280000e+000) (7, -1.21698500675006560000e+001) (8, -2.32716548999591270000e-001) (0, 1.39849812066257820000e+000) (1, 8.61601529074686030000e+000) (2, -8.16892654948812690000e+000) (3, 6.36336836822141480000e-001) (4, 8.06680739263651070000e+000) (5, -1.48723953627429890000e+001) (6, 1.11713929512570780000e+000) (7, 1.07975920330117850000e+001) (8, 7.25040023564779700000e-001) (0, -4.43696418986327860000e+000) (1, 2.66256600385343840000e+001) (2, 2.78513121744008440000e+000) (3, -6.31433067305806760000e+001) (4, 2.39316740342252880000e+001) (5, 5.01362249728758730000e+001) (6, 1.86557838191861580000e+001) (7, -7.11436753509110960000e+001) (8, 1.02448306784982310000e+000) (0, 5.79144783412034350000e-001) (1, 1.43320649271140330000e+001) (2, 6.33571676205498860000e+000) (3, -5.91404768826117580000e+001) (4, -4.96272963981008970000e+000) (5, 3.24869706686909230000e+001) (6, 3.99909832152131270000e+001) (7, -1.15303331903624820000e+001) (8, 8.25639120385379680000e-001) (0, 5.99496430418534840000e+000) (1, -1.35712501747790080000e+001) (2, 5.53854950698530320000e+000) (3, 4.43235284542270450000e+001) (4, -4.57711616373487620000e+001) (5, -1.46861468693530490000e+001) (6, -2.49742366267077140000e+001) (7, 6.88147040823490390000e+001) (8, -1.02382392958910670000e+000) (0, -1.83799755177819480000e+000) (1, 1.84394820941101870000e+000) (2, 1.20087393216049890000e+000) (3, -1.16337006054580420000e+001) (4, 7.14250998597441190000e+000) (5, 1.56767968971523480000e+001) (6, -6.61660566700805860000e-001) (7, 5.55247972735539630000e+000) (8, 6.79127845210731330000e-001) (9, 6.81894009508787090000e-001) (10, -5.46232695213857690000e+000) (11, -7.99378623942457400000e-001) (12, 5.50299127453898310000e-001) (13, 3.59844032613881590000e-001) (14, -1.28490591260434540000e+000) (15, -8.13345066382369360000e-002) (16, 4.81858426200300500000e-001) (17, 8.20521850933977890000e-002) (18, -1.19877802508824960000e+000) (19, 6.69673083604328310000e-001) (9, -5.04563948284941220000e-001) (10, 4.90809981992941500000e+000) (11, 3.51491016511401630000e-001) (12, -4.37465094129898260000e-001) (13, -3.81792254195192080000e-001) (14, 1.00169999083961650000e+000) (15, 3.02470820685367180000e-001) (16, -4.33192390995720540000e-001) (17, 9.32282592326859200000e-002) (18, 6.36409065190129300000e-001) (19, 7.82738597094949860000e-001) (9, -1.37714180717239980000e+000) (10, 2.23307358165100920000e+000) (11, 4.41743955105176890000e-001) (12, -2.31469180865707720000e-001) (13, -2.87310499378412620000e+000) (14, -6.81268252955702260000e-001) (15, 1.51639927300245590000e-001) (16, -4.34535868282895140000e-001) (17, -2.40853852385078890000e-001) (18, 2.10106630759811000000e+000) (19, 1.04351377605417060000e+000) (9, -2.54408668812696690000e-001) (10, 4.30870323721989120000e+000) (11, 6.40849244209172000000e-001) (12, -7.06221929185658510000e-001) (13, 1.45900568223926270000e+000) (14, 1.97004014136115320000e+000) (15, 5.41381421786991450000e-001) (16, -5.25901882827054860000e-001) (17, 5.98258124087819200000e-001) (18, -1.11636703686214330000e-001) (19, 1.03636814918501960000e+000) (9, 6.47338258551083680000e-002) (10, 2.09936350123278630000e+000) (11, 9.39453969923275570000e-001) (12, -3.66980323709086010000e-002) (13, -7.93253073450264970000e-001) (14, 2.78057764050001710000e-001) (15, -1.18775746196939620000e+000) (16, -2.23261090956717980000e-001) (17, -1.42313189834601620000e+000) (18, 2.22272541031341620000e+000) (19, 5.58605529045056120000e-001) 
