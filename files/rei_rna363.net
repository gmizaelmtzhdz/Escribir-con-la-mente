FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.46276145813678920000e+001) (1, 5.33869239894879260000e+001) (2, -1.85610663747108050000e+002) (3, -5.37510738103992040000e+000) (4, 3.00595708123629890000e+002) (5, 8.26602295049005780000e+000) (6, 3.04571936011984800000e+002) (7, -2.01412686875353830000e+001) (8, -6.64752896637241530000e+000) (0, 5.52782408877659390000e+000) (1, -1.92193160207350890000e+000) (2, 5.05017158150201690000e+000) (3, -3.77541507516116100000e+000) (4, 1.12346439550401150000e-001) (5, -3.95886237351123560000e+000) (6, 2.30664472658287690000e+000) (7, -1.38505465507345670000e+001) (8, -3.93625624004275140000e-001) (0, 1.01019135047528420000e+001) (1, 4.58967180556913730000e+001) (2, 6.87240111826394010000e+001) (3, 8.98544080605302470000e+001) (4, -3.27226653354405020000e+002) (5, -8.85816654191224160000e+001) (6, -7.31832010495313770000e+001) (7, 3.24067235660937970000e+002) (8, 2.50306701581066140000e+000) (0, 4.57385779011585570000e+000) (1, 1.01709274266436570000e-001) (2, 4.41782555091024240000e+000) (3, -3.68176298459398720000e+000) (4, 8.52072128237530760000e-001) (5, -3.02527363375706800000e+000) (6, 3.14648665113586070000e+000) (7, -9.63729228058174850000e+000) (8, -2.29359326927732310000e-001) (0, 9.92888924176134540000e+001) (1, 1.08984138907032620000e+003) (2, -4.15302406451004690000e+002) (3, 3.70617793991137530000e+001) (4, 1.49999866435020660000e+003) (5, -1.21869611864616190000e+003) (6, 1.44154991185972220000e+003) (7, -9.19707714899131250000e+002) (8, -7.26103676733010130000e+001) (0, 3.82416226846893800000e-001) (1, 6.64984890573074240000e+000) (2, 1.98860979005062300000e+000) (3, 1.57983692539786390000e+000) (4, -9.36215925647880100000e+000) (5, 3.54580843401672330000e+001) (6, -1.02677830567704690000e+001) (7, -9.22757193115346300000e+000) (8, -1.33343479894939150000e+000) (0, 1.10516486257435750000e+000) (1, 1.52988700916206110000e+001) (2, -1.64372237471041660000e+001) (3, 1.91197015609512950000e+001) (4, 3.83681331206243930000e+001) (5, -6.49623553078322830000e+001) (6, 3.87380458366313650000e+001) (7, 3.41709952598823610000e+001) (8, -1.09062038688292920000e+000) (0, 1.86134109841156500000e+000) (1, -6.63790245612485470000e+000) (2, 1.42080758837580020000e+000) (3, 6.29631028039744580000e+000) (4, 2.13679451128707040000e+001) (5, -5.77265248799138890000e+001) (6, 2.05164319088867120000e+001) (7, 5.12627513414743950000e+000) (8, 4.02010651285314320000e-001) (0, -5.11381267118387320000e+000) (1, 4.48464144181768280000e+000) (2, -5.66291221542333730000e+000) (3, -3.06922801859594730000e+000) (4, 1.42643980380598220000e+000) (5, 1.15440853494462240000e+001) (6, -4.84295860692560340000e+000) (7, 2.02908549300592220000e+001) (8, 5.38391040529090930000e-001) (0, -2.35407362646622740000e-001) (1, 1.88225590448486720000e-001) (2, 4.03262265160679260000e-001) (3, -6.09307182842893360000e+000) (4, 3.56797295777308940000e+000) (5, 8.49474524708427300000e+000) (6, -3.34989310648633860000e+000) (7, -1.36056143275512790000e+000) (8, -8.24211805260324890000e-001) (9, 1.80421622525209350000e-001) (10, -9.87892627913529830000e-001) (11, 7.92211012634699980000e-002) (12, 8.66644945054196980000e-001) (13, 1.28510659812416130000e-001) (14, 4.21631519914005380000e-001) (15, -7.17437560759808580000e-001) (16, 8.38741685422162650000e-001) (17, 2.64676731962541160000e-001) (18, -4.56664604844806700000e-001) (19, 2.98381449098195420000e-001) (9, -1.69937240731798080000e-001) (10, -1.93881658008115700000e+000) (11, -1.22831010967529490000e-001) (12, 1.95084581760677780000e+000) (13, -1.53370035372240950000e-001) (14, -8.82651531040052890000e-001) (15, 6.08212966402900350000e-001) (16, -1.16548941213357170000e+000) (17, -8.45666963577753280000e-001) (18, 5.93596627491447370000e-001) (19, 8.27287411914236160000e-001) (9, -1.17343504598723230000e-001) (10, 2.33120344881705770000e+000) (11, -1.55704922943388060000e-001) (12, -1.25846086285197270000e+000) (13, -3.21495984876462700000e-003) (14, 4.29669342823206240000e-001) (15, -4.07229959829851980000e-002) (16, 1.33417911885568810000e-001) (17, 1.55013431939921010000e+000) (18, -2.13165688312720070000e+000) (19, 3.03629138633930650000e-001) (9, -6.31592428536502520000e-002) (10, -6.86766838878311690000e-001) (11, -6.30456083765743810000e-003) (12, 6.13289563269012410000e-001) (13, -2.11447942576423630000e-001) (14, -1.73979269965151170000e-001) (15, 4.64995499149196300000e-001) (16, -3.00352363719089080000e-001) (17, -6.17619000745313730000e-001) (18, 1.04074068483891710000e+000) (19, 1.34910635535149810000e+000) (9, -5.90289215395963310000e-002) (10, 8.91147301803360040000e+000) (11, -8.90207133561385920000e-002) (12, -6.86298249799466120000e+000) (13, 6.07055231952791100000e-003) (14, 1.57209826410789870000e+000) (15, -1.30521485398508300000e-001) (16, 1.42035100354426660000e+000) (17, 3.92828439790776550000e+000) (18, -2.24845354431145730000e+000) (19, 7.73593913631545280000e-001) 
