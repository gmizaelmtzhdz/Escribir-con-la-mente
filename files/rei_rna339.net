FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.49780899256677090000e-001) (1, 1.53628246554230940000e-001) (2, -3.69485334693994140000e-001) (3, 4.04788463074326640000e-001) (4, -2.58596486413348270000e+000) (5, 2.07914976022788330000e-001) (6, -1.28376678827140370000e+000) (7, 4.01433436198161160000e+000) (8, -2.29184263364858610000e-001) (0, -1.97582949384749450000e+000) (1, 8.66516477249633540000e-001) (2, 1.70209089933757210000e+000) (3, -1.56443840994911480000e+001) (4, 1.13984066782507740000e+001) (5, 1.86480465957617090000e+001) (6, 4.27914470284748920000e+000) (7, -1.09361624639038710000e+000) (8, 1.81746972731541880000e+000) (0, -9.05101317938068380000e+000) (1, 8.62519763781796560000e+000) (2, 2.81527636789391970000e+000) (3, -2.50901493656125960000e+001) (4, 1.52558459432454880000e+001) (5, 2.60655941276877560000e+001) (6, -3.55970884845142950000e+001) (7, -4.70676099146857610000e+001) (8, -1.22712580863457150000e+000) (0, -3.20420527873238600000e+000) (1, -7.43084255832550420000e+000) (2, 3.81189107332864200000e+000) (3, 2.80306144799860490000e+001) (4, -1.45682665217678320000e+000) (5, -9.61927215194152120000e+000) (6, -3.59844261185771400000e+001) (7, 2.01638645326167810000e+001) (8, -2.93943612912505310000e-001) (0, -3.75607709273433610000e+000) (1, -4.68006965430405050000e+000) (2, 3.17020804373440290000e+000) (3, -4.67136264865613440000e+000) (4, -4.11459568576093200000e+000) (5, 1.07921742769771180000e+001) (6, 7.46147271700006080000e+000) (7, 1.15997088371472370000e+001) (8, 9.36974593123540180000e-003) (0, 3.96666206618481490000e+000) (1, 1.30745032868959670000e+001) (2, -1.52034993507062450000e+001) (3, 9.98837541236225410000e+000) (4, -2.53601790608593130000e+001) (5, -1.32127293737759360000e+001) (6, 7.73984737276638590000e+000) (7, 5.70216742150786260000e+001) (8, 1.68638423024183170000e+000) (0, 9.29158807541715090000e-002) (1, 4.27014616311410800000e-002) (2, -2.29747266968486520000e-001) (3, 5.04309173812240050000e-001) (4, -4.91228491406753840000e-001) (5, -4.49699955539036360000e-001) (6, 9.91532176624030370000e-002) (7, -4.48627514093595910000e-001) (8, -2.02148669928968460000e-001) (0, 1.93707486661562970000e+000) (1, 3.38137390345569690000e+000) (2, -1.61383080394886580000e+000) (3, -4.20581215570073660000e+000) (4, 2.17884799537573270000e+000) (5, -4.71951185888793980000e-001) (6, -1.23416193148010250000e-001) (7, -9.26347879292687180000e+000) (8, 6.56275504711945350000e-002) (0, 1.05729573039825320000e+001) (1, -8.35838083156669140000e+000) (2, -3.18789507534031280000e+000) (3, -1.21404003472282580000e+001) (4, 1.25969237386907520000e+001) (5, -1.99396605939063430000e+001) (6, 6.39208279026003940000e+001) (7, -2.73410988079617000000e+001) (8, -2.20933429737877360000e-001) (0, -1.28388630648863190000e-001) (1, -1.22662928983965200000e+000) (2, 6.37323549473776900000e-001) (3, 3.60460407394357270000e+000) (4, 6.53615498697000310000e-001) (5, -2.46633232022187880000e+000) (6, 2.11725454103669850000e+000) (7, -2.87536395767014290000e+000) (8, -1.71976101326249520000e-001) (9, -1.99654081512984560000e+000) (10, -5.55383656998244320000e-001) (11, 2.65199218900709580000e-001) (12, -4.58859322380079430000e-001) (13, -5.64183400005452970000e-001) (14, 5.38149895535285220000e-002) (15, 5.91735084020596820000e-001) (16, -1.93097780211573470000e+000) (17, -7.80977044048118410000e-002) (18, -6.58690405192551070000e-001) (19, 8.63655829708472100000e-001) (9, -1.90940128165125510000e+000) (10, 2.22483932805403520000e-001) (11, 2.69575345264149000000e-001) (12, 4.37575844629497170000e-001) (13, 5.46269272955974160000e-001) (14, 3.13298559835383130000e-001) (15, 3.03591779396669280000e+000) (16, 5.45055114523132820000e-001) (17, 1.16916898210531740000e-001) (18, -1.68504881038722830000e+000) (19, 6.58046749003126320000e-001) (9, 8.97698579335363970000e+000) (10, 1.73158441201483740000e+000) (11, 6.95615961151429870000e-001) (12, 7.62503020965538130000e-001) (13, 1.04263691678311530000e+000) (14, 3.64920996849317340000e-001) (15, -7.07694099532026130000e+000) (16, 4.33734822194615430000e+000) (17, 2.85800514072239660000e-001) (18, 6.80200585289411920000e+000) (19, 8.23388731973396130000e-001) (9, -2.68808985810237200000e+000) (10, -1.25009125871088120000e+000) (11, 5.68050244776014180000e-001) (12, 1.34077073215278200000e+000) (13, 2.10932038157006120000e+000) (14, 8.87328669230665670000e-001) (15, -9.89241255109667780000e+000) (16, 3.82387532216439750000e+000) (17, 5.25022099907303750000e-001) (18, -3.29668012761137830000e-001) (19, 4.98798120494989890000e-001) (9, 4.02545563309906120000e+000) (10, 1.42989814560861020000e+000) (11, 1.40810212640738990000e+000) (12, 1.67802862898770840000e+000) (13, 8.24811929076668340000e-001) (14, 8.45767243462081990000e-001) (15, -5.97085738332384700000e+000) (16, 2.98200234125103460000e+000) (17, 1.07570033472883810000e+000) (18, 1.81279420684332030000e+000) (19, 6.35048889280004470000e-001) 
