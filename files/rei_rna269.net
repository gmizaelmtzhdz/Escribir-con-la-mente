FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 2.76092305777803530000e-001) (1, -2.28550056350671230000e+000) (2, -3.77908529414792940000e+000) (3, -1.00710606553383370000e+001) (4, 8.39275444987304200000e+000) (5, 1.64250121934821640000e+001) (6, -4.68865080051557580000e-001) (7, 1.21415147433352820000e+001) (8, 2.11856337260246390000e-001) (0, 6.00275125375243950000e+000) (1, -1.12849352269415650000e+001) (2, 9.86803286337769240000e+000) (3, 3.83318178407559030000e+001) (4, 1.82580933952528280000e+001) (5, -3.86309528910682050000e+001) (6, 2.13256807302616340000e+001) (7, 3.04773148011928720000e+001) (8, -1.55978517584167450000e+000) (0, 4.74963048106404660000e-001) (1, -1.25721633663568880000e+000) (2, 1.65802977156676020000e+000) (3, 1.01725987140874760000e+001) (4, -4.04087007941138410000e+000) (5, -6.59852099804802880000e+000) (6, 2.75345335564778580000e+000) (7, 1.65632671439581820000e+000) (8, 2.24367595746759320000e-001) (0, 2.43199482457859920000e+000) (1, -1.25140619671288680000e+001) (2, -3.79625533493401200000e+000) (3, 2.71515339702848870000e+000) (4, 1.13285365360008080000e+001) (5, 1.89047972322159050000e+001) (6, -6.67215970117520300000e+000) (7, 3.40635378747769440000e+000) (8, -2.87066724828608270000e-002) (0, 2.07732281847652760000e+000) (1, -7.45492648545985760000e+000) (2, 9.10050331570898540000e-001) (3, 1.05897186094224430000e+001) (4, 1.57127896958375520000e+001) (5, -5.49092758577547450000e+000) (6, 8.71268327105923920000e+000) (7, -3.68606354898001150000e+000) (8, 1.81609153109599850000e-001) (0, 3.53486769545085130000e+000) (1, -4.39788329265189400000e+000) (2, 5.21802140571271790000e+000) (3, 2.77037416918996370000e+001) (4, -2.16770504517899310000e+001) (5, -1.67015385466996240000e+001) (6, 2.32529667186689750000e+000) (7, 5.57350605486337610000e+001) (8, -1.19258781755806730000e+000) (0, -6.40972989385437790000e-001) (1, -1.24463109315542420000e+001) (2, -1.92258654740590760000e-001) (3, 2.71766544280786740000e+001) (4, -1.77778044025124180000e+000) (5, -9.61948686441821190000e+000) (6, -1.83570048899273170000e+001) (7, 7.32917890511396930000e+000) (8, -3.21631286229988540000e-001) (0, -6.83783520415385590000e-001) (1, -1.39741128058979630000e+001) (2, 2.80224315959615740000e+000) (3, 7.55087966689268610000e+000) (4, -4.69522021750597140000e+000) (5, -2.94889014539523870000e-001) (6, -3.38677226163151660000e+000) (7, 8.91677075476830080000e+000) (8, -9.43495965735968580000e-002) (0, 9.45299949797609070000e+000) (1, 1.36602354356899890000e+000) (2, 5.40156057311116730000e+000) (3, 1.15556992196542790000e+001) (4, -3.26351479451571440000e+001) (5, -4.45232437977967080000e+000) (6, -5.90652148702153920000e+000) (7, -9.80207414061495900000e+000) (8, -9.26622124841582240000e-001) (0, -8.43701844570962400000e+000) (1, -1.89255877196070270000e+001) (2, 1.01812027097675570000e+001) (3, -7.75730606331234630000e+000) (4, -7.26532004502056240000e+000) (5, -7.54118752802774940000e+000) (6, 2.01808649006608680000e+001) (7, 2.25307636903616210000e+001) (8, 1.29697681782888030000e+000) (9, -1.38310807798896550000e+000) (10, -6.16968071130693850000e-001) (11, -7.05939732128214040000e-001) (12, -1.99192867686586030000e-002) (13, 1.24561095705913290000e+000) (14, 6.84864259944629520000e-001) (15, -9.37672357191641440000e-001) (16, 1.30193144173925000000e+000) (17, -6.86587945998258560000e-001) (18, -6.22301924818488560000e-001) (19, 5.96493152004043630000e-001) (9, 4.60748483734746970000e-001) (10, 2.30185581878115550000e-001) (11, 1.92334089702218240000e-001) (12, 4.77055719410257870000e-001) (13, -8.62202846088426230000e-001) (14, -2.28897488152638860000e-001) (15, 6.54410458734723140000e-001) (16, -1.43150082025212580000e+000) (17, 3.06109337259630960000e-001) (18, 5.87419878546159400000e-001) (19, 7.54199041182262110000e-001) (9, 1.39667181068621420000e+000) (10, 4.38607172243863530000e-001) (11, 2.36973738328046140000e+000) (12, 1.66578663406699410000e-001) (13, -1.36370878349620140000e+000) (14, -8.34113986808409090000e-001) (15, 6.86642340938668720000e-001) (16, -1.16310383729000780000e+000) (17, 4.54330121638123090000e-001) (18, 5.50884404632358440000e-001) (19, 5.59707843455528380000e-001) (9, -6.24571969611775820000e-002) (10, -7.44483492896743430000e-001) (11, -3.24521294369712710000e+000) (12, -3.38365166668869230000e-001) (13, 2.25901557409377900000e+000) (14, 8.29029794659169590000e-001) (15, 1.23590000776346140000e+000) (16, -1.91615249637999070000e+000) (17, 6.58088638083680460000e-001) (18, 8.28213083222196440000e-001) (19, 1.03642846581202530000e+000) (9, 2.77268747241215550000e+000) (10, -6.14611605843521260000e-001) (11, -1.71763621356821710000e+000) (12, -2.73108451725506910000e+000) (13, 2.87818161347760930000e+000) (14, -5.88286300942601130000e-002) (15, 1.43831834400023610000e+000) (16, 4.60748177755687220000e-001) (17, 7.89460591016237000000e-001) (18, -5.05574323069444830000e-002) (19, 8.76638703811208010000e-001) 
