FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 5.96081273019637780000e+000) (1, 1.73041665303494450000e+001) (2, 4.98244840992564610000e+000) (3, 2.24384505422358560000e+001) (4, -5.61848389338809650000e-001) (5, -2.72036459933187550000e+001) (6, 3.34952650741195510000e+001) (7, 1.81637486765656830000e+000) (8, 2.11674790683453930000e-001) (0, 1.00586661713896480000e+001) (1, 2.94147079019177760000e+000) (2, -1.03748073044074970000e+001) (3, 6.22655115236222370000e+001) (4, 2.81731016220754030000e+000) (5, -8.27677786912161650000e+001) (6, 5.45994101921766630000e+001) (7, 4.66610690369518930000e+001) (8, -1.36616845070611040000e-002) (0, 6.76683875940803040000e-001) (1, 7.79903553576090650000e-001) (2, 4.22543835196746360000e+000) (3, 1.28752573962447610000e+000) (4, 1.03530984970537300000e+000) (5, 5.24815747889404770000e-001) (6, 2.46637538759432420000e-001) (7, -1.32961085286923880000e+001) (8, -1.99593339693658530000e-001) (0, 3.89520162082377650000e+000) (1, 1.59882611406137550000e+000) (2, 6.90930341768486840000e+000) (3, -2.01007801636960260000e+001) (4, 4.17011051503318410000e-001) (5, 2.20226749829277360000e+001) (6, 6.31400909931064460000e+000) (7, -4.26900023993072470000e-001) (8, 2.66180598352959040000e-001) (0, 6.03420234950117540000e-001) (1, -2.70962182582186680000e-001) (2, 8.47687042934793020000e-001) (3, -3.91381338466937030000e+000) (4, 1.34955773120023540000e+000) (5, 3.77807299996082690000e+000) (6, -1.83926975574110200000e+000) (7, -7.69555440638615470000e-001) (8, 3.04165392311668870000e-002) (0, 4.56177011172807050000e+000) (1, 1.98332427911114770000e+001) (2, 1.81038927272042150000e+001) (3, -4.58819151299978230000e+000) (4, -2.33862441941311480000e+001) (5, 4.10671469318850480000e+001) (6, 6.33699842707973730000e+000) (7, 2.05303388142341210000e+000) (8, -1.10985659466511720000e-001) (0, -3.03613061015096930000e+000) (1, -7.14498611203631340000e-001) (2, -2.92088688985090390000e+000) (3, -4.04519182889307770000e+000) (4, -8.68978728710392720000e+000) (5, 4.08913035743982610000e+000) (6, -1.62229698973912230000e-001) (7, -6.21724176212498760000e+000) (8, 4.58847302914579920000e-001) (0, 7.46729177104420660000e-001) (1, 9.25564938322665220000e+000) (2, -4.31135046125493650000e+000) (3, 3.58464662126735220000e-001) (4, -1.59716861706622510000e+000) (5, -4.04956140382058650000e+000) (6, -1.19273983112654850000e+000) (7, 5.28297805713536840000e+000) (8, 1.35565910527216500000e-001) (0, -1.42032065436473660000e+000) (1, -7.46169241840487100000e+000) (2, -3.86761961573159810000e+000) (3, -4.13524636846043410000e+000) (4, 2.56844404685508280000e-003) (5, -8.68782256375697280000e-001) (6, 5.98164459654500650000e+000) (7, 1.85334289823393480000e+001) (8, 2.75429728468646660000e-001) (0, -3.23120809273218380000e+000) (1, -1.41907489573636740000e+001) (2, -3.44243223093677160000e+000) (3, 4.29290401718764370000e+001) (4, 3.04785513396423320000e+000) (5, -1.61967093647046700000e+001) (6, -3.18737286175260410000e+001) (7, 1.23637516559065810000e+001) (8, -3.10069063358179460000e-001) (9, -7.36444143772766900000e-001) (10, 9.90325672067655090000e-002) (11, -1.37147007550033910000e+000) (12, -1.38646692685784490000e+000) (13, -1.19090131020845890000e+000) (14, 4.52513331881162380000e-001) (15, -1.10304962509463470000e+000) (16, -1.29210286315713160000e+000) (17, -8.32994313201294470000e-001) (18, -7.82785480285423390000e-001) (19, 1.07712501102459800000e+000) (9, 7.19454665033591900000e-001) (10, -3.89843065732427050000e-001) (11, 2.14608302642400380000e+000) (12, 4.55330742780904680000e-001) (13, 1.62870860717832320000e+000) (14, -1.50668040340569490000e-001) (15, 7.17253509278269700000e-001) (16, 1.61501728755935030000e+000) (17, 1.60104265671699310000e+000) (18, 5.66483162102664920000e-001) (19, 5.19859167198685300000e-001) (9, 5.76533667997444770000e-001) (10, -3.42902458226495900000e-001) (11, 2.98784001850110000000e+000) (12, 1.78527680006998810000e+000) (13, -1.59602209827228500000e+000) (14, -4.27100767345754200000e-001) (15, 1.03050908515336870000e+000) (16, 1.95652526886515840000e+000) (17, 1.67736318559744070000e+000) (18, 8.99955522305509240000e-001) (19, 5.97074342353955070000e-001) (9, -1.09751420893273750000e-001) (10, 4.99731729584342450000e-002) (11, 4.75348848957523900000e+000) (12, -1.24628378466747370000e-001) (13, 2.99246540055660580000e+000) (14, 2.20607895683765820000e-001) (15, 4.05907678331858760000e-001) (16, 2.51492882623060420000e+000) (17, 2.99306534049907570000e+000) (18, 5.75165186624562950000e-001) (19, 9.16821351525027310000e-001) (9, 1.40389441194604950000e+000) (10, -5.43566220384272940000e-001) (11, 1.40839535173810650000e-001) (12, 1.71014530770078530000e+000) (13, -3.24371062095392850000e-001) (14, -1.12326571153909430000e+000) (15, 5.64479424614304000000e-001) (16, 7.91296807778285260000e-001) (17, 2.23493275592841740000e-001) (18, 8.17453554535946480000e-001) (19, 6.81594932646925170000e-001) 
