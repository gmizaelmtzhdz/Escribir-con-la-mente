FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 5.29496024368466940000e+000) (1, 1.70368610781650530000e+001) (2, -1.51991306435354070000e+001) (3, -3.00236100756708170000e+000) (4, 2.80025763155918490000e+001) (5, -3.49575426292222030000e+001) (6, 2.01110451567211720000e+001) (7, 7.90099317611849910000e+000) (8, 7.72760383942843850000e-001) (0, 2.21022116019382060000e+000) (1, -8.22127676691282260000e+000) (2, 2.24081689955854600000e+000) (3, -5.75760389182729870000e+000) (4, 1.20214912450191110000e+000) (5, -1.63589447693097000000e+000) (6, 1.52663716502202960000e+000) (7, 8.68244738980314960000e+000) (8, 8.59091063453256560000e-003) (0, 1.36583422058969560000e+000) (1, 4.17465507248993360000e+000) (2, 7.91059981787918160000e+000) (3, 3.31004336222725910000e+000) (4, -1.62102752730053760000e+001) (5, 4.73653005196441230000e+001) (6, -1.34582620684667940000e+001) (7, 2.72093178224289610000e+001) (8, -2.03070475194059890000e-002) (0, -6.88502364753883890000e+000) (1, -4.11895455804022820000e+001) (2, 8.34617430599886490000e+000) (3, 2.27645716155014560000e+001) (4, 8.04464401731407100000e-001) (5, 3.82154167082870530000e+000) (6, -3.45082210705238880000e+001) (7, 2.33789585216977900000e+001) (8, 1.56902708683291040000e+000) (0, 1.02855048100632800000e+001) (1, -3.13371959001576970000e+000) (2, 2.92870449175619290000e+000) (3, 2.26462740260193700000e+001) (4, -3.01829877824590230000e+001) (5, -1.34704971807129730000e+001) (6, 6.09259396526769750000e-001) (7, -1.97015412871105330000e+001) (8, -7.24703880900044890000e-001) (0, 1.50269771525888850000e+000) (1, -1.04018430348222000000e+000) (2, -2.43374210616735410000e+000) (3, 8.57094317898804900000e+000) (4, -6.55469777960519020000e+000) (5, -2.21594308534846610000e+001) (6, 3.64928205158341080000e+000) (7, -6.57394037432458060000e-001) (8, -4.60848029415239060000e-001) (0, 2.21075460484093540000e-001) (1, -3.63703237965431820000e+000) (2, 3.02719374467388660000e+000) (3, -1.02449565132160690000e+001) (4, 6.16006175120448240000e+000) (5, 8.10759792728037890000e+000) (6, 1.57919346668381120000e+000) (7, -3.87951262236540470000e-001) (8, -3.07578621195813750000e-001) (0, 2.69275808872899260000e-001) (1, 1.76296582824221630000e+001) (2, -6.22333552761361200000e+000) (3, 2.50152199173291300000e+000) (4, -6.20942956373346070000e-001) (5, -7.84409375626932000000e+000) (6, 6.90801389231137990000e+000) (7, -9.24260959774604270000e+000) (8, 5.55104124840750670000e-001) (0, 3.62962516285592200000e+000) (1, -1.17954246495358590000e+001) (2, 6.84734278253539940000e-001) (3, -4.69098837953093730000e+000) (4, 1.64586317698471270000e+001) (5, -1.53668348565680650000e+001) (6, 1.28770952988832120000e+001) (7, -9.22276764365059900000e-001) (8, 3.37612160892408920000e-001) (0, -1.08214401087985990000e+001) (1, 1.01221957248935010000e+001) (2, -2.47426467963144510000e+000) (3, -2.08844309662879330000e+001) (4, 1.06752204610198620000e+001) (5, 2.91856081930055780000e+001) (6, -1.55187664445189600000e+001) (7, 3.98964571978814040000e+001) (8, 5.21793793869059110000e-001) (9, -1.58475185623072280000e-001) (10, -1.04921335129859770000e+000) (11, 2.68401589999355760000e-001) (12, -3.24120150479936590000e-001) (13, -2.49250930794532670000e-001) (14, 1.07287911311965600000e+000) (15, 1.28860756294089910000e-001) (16, -9.11545455178406570000e-001) (17, 3.76050033700464300000e-001) (18, 4.17833653703922680000e-002) (19, 1.14650430409276760000e+000) (9, 8.04856391992529170000e-002) (10, 1.41618436397205820000e+000) (11, 5.06078903823769660000e-002) (12, 5.08072592036640010000e-001) (13, -3.22578343659617070000e-001) (14, -4.14097929372228000000e-001) (15, 5.89588269907826650000e-001) (16, 1.57588174760934980000e+000) (17, -7.82363296596825690000e-001) (18, -3.97793653213955880000e-001) (19, 1.91560870459715370000e-001) (9, -9.71418158604666740000e-001) (10, 6.60665886183313900000e-001) (11, -6.83106836346678010000e-001) (12, -1.71031399248852830000e-001) (13, 6.15084502584189790000e-001) (14, -2.00327302306314660000e+000) (15, -2.39967024674770670000e+000) (16, 6.59612320128664550000e-001) (17, 1.08619867491596020000e+000) (18, 6.51023688116263650000e-001) (19, 4.74274714930457420000e-001) (9, 8.75621381544607750000e-003) (10, -9.10587365570960320000e-001) (11, 1.40127356020876700000e-001) (12, 5.20985519147936120000e-001) (13, 1.26761130883338340000e+000) (14, 8.62957459655621870000e-001) (15, 1.87320663605196100000e+000) (16, 1.19311014742612300000e+000) (17, 9.18586371088627730000e-001) (18, 1.17312550868489800000e+000) (19, 8.34361842870299240000e-001) (9, 1.31750895901515340000e-001) (10, -7.16801043231068520000e-001) (11, -6.58844783468723220000e-001) (12, 1.73640165327236940000e-001) (13, 1.51200274671151600000e+000) (14, -1.29283325415477910000e+000) (15, -4.99818188019640120000e-001) (16, -1.52486995120752630000e-002) (17, 1.17065808605241160000e+000) (18, 1.25663788950981340000e+000) (19, 6.60845510655106110000e-001) 
