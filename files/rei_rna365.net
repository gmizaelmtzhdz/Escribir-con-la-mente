FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.01133125678955200000e+001) (1, -1.07385021813455880000e+000) (2, 1.49714698518841520000e+001) (3, -2.22172428710397970000e+001) (4, 4.74788118673627300000e+001) (5, -1.90792115925283130000e+002) (6, 8.48188760092366040000e+001) (7, 1.07110740676482050000e+001) (8, -1.51703571434453080000e+000) (0, 9.74343920669204720000e-001) (1, 1.77675406177943730000e+000) (2, 2.89912234853826690000e+000) (3, -2.24173952857356510000e+001) (4, -2.54914757191199830000e+000) (5, -3.16809390287087260000e+000) (6, 1.87468735474474710000e+001) (7, 7.79280226347405320000e+000) (8, -5.12420242489598830000e-001) (0, 1.85729706558253030000e+000) (1, 2.91287542601583560000e+000) (2, 4.88052191543148610000e+000) (3, -1.28023083246445460000e+001) (4, 1.27644064062808280000e+000) (5, 8.13514255857008810000e+000) (6, -2.81003563454196840000e+001) (7, 1.61353161208819740000e+001) (8, 2.61515770098576740000e-001) (0, 1.34293614631066770000e+001) (1, -8.03834086625303000000e+000) (2, 3.19518042286286490000e+001) (3, -1.40239023368116650000e+002) (4, -5.98817772891690150000e+001) (5, 2.81749405575906050000e+002) (6, -4.40228145522492120000e+000) (7, -9.76860144478064290000e+001) (8, 9.77798562472535690000e+000) (0, -6.74922878565014340000e+001) (1, 1.71780933580192860000e+001) (2, -6.09314613214649940000e+001) (3, 4.53136805393595670000e+001) (4, -7.67605941149617620000e+001) (5, 3.55789424912509840000e+002) (6, -1.46440272711692160000e+002) (7, 1.90479207641952190000e+001) (8, 2.48838327807548640000e+000) (0, -1.40769100826313330000e+000) (1, -8.16420960314465740000e+000) (2, -6.23484763143852750000e+000) (3, 4.07666257575223910000e+001) (4, 7.47815948901236100000e+000) (5, -2.27886598129429210000e+001) (6, -8.32734459419085300000e+000) (7, 8.81178961750609350000e+000) (8, -2.89955112111219160000e+000) (0, -3.47981014934311750000e+000) (1, 3.27248694861793150000e+001) (2, -1.21963412174871880000e+001) (3, 2.32072478105709080000e+000) (4, -1.88706937419504260000e+001) (5, -7.63875018990990460000e+000) (6, 2.79504020739432800000e+001) (7, -2.47370154086106140000e+000) (8, -1.07895546766512960000e+000) (0, 3.22881136409864090000e+000) (1, 2.14896039907165640000e+001) (2, 9.61254952227502810000e+000) (3, -4.46451028850404940000e+001) (4, -1.04538032844274670000e+001) (5, 1.55867321049784110000e+000) (6, -1.11929645946749470000e+001) (7, 3.92662609428083160000e+001) (8, -1.04628188775682780000e+000) (0, -1.69235090517557700000e-001) (1, 2.12175004284712010000e+000) (2, -1.23277672379307880000e-001) (3, -2.78339302185332430000e+000) (4, -1.49209296630168620000e+000) (5, 2.30758235322809420000e-001) (6, 3.65124943595260780000e+000) (7, -1.06672016985961960000e+000) (8, -1.60008358016779660000e+000) (0, 2.18561066722615320000e+002) (1, -2.86291170482243730000e+002) (2, 8.00901143489988390000e+002) (3, -5.93453117150083700000e+002) (4, -2.60210663068257020000e+002) (5, 1.50000000000000000000e+003) (6, -4.60271126146822330000e+002) (7, -7.21768547686160450000e+002) (8, 6.96024979790051930000e+001) (9, -3.33153205975466120000e-002) (10, -6.12521613400890620000e-001) (11, -7.56071652588580890000e-001) (12, -4.89453611431750650000e-001) (13, -2.03056589535254500000e-002) (14, -7.96221276892707610000e-001) (15, -1.97567568745566940000e-001) (16, 3.68853040572635570000e-001) (17, -2.18943477003713250000e-001) (18, -3.99503726487591640000e-001) (19, 6.47914118526863650000e-001) (9, -1.48843170809681070000e-001) (10, 6.40835219301742700000e-001) (11, 9.65123691756073930000e-001) (12, 4.05373324968803720000e-002) (13, -6.90796333873213710000e-002) (14, 6.21796965431390960000e-001) (15, 1.99019689100838280000e-001) (16, -5.29166560740651490000e-001) (17, 2.78978200564899080000e+000) (18, 3.53413540019113460000e-001) (19, 2.57340735429742780000e+000) (9, -4.50816231070506220000e-001) (10, 1.38691700755433440000e+000) (11, 1.98277594444063590000e+000) (12, 6.37943340728948760000e-001) (13, -4.03533014837161530000e-001) (14, 1.41704267793171310000e+000) (15, 6.56111346907328420000e-001) (16, -1.33991417009461440000e+000) (17, 3.65844194175462260000e+000) (18, -2.19820057237626680000e-001) (19, 3.89645652718493140000e+000) (9, 4.89899605568618950000e-001) (10, -1.68329936609397990000e-001) (11, 5.24374883241525560000e-002) (12, -4.78602066581775010000e-001) (13, 4.28740213952008900000e-001) (14, 2.85909439388695010000e-001) (15, -3.46497725569105130000e-001) (16, 6.12280094386867880000e-002) (17, 4.95038089280374560000e+000) (18, 8.98265781874105000000e-001) (19, 3.67060405435413490000e+000) (9, 6.22618796130773420000e-001) (10, -2.11053663606878380000e-001) (11, 1.86633845039676250000e-001) (12, 1.82552486036235420000e-001) (13, 5.28682283066852720000e-001) (14, 5.33075202232379700000e-001) (15, -3.89932509341892610000e-001) (16, -3.60114438606638780000e-002) (17, 5.77387762188524260000e+000) (18, 3.54257640063812620000e-002) (19, 4.56048327054623210000e+000) 
