FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -7.65760255000704550000e-001) (1, 2.20300288067465730000e+000) (2, 6.75227921918162610000e-001) (3, 4.61992749017340820000e+000) (4, 3.31586482614014600000e+000) (5, -1.30024361475642250000e+001) (6, 6.08485205013103060000e+000) (7, -4.57227168997116800000e+000) (8, -1.21716223553277230000e+000) (0, 7.67437001701100560000e+000) (1, 2.41354298963857650000e+000) (2, -9.56005166446110620000e+000) (3, -1.06977243111545160000e+001) (4, 2.13505163341930790000e+000) (5, -4.34269162991757090000e+000) (6, 4.08201216096178430000e+001) (7, -3.40259610140709650000e+001) (8, 8.43779120322096010000e-001) (0, 1.34661312023366410000e+001) (1, 1.30983383561810000000e+002) (2, -3.79756417760738000000e+001) (3, 1.29160749202326120000e+002) (4, -4.84872564723089110000e+002) (5, 3.85050173518678380000e+002) (6, -1.59194997689426370000e+002) (7, 1.50000000000000000000e+003) (8, 9.60996536605711430000e+000) (0, -4.06535519849841490000e-001) (1, -5.69842729446639830000e-001) (2, 2.28952234010326410000e+000) (3, -2.24288608312124050000e+000) (4, 3.18611732254435510000e+000) (5, -2.75135467548540790000e-001) (6, 7.07266674467517650000e+000) (7, -8.78652793872624470000e+000) (8, -1.83777134852962250000e+000) (0, 2.11333225187081660000e+001) (1, 1.98947330403254840000e+001) (2, -2.02213377041809430000e+001) (3, 1.81524243653988080000e+001) (4, -2.21477440180947160000e+001) (5, -3.75744533862678340000e+001) (6, 4.28765629326551120000e+001) (7, 1.73446678202508550000e+001) (8, 2.81623048723296380000e+000) (0, 1.37113061074281380000e+000) (1, -1.08377682647271010000e+000) (2, -4.99240403477478000000e+000) (3, -5.76065518425608760000e+000) (4, -4.53842017407905200000e-001) (5, 8.45956614896874020000e+000) (6, -4.75514651076999680000e+000) (7, 2.36858907134370030000e+000) (8, -1.44639328804138230000e+000) (0, -3.04466187547358170000e+000) (1, -9.39247615365386500000e+000) (2, 3.38098680575121070000e+000) (3, 2.00975593274723220000e+001) (4, 1.03348213712605550000e+001) (5, -1.58448918864170860000e+001) (6, -3.60636654317440350000e+001) (7, 3.63749235863230710000e+001) (8, -4.97745079380651270000e-001) (0, -1.10510700374450590000e+000) (1, -4.52429914769798990000e+000) (2, 3.72601562126756210000e+000) (3, -5.81255086293952770000e+000) (4, 3.92252225972091350000e+000) (5, 7.30899854377131850000e+000) (6, 6.40801023351749150000e+000) (7, -8.07226336946646760000e+000) (8, -1.66682624303325480000e+000) (0, 2.02566790158333230000e+000) (1, -1.93786446050093130000e-001) (2, -1.49842183605009310000e+001) (3, -9.09352510865739380000e+000) (4, 2.08313269986299830000e+001) (5, -3.14064648525370730000e+000) (6, 2.04680848340511400000e+001) (7, -3.72977909651099890000e+001) (8, -9.82288570810253780000e-001) (0, -3.07291177879076830000e+000) (1, 3.18940342958760590000e+000) (2, 9.14899643757734000000e+000) (3, -2.05531735524615830000e+000) (4, -1.03874838376232680000e+001) (5, 7.05865772183571670000e+000) (6, -2.44374354368049110000e-001) (7, 3.64009057519411080000e+000) (8, -6.47401118399726360000e-002) (9, 2.42056468082352880000e+000) (10, -1.52997417643253450000e-002) (11, -6.75984617196137980000e-002) (12, -2.88979735304498590000e+000) (13, -4.92569587758257600000e-001) (14, 7.35620911342383050000e-001) (15, -3.13944514144187610000e-001) (16, 1.95179611974233720000e+000) (17, -4.67693410117000770000e-001) (18, -3.68604293254160780000e-001) (19, 1.80463527569700060000e+000) (9, -1.50051298589883670000e-001) (10, 3.32443248473613560000e-001) (11, 2.21764421210836780000e-001) (12, 2.30546250044152720000e+000) (13, 1.33597060985732120000e-001) (14, 2.38456475427864900000e+000) (15, 6.58822253908238120000e-001) (16, -1.32910882479397950000e+000) (17, 5.53933110114805390000e-001) (18, 1.21993446253338630000e+000) (19, 2.81325324683478590000e+000) (9, -1.77807437205553560000e+000) (10, 4.49647264604660480000e-001) (11, 2.75597821202058830000e-001) (12, 1.11229509322005170000e+000) (13, -4.95981434762474690000e-001) (14, -1.11568277639604060000e+000) (15, 5.37573907491698420000e-001) (16, -1.95549163480393970000e+000) (17, 8.47133728566057840000e-001) (18, 1.02819318557127380000e+000) (19, -5.58867293618194210000e-001) (9, -5.64248910200061520000e-001) (10, 2.24653502093891180000e-001) (11, 4.33672076464939550000e-001) (12, 8.79494122733771280000e+000) (13, 2.37487754804495240000e-001) (14, 3.10616568002675340000e+000) (15, 7.35611913819421040000e-001) (16, -2.95821768906332980000e+000) (17, -2.09525939613089270000e-001) (18, 2.44842073152891830000e-001) (19, 5.83274702971387080000e+000) (9, -2.82742182757976490000e+000) (10, 2.18619158779426660000e+000) (11, 5.29429004302780610000e-001) (12, 5.08885177814726660000e+000) (13, -8.88869701546868620000e-001) (14, 1.17231532949287900000e+000) (15, 2.22669044435761570000e+000) (16, -4.15161476439005290000e+000) (17, 1.12077841344800460000e+000) (18, 2.30433589915363290000e+000) (19, 1.54072808393940730000e+000) 
