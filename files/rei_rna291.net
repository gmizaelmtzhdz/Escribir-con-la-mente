FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.86855192055657330000e+000) (1, 5.05210328064526410000e+000) (2, 5.29674249008115710000e+000) (3, -2.05292641199489980000e+000) (4, -1.73731978518406760000e+000) (5, -4.33270674334374000000e-001) (6, 3.72214225067823930000e+000) (7, -9.46652639185316500000e-001) (8, 4.93306919883581410000e-002) (0, -1.39860709859597490000e+000) (1, 8.67093841160090050000e+000) (2, 1.54082157147193490000e+000) (3, -1.02351304331392310000e+001) (4, 1.60658297682510140000e+001) (5, 2.06841464675207370000e+001) (6, -5.10832597701606520000e+000) (7, -3.52938729583574110000e+000) (8, 5.99116043217601920000e-001) (0, -1.47803882647439620000e+000) (1, 4.52165191170212480000e+000) (2, 1.58137471070676350000e+000) (3, 3.82662474661412140000e+000) (4, -1.80878009446954740000e+000) (5, -5.92149623235216800000e+000) (6, 6.45145855889894020000e+000) (7, -1.39017292139829450000e+000) (8, 1.07397600639266870000e-001) (0, -2.07498727749604630000e+000) (1, 2.28913092552312350000e+001) (2, 3.25562771304222090000e+000) (3, -1.27979850194327160000e+001) (4, -1.76272922576897990000e+000) (5, 3.80792840126546040000e+000) (6, -3.92470106753922600000e+000) (7, -1.09470238139409530000e+001) (8, 4.13896281614334120000e-001) (0, 5.98601027623912650000e-001) (1, 1.77825514707663640000e+001) (2, -6.06075678808989960000e+000) (3, 4.81353764370712330000e+000) (4, -2.15052035762949460000e-001) (5, -8.30828160996875200000e+000) (6, -1.01441153368556790000e+000) (7, 8.47581047217149000000e-001) (8, 2.41274961932869790000e-001) (0, -1.97449034225393020000e+001) (1, -1.08164764752728470000e+001) (2, -5.93587978897285780000e+001) (3, -6.79601324103140310000e+000) (4, 6.54738473785883170000e+001) (5, -4.19401153553740040000e+001) (6, -8.45852397517861300000e+000) (7, 1.33267985710602530000e+001) (8, -2.62798507437806750000e+000) (0, 6.67313417379174910000e-002) (1, 2.64302916274330830000e-001) (2, -1.54366919475938900000e+000) (3, 9.09809355337384050000e-001) (4, -2.85376526256592320000e-001) (5, -1.53798263785150270000e-001) (6, -1.00877713246585050000e+000) (7, 1.17768645434550190000e+000) (8, 1.87738663998403690000e-001) (0, 5.82846277814546370000e+000) (1, 4.17121818482128930000e+001) (2, -8.60658704419424580000e+000) (3, -4.05005645530060840000e+000) (4, 2.38407020723086910000e+001) (5, -4.12203240562763450000e+000) (6, -1.06944687509660030000e+001) (7, -4.83673962341279480000e+000) (8, -1.96314978071352120000e+000) (0, 7.97867895310273050000e+000) (1, -3.82903426044367020000e+000) (2, 8.83952322577801300000e+000) (3, -1.09787759472514800000e+001) (4, -3.90371162784425920000e+000) (5, -8.64396028036648870000e-004) (6, 5.56405056552730200000e-001) (7, -2.47315640725344860000e+001) (8, 6.04280813315058780000e-001) (0, 3.80443096094386220000e+000) (1, 4.05820841796624730000e+001) (2, -1.15276213654317950000e+001) (3, -4.80329984061010910000e-001) (4, 5.26441766060870810000e+000) (5, -9.38696288188299550000e+000) (6, -1.42870554318612070000e+001) (7, -3.33588825358092440000e+000) (8, -1.12707444624744270000e+000) (9, -1.58406786476648050000e+000) (10, -2.76456959642478020000e-001) (11, 2.45781011499984500000e+000) (12, 5.19207065849595530000e-001) (13, -2.65262810964539140000e+000) (14, -1.53398893610579600000e-001) (15, 7.73448183234818900000e-001) (16, 1.01313386733923020000e-001) (17, -4.21787538396827640000e-001) (18, 7.76803312952704330000e-001) (19, 1.14405461860111760000e+000) (9, 1.10158313953590190000e+000) (10, 4.38937991959748030000e-001) (11, -2.43297217324759620000e+000) (12, -3.00339381913256040000e-001) (13, 2.46935942270286990000e+000) (14, 8.96439819679270380000e-003) (15, -2.48668153607503320000e+000) (16, -3.13947257794393200000e-001) (17, 9.41736236325233510000e-002) (18, -5.80953413437450990000e-001) (19, 2.50442196488333270000e-001) (9, 3.71923689986509850000e-002) (10, 9.16489942411336190000e-001) (11, 6.42855407305775060000e-001) (12, -3.48956379537648800000e-001) (13, 5.33706056810362540000e-001) (14, 5.28366976019288840000e-002) (15, 1.33185480697465940000e+000) (16, -6.39947995627205390000e-001) (17, 4.12577071190038610000e-001) (18, 2.82268693234730970000e-001) (19, 1.65397892201374550000e-001) (9, -2.93412347090524440000e-001) (10, 1.55491845151736950000e-001) (11, -1.32632290688196800000e+000) (12, -2.19332751329084360000e-001) (13, 1.86445742828939580000e+000) (14, 1.49992910417622830000e-001) (15, -6.82619188449550850000e+000) (16, -4.84722685118007760000e-001) (17, -1.10773258532588290000e-001) (18, -9.60145840720196680000e-002) (19, 1.24404810619742400000e+000) (9, 3.98731837204173980000e+000) (10, 1.22158171033642300000e+000) (11, -1.96633882653722410000e+000) (12, -2.29884630335777420000e+000) (13, 1.34494690189335420000e+000) (14, 1.58120549128732570000e+000) (15, 4.36593979106542470000e+000) (16, -1.02116082269553780000e+000) (17, 1.25139754733608010000e+000) (18, 1.15871336189764260000e+000) (19, 1.53280835558968450000e+000) 
