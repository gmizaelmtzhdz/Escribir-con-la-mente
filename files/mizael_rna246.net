FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.97039867937565560396e-02) (1, 1.49420926272869181162e-01) (2, 1.78875053226947855478e-01) (3, 7.15814474225044961031e-02) (4, 1.80906617939472269541e-01) (5, 3.57972252368927712496e-02) (6, 1.50188097655773233896e-01) (7, 2.01531493961811136728e-01) (8, 1.98147544562816690927e-01) (0, 2.14367860853672098642e-01) (1, 1.25237086713314127451e-01) (2, 6.26307520270348305758e-02) (3, 3.57037800550461525972e-02) (4, 2.02113667428493570810e-01) (5, 1.19160281419754099375e-01) (6, 8.61622336506844277437e-02) (7, 1.55609080493450235849e-01) (8, 1.21543275117874216562e-01) (0, 1.72853851616382669931e-01) (1, 1.37671099901199411875e-01) (2, 1.99889847934246134287e-01) (3, 1.79154077470302652841e-01) (4, 1.13522903919220041757e-01) (5, 1.62658119499683451181e-01) (6, 1.44458973705768656259e-01) (7, 8.86426660418511147554e-02) (8, 1.72105381190776896005e-01) (0, -1.80108694285154413706e-01) (1, -1.63672575652599405771e-01) (2, -1.21724890470504831796e-01) (3, -9.45280137658119912203e-02) (4, -1.13968590199947428232e-01) (5, -1.92303964793682169443e-01) (6, -1.35652976036071848398e-01) (7, -6.23871478438378090914e-02) (8, -3.13973519206047768648e-02) (0, -1.19855748414993357187e-01) (1, -1.32199058234691690927e-01) (2, -4.98658660054207558687e-02) (3, -1.41708211898803781992e-01) (4, -1.37831205427646708017e-01) (5, -1.44628794789314341074e-01) (6, -9.90774649381638283785e-02) (7, -1.22127437889576029306e-01) (8, -1.62515142858028482920e-01) (0, -1.99917184114456247812e-01) (1, -5.59652093052864785250e-02) (2, -2.69060674309731240328e-02) (3, -9.83739066123963112886e-02) (4, -1.03111350834369730478e-01) (5, -1.09234975576400827890e-01) (6, -1.18484066724777292734e-01) (7, -1.43957288861274790293e-01) (8, -2.15712087154388498789e-01) (0, 6.41740541160107369478e-02) (1, 2.05016973614693398531e-02) (2, 9.29305794835091347750e-02) (3, 2.16279441416263651377e-01) (4, 6.03930111229420418795e-02) (5, 1.49258026778698038584e-01) (6, 1.14554556012153696543e-01) (7, 1.85864994227886271005e-01) (8, 5.52894267439842934664e-02) (0, 1.42250599265098642832e-01) (1, 7.02120269834995980318e-02) (2, 2.12902286946773600107e-01) (3, 1.30853252410888742929e-01) (4, 1.70356282889843058115e-01) (5, 1.00703241229057383066e-01) (6, 1.00987384021282267099e-01) (7, 4.86480835080147500094e-02) (8, 1.82872036397457193857e-01) (0, -6.36414232850075478609e-02) (1, -7.04293790459633584078e-02) (2, -1.59255405813455652719e-01) (3, -2.06156553626060556894e-01) (4, -5.03465625643730874117e-02) (5, -1.95220606327056955820e-01) (6, -2.13062623441219400888e-01) (7, -1.28720464110374521738e-01) (8, -7.83319416642189736422e-02) (0, -1.02297590970993113046e-01) (1, -2.72045227885246987398e-02) (2, -2.02289232909679483896e-01) (3, -9.80096700787544961031e-02) (4, -1.83030487895011972910e-01) (5, -2.01787548065185617929e-01) (6, -2.50790956616402382906e-02) (7, -1.86751054525375437265e-01) (8, -1.61394545733928751474e-01) (9, 1.44178913831710886484e-01) (10, 1.47803509533405375009e-01) (11, 4.44704610109329934176e-02) (12, 1.79468342959880899912e-01) (13, -1.69945908635854792124e-01) (14, -1.45317533910274576670e-01) (15, -6.76293912529946084078e-02) (16, 1.80907348096370768076e-01) (17, 4.50387540459633584078e-02) (18, -1.86926158070564341074e-01) (19, 6.18947203457356209810e-02) (9, 7.36868287622929329928e-02) (10, 2.15945893824100565439e-01) (11, 2.18253323733806681162e-01) (12, 2.32574510574341530855e-02) (13, -1.63309523761272501474e-01) (14, -2.07903245389461588388e-01) (15, -4.70891240239144082125e-02) (16, 1.01469891071319651132e-01) (17, 3.90341523289681191500e-02) (18, -1.55809583067894052988e-01) (19, 4.31379470229149575289e-02) (9, 1.56736561954021524912e-01) (10, 7.69859085977078194674e-02) (11, 6.08487184345722909029e-02) (12, 7.87269006669522042330e-02) (13, -1.26044580638408731943e-01) (14, -1.60938838422298502451e-01) (15, -1.66352210491895746713e-01) (16, 1.47204393446445536142e-01) (17, 1.37666644454002451425e-01) (18, -4.21732905507088418062e-02) (19, 7.50078986585140938814e-02) (9, 1.62137100398540567880e-01) (10, 1.57295057475566935068e-01) (11, 1.25062005519867014414e-01) (12, 3.68195641040802712496e-02) (13, -1.30334334373474192148e-01) (14, -1.54030674993991922861e-01) (15, -1.78141700029373240000e-01) (16, 1.42739521265029978281e-01) (17, 1.27864049673080515390e-01) (18, -1.24454872608184885507e-01) (19, 1.38685407042503427988e-01) (9, 1.26117365360260080820e-01) (10, 1.18802579045295786386e-01) (11, 1.95375898778438639170e-01) (12, 1.38214128017425608164e-01) (13, -1.48286545574665140634e-01) (14, -1.63154227584600519663e-01) (15, -8.27517452836037392672e-02) (16, 1.55903885066509317880e-01) (17, 9.99837237596512551363e-02) (18, -1.46015183925628733164e-01) (19, 2.12889799773693155771e-01) 
