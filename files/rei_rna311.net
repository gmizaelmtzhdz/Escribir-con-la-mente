FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.17378594268183200000e+000) (1, -7.50416643498494370000e+000) (2, -9.08919060102900290000e+000) (3, -9.90236008470519200000e+000) (4, 1.15630060723969410000e+001) (5, 1.11985701977603060000e+001) (6, 4.90940451028687710000e+000) (7, -3.80628114063433000000e+001) (8, 2.70324085815861810000e-001) (0, 4.62016650038687420000e-001) (1, -6.71307413952177860000e-001) (2, 3.63702167609699090000e-001) (3, -1.16930755143010500000e+000) (4, 6.91101375052510010000e-001) (5, 1.11068570465453510000e+000) (6, -3.35625613034198080000e-001) (7, -1.26330665062161840000e+000) (8, 7.17126010912364220000e-002) (0, -5.16539341735120860000e+000) (1, 2.66550466731763350000e+000) (2, 5.93401967504713210000e+000) (3, -2.67513828637295030000e+000) (4, 5.14208181423181720000e+000) (5, 1.61647305509314540000e+000) (6, 7.69632370962702780000e+000) (7, -1.11694699733841640000e+001) (8, -2.12654931348443570000e-001) (0, -1.10935511503661410000e+000) (1, 8.35107914021551070000e+000) (2, 7.40554643428313140000e+000) (3, -1.43874640488318840000e+001) (4, 8.43300377075043530000e+000) (5, 8.66264027666375290000e+000) (6, 1.93634447331744360000e+001) (7, -1.58907065343817940000e+001) (8, 1.27648981496665750000e+000) (0, -2.48865409387901120000e+000) (1, -9.67346015819187780000e+000) (2, 1.66590823224475460000e+001) (3, -9.12914780485340140000e+000) (4, 2.35845301932905680000e+001) (5, 1.27880635589750560000e+001) (6, -2.89130929183967260000e+000) (7, 9.59602514738545760000e+000) (8, 1.92270853495372430000e+000) (0, 4.72377154469812940000e+000) (1, 7.33015753507661570000e-001) (2, -1.72407217333114480000e+000) (3, 4.66361105493491030000e+000) (4, -1.48154920571778510000e+001) (5, -2.13450839066684090000e+000) (6, -2.66675246499024520000e+000) (7, 4.46185457507248810000e+000) (8, -1.60824516005617590000e-001) (0, -4.03924152292084050000e+000) (1, 1.69313214332152950000e+001) (2, -9.45978491683195520000e+000) (3, 9.68648949025694070000e+000) (4, -6.23372719286229590000e+000) (5, -5.03959725627227910000e-001) (6, -2.12668208179028410000e+000) (7, 2.77521260798635690000e+001) (8, 7.76899069053982320000e-001) (0, 3.17919349757358830000e+000) (1, -1.12188406315900880000e+000) (2, 5.78083688921289140000e-001) (3, -8.15533924688257980000e+000) (4, -8.58558402003882340000e-001) (5, -4.48738488893883240000e+000) (6, -2.40104195987550510000e+000) (7, 1.45868103629458300000e+001) (8, 9.80494165695415810000e-001) (0, 2.35306151795831970000e-001) (1, -2.59250348897034910000e-001) (2, -5.20918457577888090000e-002) (3, 2.24000114999410360000e-001) (4, -1.95970875411479730000e+000) (5, 5.00368781959710240000e-001) (6, -1.45525148449692950000e+000) (7, 1.57596422619013880000e+000) (8, -9.45805679681832050000e-002) (0, 1.22301396887142490000e-001) (1, 1.09235695721653450000e+001) (2, -6.91839905854833010000e-001) (3, -3.37494973762470220000e+000) (4, -1.88906630446163670000e+001) (5, 8.48946770943523890000e-001) (6, 1.34485626026019140000e+001) (7, -4.79008865679429880000e+000) (8, 9.53067007985313520000e-001) (9, -3.13090276052865100000e-001) (10, -2.09760663739432150000e-002) (11, -8.81383817002446830000e-001) (12, -3.80146203892558100000e-001) (13, 1.24929635520312330000e-001) (14, -9.89518866984857250000e-001) (15, -4.00590255348654610000e-001) (16, -4.56695612596785700000e-001) (17, -1.62106136176622880000e+000) (18, 6.92710954917174600000e-001) (19, 5.49337436278657390000e-001) (9, 4.34323136019854670000e-001) (10, 1.87179485403307110000e+000) (11, 1.17463235470894770000e+000) (12, -4.90273347107960250000e-002) (13, 1.37372187457486940000e-001) (14, 8.72794683918914900000e-001) (15, 7.03466201648307870000e-001) (16, 7.05839590160557860000e-001) (17, 1.73532131311444630000e+000) (18, -5.19714715588186050000e-001) (19, 5.70033320126792530000e-001) (9, 8.79342361594902750000e-001) (10, -5.15402406162437640000e+000) (11, 2.00550210908236660000e+000) (12, 6.01594863513458140000e-001) (13, 6.15238652530064930000e-001) (14, 2.48202303013110640000e+000) (15, 6.33133494879660640000e-001) (16, 7.85135667375890910000e-001) (17, 1.50607205024168710000e+000) (18, -1.16065217814470010000e+000) (19, 6.59990128106621830000e-001) (9, 9.68136215260050200000e-002) (10, 4.62974722236325050000e+000) (11, 1.01655204810580120000e+000) (12, -1.54734475610824340000e+000) (13, 4.80773153512963130000e-001) (14, 9.34079213842706870000e-001) (15, 4.69419569481221650000e-001) (16, 6.64324645431362490000e-001) (17, -4.96887987940126230000e+000) (18, 6.27203455992438600000e-002) (19, 8.35068380852799110000e-001) (9, 1.10303762006132520000e+000) (10, -5.55485423050245060000e+000) (11, 2.69757714777763890000e+000) (12, 1.77159965689433620000e-001) (13, 8.43983300937890420000e-001) (14, 3.46476115426063200000e+000) (15, 9.52427881097932750000e-001) (16, 1.74836900895233670000e+000) (17, -9.65800113580915550000e-001) (18, -1.91959098451555370000e+000) (19, 6.23280379746473210000e-001) 
