FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.14676945066225100000e+000) (1, 3.08039331786777690000e+000) (2, -1.14308636233236530000e+000) (3, -1.26941239605041240000e+001) (4, 1.30255863895994700000e+001) (5, 1.22228132399910850000e+001) (6, 4.89403335974246990000e+000) (7, 9.18723235504091850000e-001) (8, 4.74414012174040890000e-001) (0, 9.64881426707207220000e-001) (1, 1.13969451425508550000e+001) (2, -4.00336053808948030000e+000) (3, 1.39787912117939670000e-001) (4, 2.74564808028525990000e+000) (5, 1.70924535497159470000e+000) (6, 1.77854620988968540000e+000) (7, -8.96167716850946760000e+000) (8, 4.25052007129130100000e-001) (0, 5.99160448430620820000e+000) (1, -1.72170035027592800000e+001) (2, 3.01255656747618740000e+000) (3, 2.58085190833683880000e+001) (4, -7.97611901852478410000e+000) (5, 4.78446759313665650000e+000) (6, -1.53083509479293940000e+001) (7, 3.52686056081417480000e+001) (8, -4.49969293996304980000e-001) (0, 5.19867284122419630000e+000) (1, -1.16314868302738930000e-001) (2, 2.62963943545567650000e+000) (3, 1.18176541067935390000e+001) (4, -2.17441802945701750000e+001) (5, -6.51092110338788730000e+000) (6, -3.42979967992070070000e+000) (7, -4.05562127294844550000e+000) (8, -3.66495135110917750000e-001) (0, 1.58445453300582880000e+000) (1, -6.24137967320486450000e+000) (2, -8.04210822112602970000e-001) (3, 3.51534767432186480000e+000) (4, 7.05923317824102540000e+000) (5, 3.85141276777589800000e-001) (6, 2.76266983529534960000e+000) (7, 1.29507903121270790000e+001) (8, 3.33159147979604830000e-001) (0, -3.32669421736336090000e+000) (1, 7.59601468656934560000e+000) (2, 4.09777345609465330000e-001) (3, -1.19977374874272850000e+001) (4, -9.23132696462358400000e-001) (5, 1.34214481684964400000e+001) (6, -1.51015170649878020000e+000) (7, -3.99909936231916640000e+000) (8, 3.67469240305552280000e-001) (0, -1.37358810047161410000e-001) (1, -1.68348462517543920000e+000) (2, 2.86980460735427930000e-001) (3, 4.67155729607076160000e+000) (4, 7.56873530923365180000e-001) (5, -3.43920001943704400000e+000) (6, 6.69963648682308040000e+000) (7, -2.66485796046510660000e+000) (8, 2.63675146021551900000e-001) (0, 6.98571535869024980000e-001) (1, 1.63025504732555150000e+000) (2, 1.46411527351725200000e+000) (3, 1.87144274338947450000e+000) (4, -1.24228654508250840000e+001) (5, 4.68632085095533400000e+000) (6, -1.93899389228734510000e+000) (7, -6.21167258695720540000e-001) (8, 4.50124763491022840000e-002) (0, 1.52058953401770140000e+000) (1, 1.36348153259192180000e+001) (2, 4.31016594761760440000e+000) (3, -4.91882387392393810000e+001) (4, -2.52177377175377740000e+000) (5, 2.21094027433038680000e+001) (6, 3.48011536532110170000e+001) (7, -7.50944127933400110000e+000) (8, 2.81722362635647480000e-001) (0, -5.99355402829225080000e+000) (1, -1.13587274593036400000e+001) (2, 6.37783883587310640000e+000) (3, -1.18442382115456350000e+001) (4, -2.73599027084850110000e+000) (5, 9.70036384559129590000e+000) (6, 1.60155331943965610000e+001) (7, 8.25322447084851520000e+000) (8, 5.10790949529020600000e-001) (9, -1.78741868238953170000e+000) (10, -1.36798755390384260000e+000) (11, 3.16314783946182070000e-001) (12, -1.95656696417547330000e+000) (13, -3.45052221579771110000e-001) (14, 9.72384057267405400000e-001) (15, 2.76439246291610720000e+000) (16, 9.66829674688896910000e-001) (17, 5.22135627845220500000e-001) (18, -1.13367099789230920000e+000) (19, 6.79498924204919530000e-001) (9, 1.18445278301896790000e+000) (10, 1.43026095543770530000e+000) (11, -1.82075955508731620000e-001) (12, 9.80984846936575390000e-001) (13, 1.23436590718450660000e-001) (14, -9.42935943327577800000e-001) (15, -2.59092325471637610000e+000) (16, -2.53780387778570090000e-001) (17, -4.26680408890477200000e-001) (18, 1.03494394398233160000e+000) (19, 7.13779796984127080000e-001) (9, 2.54710139173666270000e+000) (10, 5.10153293837500970000e-001) (11, -6.50195211366829450000e-001) (12, 1.64025350130327910000e+000) (13, 4.22363659871125790000e-001) (14, -1.31892099530037750000e+000) (15, -1.64013317707990790000e+000) (16, 5.41776738262192190000e-001) (17, -5.94531635314049290000e-001) (18, 6.35892227944701240000e-001) (19, 7.92923884794284660000e-001) (9, -3.44204107775953450000e-001) (10, 1.60552240856238270000e+000) (11, -4.35738300439282630000e-001) (12, 2.89915143431393090000e+000) (13, 2.29646313827438320000e+000) (14, 1.81156448435474560000e+000) (15, -2.38861581907456830000e+000) (16, -3.68853410896573890000e+000) (17, -6.41908405667093950000e-001) (18, 1.51604426303408090000e+000) (19, 6.40097695253323160000e-001) (9, 2.53735750242899720000e+000) (10, -1.49666968183744520000e+000) (11, -1.22529265556039960000e+000) (12, 2.04515239633584710000e+000) (13, 2.33922955646817780000e+000) (14, -1.55887294738996710000e-001) (15, -1.08546008840986370000e+000) (16, 1.12312594732957130000e-001) (17, -6.47473385022482970000e-001) (18, -4.69672281880747780000e-001) (19, 9.52412426007023800000e-001) 
