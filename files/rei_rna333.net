FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -4.65756028176079200000e-001) (1, 6.38146888023170320000e-001) (2, -3.88623992071714550000e-001) (3, -1.47130335622333730000e+000) (4, -4.91517344224705430000e+000) (5, 3.56346409720640840000e+000) (6, -2.40186985054138400000e+000) (7, 2.33386364307080550000e+000) (8, -1.00667225046047350000e-001) (0, 2.16224115421318870000e+000) (1, 2.13692640654819360000e+001) (2, -3.61372338876360820000e+000) (3, -1.91670881205517920000e+000) (4, -1.66203676632856060000e+001) (5, -2.78152581900989260000e+000) (6, 9.07620999151547810000e+000) (7, -3.73091085743456090000e+000) (8, 8.98043631822395990000e-001) (0, 7.47125767091956750000e+000) (1, 4.39593896841256400000e+001) (2, -1.82527912842285430000e+001) (3, 1.83661277053015970000e+001) (4, -5.73167305610855140000e+000) (5, -4.42244723198251610000e+001) (6, 2.38009669093861940000e+001) (7, 2.26457391141965050000e+001) (8, 1.95872432744818780000e+000) (0, 1.65331753394176050000e+000) (1, 2.33808202963379140000e+000) (2, 1.07037872935549270000e+000) (3, -6.36345077816013020000e-001) (4, -5.58572926917623120000e+000) (5, -4.94907695769414680000e-001) (6, 1.46723038876952730000e+000) (7, -2.86439099324082570000e-001) (8, -1.44485902243636360000e-001) (0, 5.43188887245490900000e+000) (1, -1.21278385086312990000e+001) (2, -2.69939203755592190000e+000) (3, 4.21277501203045190000e+001) (4, -1.69225701343749190000e+001) (5, -4.40806915887836080000e+001) (6, -7.85886448333796220000e+000) (7, 2.00673159075189100000e+001) (8, -2.96862774757375860000e+000) (0, -9.64744866053059870000e-001) (1, 1.39785894371167870000e+001) (2, -6.30703194875889040000e+000) (3, -4.66060548622440330000e+000) (4, -6.89089525455178990000e-001) (5, -6.68277623400073460000e-001) (6, 1.07047700859704610000e+000) (7, -2.13547362247915680000e+000) (8, 9.16693186942317380000e-001) (0, 6.38687160428849320000e-001) (1, 8.11401181929596870000e-001) (2, 9.23624972765428430000e-001) (3, -1.76752215104056450000e+000) (4, 1.49552058603970810000e-001) (5, 9.16575710369922580000e-001) (6, 8.15422488205657440000e-001) (7, -2.15258392595822600000e+000) (8, -1.88009564852913170000e-001) (0, -9.14305389389247480000e+000) (1, -5.04934276596688840000e+000) (2, 1.49554035263826500000e+001) (3, -5.24331400917466940000e+001) (4, 3.89288904095308230000e+001) (5, 1.02633174914577180000e+002) (6, -5.60477790494858840000e+000) (7, -1.87833065488960250000e+001) (8, 3.82468948527705880000e+000) (0, 5.79492962570539840000e-001) (1, -4.24179058963642660000e-001) (2, 3.63541249793376400000e-002) (3, 2.82152750179747970000e+000) (4, -2.14472257196269740000e+000) (5, -2.60306088073075200000e+000) (6, 6.56835913646677930000e-001) (7, 1.59885770545871940000e+000) (8, 3.94715243254606180000e-002) (0, 8.61106880421866340000e-001) (1, -2.38074799848075180000e+000) (2, 2.64290388383287930000e+000) (3, 3.30264091010556650000e-001) (4, -6.72242662639283410000e+000) (5, 3.55283489551182050000e-001) (6, 1.03072530379736960000e+000) (7, 1.85220549083933820000e+000) (8, 1.76137007106164390000e-001) (9, -3.21447017981879220000e+000) (10, 7.50257610442337520000e-001) (11, -5.35775591863105190000e-001) (12, 3.03613055911210820000e+000) (13, -3.30938112992086720000e-002) (14, -5.91572887702177860000e-001) (15, -7.84262090076807010000e+000) (16, -1.64049772218178570000e-001) (17, -5.93585784573047000000e+000) (18, 2.71019873062470500000e-001) (19, 5.02733447315518830000e-001) (9, 1.13385736007460980000e+000) (10, -6.13010779979725200000e-001) (11, 8.11680540901271450000e-002) (12, -2.06521205606822370000e+000) (13, 3.15937002046246860000e-001) (14, 1.22112875615867260000e+000) (15, 4.38278089050206350000e+000) (16, 2.09655633775949120000e-001) (17, 2.06839137705481860000e+000) (18, 1.10572645135731950000e+000) (19, 7.95090557134737090000e-001) (9, 2.13413433979387790000e+000) (10, 4.56854509753531200000e-002) (11, -7.95619612401070820000e-001) (12, -6.85110634010520060000e+000) (13, 4.87712828148939010000e-001) (14, 1.92304011239248120000e+000) (15, 1.10140516093286800000e+001) (16, 7.04107272278792110000e-001) (17, 1.07260470732665370000e+001) (18, 1.32808133339877600000e+000) (19, 8.31847174331487140000e-001) (9, 2.29351618355181200000e-001) (10, -6.31526048168125190000e-001) (11, 3.39204026427944950000e-001) (12, -1.42275703606929030000e+000) (13, 7.45798447399648960000e-001) (14, 1.03436570721085360000e+000) (15, 3.45459210765863120000e+000) (16, 1.55130965624420220000e-001) (17, -7.83544060808513580000e-001) (18, 1.70101845627021040000e+000) (19, 1.21624117641383900000e+000) (9, -2.18272151634422550000e+000) (10, -1.76679769865132630000e+000) (11, 1.95527610756242560000e-001) (12, 4.91205185769346200000e+000) (13, 1.81138345911797540000e+000) (14, 1.67730652559880160000e+000) (15, -5.21007494736758310000e+000) (16, 1.46014294939809820000e+000) (17, -5.86640126557753310000e+000) (18, 1.04832234818397670000e+000) (19, 1.00520750366679710000e+000) 
