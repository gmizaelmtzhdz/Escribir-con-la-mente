FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.57470291355840090000e-001) (1, -1.40030963061909010000e+000) (2, 6.80667925226023370000e-001) (3, -7.42267566415376280000e-001) (4, -2.45087297177983300000e+000) (5, 1.68655906031533130000e+000) (6, -7.38616139806372640000e-001) (7, 1.60183070893193480000e+000) (8, -2.48029634548794590000e-001) (0, 3.05413749421234230000e-001) (1, -7.85963475150651190000e+000) (2, 5.06339535830081110000e+000) (3, -2.73371065402574680000e+000) (4, 1.45530097400428680000e+000) (5, 6.71035421003186360000e+000) (6, -1.57734785260777380000e+000) (7, 2.54221704662624100000e+000) (8, 5.69171856153673160000e-001) (0, 3.13102704118397360000e-001) (1, 3.41424932620675440000e+000) (2, 4.90804967301688090000e-002) (3, -4.48283088247345420000e+000) (4, -1.24529495550034030000e+000) (5, 8.40374751719375150000e-001) (6, 1.18602358520269720000e+000) (7, -3.06035418806134270000e+000) (8, 3.29010997317198540000e-002) (0, 9.79421291127274150000e+001) (1, -3.69885022900728520000e+001) (2, 1.50000000000000000000e+003) (3, 1.49964408369367590000e+002) (4, -5.27181282632409190000e+002) (5, 1.78515122241603540000e+002) (6, -6.35666234744126960000e+000) (7, -1.87811327875629360000e+002) (8, 8.32282665040351330000e+000) (0, -5.09907985485227490000e+000) (1, -2.67764585516917240000e+000) (2, -1.63069476798743800000e+001) (3, 2.29384100052519280000e+001) (4, -8.40685361413810560000e+000) (5, 3.03172196171023380000e+000) (6, -1.14015771145476140000e+001) (7, 4.07829935673725930000e+001) (8, -4.16368109010122170000e-001) (0, -2.52592479219025670000e-001) (1, -1.38768464581180440000e+001) (2, 1.07418191812220770000e+001) (3, -1.10895019424513760000e+001) (4, -1.24352137723456410000e+001) (5, 1.23854368347603360000e+001) (6, 2.67547507259647780000e+000) (7, -3.73145417922260680000e+000) (8, 6.39467447822455680000e-001) (0, -9.38646446979916390000e-001) (1, -2.72250866062888730000e-001) (2, 2.47154127278324110000e+000) (3, -1.08041726029899950000e+001) (4, 1.02794602452617720000e+001) (5, 1.89030383523994880000e+001) (6, 1.47983148207677840000e+000) (7, 1.16834120924231000000e+000) (8, 1.12748432835263570000e+000) (0, -4.11171624821618660000e+000) (1, -1.73275556627484200000e+001) (2, 3.05954783160220680000e-001) (3, -8.92071394841481440000e+000) (4, -2.13580293599154130000e+001) (5, 1.07352512774249540000e+001) (6, 8.85534083649730160000e+000) (7, -1.24482361884556660000e+000) (8, 1.84751576526636960000e+000) (0, -1.09222800047208260000e+000) (1, -1.08306954134888950000e+001) (2, -2.25911849290809920000e+000) (3, 1.83797421371237420000e+001) (4, -1.36008640810643320000e+000) (5, -8.16538217118938730000e+000) (6, -1.34346517778301790000e+001) (7, 1.65398830969588740000e+001) (8, -8.40255211635019960000e-002) (0, 5.62179688986375490000e-001) (1, 6.70973931422856750000e+000) (2, -5.42660415239738620000e-001) (3, -2.69445494737349240000e+000) (4, 1.70744287961151620000e+000) (5, -1.85164926374759940000e+000) (6, 3.29874176014666710000e+000) (7, -6.23608364131048540000e+000) (8, -1.13346867825821100000e-001) (9, -5.83271312858995380000e+000) (10, -1.14304246034631580000e+000) (11, 5.15372480248859620000e-001) (12, 5.56907888877647070000e-003) (13, 3.70520087014026220000e-001) (14, 1.24010069062187540000e+000) (15, -7.90877580106351450000e-001) (16, -7.81333964952923950000e-001) (17, -9.96506536297340760000e-001) (18, -3.27332757083321550000e+000) (19, 6.64547463072165830000e-001) (9, 2.66993623492563480000e+000) (10, 9.96926860514962380000e-001) (11, 1.13780155082828660000e+000) (12, 6.77992179107623490000e-002) (13, -7.70156718740711430000e-002) (14, -7.29462922218648830000e-001) (15, 8.94518189058882250000e-001) (16, 5.66650509445114190000e-001) (17, 9.41029385595008040000e-001) (18, 2.15918541620821670000e+000) (19, 2.86912989689663780000e-001) (9, 8.36069379503388530000e+000) (10, -1.51313993060346360000e+000) (11, -4.13768351257632090000e+000) (12, -3.99835880330198620000e-003) (13, -6.34022177347749460000e-001) (14, -4.48936412637891190000e-001) (15, 2.45981430583359150000e+000) (16, 7.44440761120483850000e-001) (17, 1.32482639265681710000e+000) (18, 4.43570722578280920000e+000) (19, 9.03756749805727180000e-001) (9, 3.88707233542540380000e+000) (10, 3.35176500548011450000e+000) (11, 3.14267205068563540000e-001) (12, -3.63384580014977590000e-001) (13, 9.03700492546878760000e-002) (14, -1.13655945304176240000e+000) (15, -5.10125191397396540000e-001) (16, 9.75655220558309440000e-001) (17, 1.27494379198470820000e+000) (18, 5.82833233995931630000e+000) (19, 1.22292076698751750000e+000) (9, 5.89770849432254800000e+000) (10, -5.35561710592371450000e-001) (11, -1.14482657224958450000e+000) (12, -8.30121219444969530000e-001) (13, -6.61458120708119820000e-001) (14, -6.64434768377254240000e-001) (15, 1.74369534254899160000e+000) (16, 4.49553126196668040000e-001) (17, 1.49245454951230490000e+000) (18, 2.50796074925939740000e+000) (19, 1.77741839970495550000e+000) 
