FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 5.49966354799108630000e+000) (1, -3.67433224139637550000e+000) (2, 6.89432945943944550000e+000) (3, -1.36800957210154190000e+001) (4, 2.23721020198784610000e+001) (5, -1.06141026861366900000e+001) (6, 7.65403524623521390000e+000) (7, -3.80145031135492460000e+001) (8, 5.65179420428897240000e-001) (0, -3.75718680294772730000e+000) (1, 5.47089793079933790000e+000) (2, -3.01438214665213390000e+000) (3, -1.77305831716422870000e+001) (4, 1.41341758650464000000e+001) (5, 1.97605364175182640000e+001) (6, -1.01468601332214940000e+000) (7, 1.31384529196046620000e+001) (8, 1.03183271936023410000e+000) (0, -2.34926550171715850000e-001) (1, 1.41164028470052170000e+001) (2, -6.29538110464974570000e+000) (3, 2.71688524544806450000e+000) (4, 2.27622004118365500000e-001) (5, -9.07753002131345180000e+000) (6, 2.08585935816049560000e+000) (7, 3.56298033722587880000e+000) (8, 1.15258905074038840000e+000) (0, -1.77745165479962930000e+000) (1, -2.76442999969281770000e+000) (2, -3.87360893954261610000e+000) (3, -2.43551724492622720000e+000) (4, 2.24036181147191770000e+000) (5, 7.12451696766632650000e+000) (6, -1.39694927142950040000e+001) (7, 1.57836791331483770000e+001) (8, 1.09560678313533720000e-001) (0, 3.75618038782239830000e+000) (1, 1.20489359251349700000e+001) (2, 1.53552842210018500000e-001) (3, -1.66533504316464080000e+000) (4, -3.58785400958433650000e+000) (5, 2.29403932567894350000e+000) (6, -1.40553731148387760000e+000) (7, 2.28083990710158770000e+001) (8, -1.64106411673830970000e-002) (0, 4.43971275192644650000e+000) (1, 1.70889852557310780000e+001) (2, 3.50353644583685100000e+000) (3, -2.38933693730408730000e+001) (4, -2.62356680064240550000e+000) (5, 1.86649237285163570000e+001) (6, 7.51111254584300170000e-001) (7, 5.73520186423856870000e+000) (8, -2.26529056330707740000e-002) (0, -1.83494124508648740000e-001) (1, 3.42229228899076370000e-001) (2, -1.62680066500742270000e+000) (3, 2.15288024870470100000e+000) (4, -1.45569647748985060000e+000) (5, -5.32708329169389930000e-001) (6, -2.85061321637158250000e+000) (7, 5.31846123415891460000e+000) (8, 9.54985244435202360000e-002) (0, -1.95880887401481730000e+000) (1, -1.31728261803078810000e+001) (2, -1.06605354225412130000e+000) (3, 2.40881739187903210000e+001) (4, 1.82657843146987050000e+000) (5, -1.32997544496972770000e+001) (6, -4.49815803804042870000e+000) (7, 1.71190639938248630000e+000) (8, -2.49612862714398280000e-001) (0, -6.27191368826748860000e-001) (1, 1.49092233801292350000e+000) (2, -8.10590356303555140000e-001) (3, 1.66156459847729070000e+000) (4, 3.69892294350239010000e-001) (5, -2.38380586036990620000e+000) (6, 2.13258645725539520000e+000) (7, -4.19306599041571310000e-003) (8, 1.52394126147933820000e-001) (0, -1.21248349682461410000e+000) (1, -1.09002040553720870000e+000) (2, 2.71609522530615770000e-001) (3, 1.06788754593311740000e+000) (4, 5.54246826290035250000e+000) (5, -1.93837290353927520000e+000) (6, 1.44525955146793270000e+000) (7, -4.67262907040552110000e+000) (8, 1.51385372674722050000e-001) (9, -7.42162414076827280000e-003) (10, -3.75412085261717380000e-001) (11, -9.99577700002569180000e-001) (12, -3.01073245433621900000e-002) (13, 2.03462460961915950000e-001) (14, -2.89224487278690320000e-001) (15, 1.44414059499626020000e+000) (16, -7.26380592415707630000e-001) (17, 1.98282135009893380000e+000) (18, 9.63354287575671320000e-001) (19, 9.15658923773354780000e-001) (9, -2.14119839748733080000e-001) (10, 3.16660779928519150000e-001) (11, 1.34019995093659940000e+000) (12, 5.46902739293774750000e-001) (13, -4.02344030605992330000e-001) (14, 4.74542227901005360000e-001) (15, -3.79738222107434490000e+000) (16, 8.69518506673966460000e-001) (17, -1.49270207438489870000e+000) (18, -1.24616423220920990000e+000) (19, 5.04962246764709690000e-001) (9, -1.26363012593251780000e-001) (10, 5.92860873883530370000e-001) (11, 1.11490812730747500000e+000) (12, -1.64510750773618510000e-001) (13, -1.53530003282490200000e+000) (14, 1.97585234688393040000e+000) (15, -2.26974748423947850000e+000) (16, 2.15814693780777360000e+000) (17, 1.58666199882631610000e-001) (18, -2.04367035452122940000e+000) (19, 6.74539129884998980000e-001) (9, 5.70637699581600590000e-002) (10, -5.15936944448635580000e-001) (11, 1.32431729358287020000e+000) (12, 2.57584388785065240000e+000) (13, 4.00696609182973840000e-001) (14, 2.06912183836469390000e-001) (15, -1.05032082274450560000e+001) (16, 1.20957901543979700000e+000) (17, 3.35819188840102360000e+000) (18, -3.33513408574802070000e+000) (19, 1.03992538798633040000e+000) (9, 7.51478244289938590000e-001) (10, 4.90372303514538590000e-001) (11, 6.71118747701717200000e-001) (12, 1.68497670454582330000e+000) (13, 3.17395372293513490000e-002) (14, 5.74645275385360030000e-001) (15, -5.33049477128318650000e+000) (16, 1.82931836086331660000e+000) (17, 3.83825955560646380000e+000) (18, -4.11322685223531350000e+000) (19, 6.85358869383846940000e-001) 
