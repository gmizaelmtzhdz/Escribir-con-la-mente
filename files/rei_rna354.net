FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -7.59261726841914970000e+000) (1, 1.54847761003048830000e+001) (2, 2.38031351360315000000e+001) (3, -7.32499556161386690000e+000) (4, -7.18984942488900460000e+000) (5, -3.04552608174549100000e+001) (6, 3.16232548110542240000e+001) (7, -3.74622706907477150000e+001) (8, -1.78386779486992330000e-001) (0, 1.41489937631862630000e+001) (1, 7.76745124538682050000e+000) (2, -1.22230249545030800000e+001) (3, -1.70753692396091710000e+000) (4, 4.31537960902231670000e+001) (5, -4.91081127282570690000e+001) (6, 1.79509644840851160000e+001) (7, 9.83532136960877250000e+000) (8, -7.40309648081886710000e-001) (0, -2.35947835018447270000e+000) (1, 7.87996451094803340000e+000) (2, 1.70742672477403450000e+001) (3, 1.78824582436561600000e+001) (4, -8.70914597992445390000e+000) (5, -5.21966848370793670000e+001) (6, 4.84143744769783520000e+001) (7, -4.34641620179719790000e+001) (8, -1.03890048014577970000e+000) (0, 4.03953969965971280000e+000) (1, 1.58371419856559450000e+001) (2, 4.96266841903905130000e+001) (3, -1.50034433272824690000e+001) (4, -5.37116510706819670000e+001) (5, -2.48267878929100360000e+000) (6, -1.92636231128014790000e+001) (7, 4.98388997316962660000e+001) (8, -6.90715661188223360000e-001) (0, 7.48930302830639590000e+000) (1, -8.40207256666639250000e+000) (2, 1.72965477833938910000e+001) (3, 2.29263726178362180000e+001) (4, -3.72654586013028820000e+001) (5, -9.14492844894780610000e-002) (6, -4.24784997949649320000e+000) (7, -3.24315488200611100000e+001) (8, -1.22203728860472590000e+000) (0, -5.72380946128917750000e-002) (1, 9.27376069826844150000e+000) (2, -1.35367341859288150000e+001) (3, 1.14763713917742830000e+001) (4, 1.49994340544980780000e+001) (5, -3.85344988034495590000e+001) (6, 8.31854376704653480000e+000) (7, 5.90808538386058050000e+001) (8, -8.58642036698390340000e-001) (0, -2.21968347281200780000e+002) (1, 9.04127974262374440000e+002) (2, 1.50000000000000000000e+003) (3, -9.59033742794636050000e+002) (4, 2.59375867017633820000e+002) (5, -2.10224624787684430000e+002) (6, 8.86521220478593020000e+002) (7, 5.87093018928145280000e+002) (8, 4.35879913824750530000e+001) (0, -1.36834958092331430000e+001) (1, -4.09391421800705610000e+001) (2, -4.60042000111891130000e+001) (3, 5.19829973572597270000e+001) (4, -8.49687087239120940000e+000) (5, 4.96036510648586240000e+001) (6, -4.00402936993123650000e+001) (7, 3.01385007813118970000e+001) (8, 1.42668623018739750000e+000) (0, -1.24244500417302710000e+000) (1, -1.35206969439402270000e-001) (2, 1.34049342075121650000e-001) (3, -4.93326180930858450000e+000) (4, 5.08643987528115280000e+000) (5, 2.17711436431149520000e+000) (6, 6.24476146264809810000e+000) (7, -9.77297386258733170000e+000) (8, 5.05293737629141870000e-001) (0, -1.23965364150926620000e+001) (1, -9.26670445039707860000e+000) (2, -7.68034005331485760000e+001) (3, 2.85385204813310870000e+001) (4, 8.32758877872312690000e+001) (5, -2.54353780592932280000e+001) (6, 2.28179608428624510000e+001) (7, -3.79993036873224170000e+001) (8, 1.50560515332596330000e+000) (9, -7.93886523118338960000e-001) (10, -2.06665855202006450000e-001) (11, 7.67943570188300060000e-001) (12, 5.27309383265572310000e-001) (13, -4.29992250645039710000e-001) (14, -3.36704951088885980000e-001) (15, -1.67167444466777890000e-001) (16, -1.97824645376958490000e-001) (17, 8.18881650072568470000e-002) (18, 4.11437768135611450000e-001) (19, 6.19790862429910770000e-001) (9, 3.82412331296361710000e-001) (10, -1.16613633842668150000e-001) (11, -4.76553970486322700000e-001) (12, -3.89107871083998910000e-001) (13, 2.03442961473877610000e-001) (14, 2.71379147781576510000e-001) (15, 1.76908246006154930000e-001) (16, -1.40628396769794120000e-002) (17, -1.50993060148524640000e-003) (18, -2.39074276694532160000e-001) (19, 6.92059781540196320000e-001) (9, 5.63094563321634430000e-001) (10, -3.80943828623604990000e-001) (11, -3.56368110359392360000e-001) (12, -1.22073488970899380000e+000) (13, 9.99330397020208910000e-003) (14, 2.84569732516351480000e-001) (15, 3.10430669138829500000e-001) (16, -2.14266053294731810000e-001) (17, -1.84863186377656400000e+000) (18, -7.07637914954690530000e-001) (19, 1.17612751342217160000e+000) (9, 7.50072222371247710000e-001) (10, 1.76969122069714990000e-001) (11, -9.59071583799656960000e-001) (12, -1.45544427549109350000e-001) (13, 1.05565472863200080000e+000) (14, 6.91309014361381370000e-001) (15, 2.49131246496545030000e-001) (16, 2.70734017954260830000e-001) (17, 1.60729838903211350000e+000) (18, -1.19171012344168830000e-001) (19, 7.78939410744830860000e-001) (9, 9.68995037645546400000e-001) (10, 5.79068993658207960000e-001) (11, -6.66629875757173700000e-001) (12, -7.14767519527266910000e-001) (13, 9.96219208401002420000e-002) (14, 8.11930590759534500000e-002) (15, 1.62862586640468680000e-001) (16, 4.47845549049217200000e-001) (17, -8.13579212388373050000e-001) (18, -6.44023730348629700000e-001) (19, 1.06960890450424470000e+000) 
