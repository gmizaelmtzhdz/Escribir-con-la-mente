FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.23912318808708590000e+000) (1, -2.03502835658819190000e+000) (2, 3.42579848061678670000e+000) (3, -4.19393395373806270000e-001) (4, 5.14611725945655960000e-001) (5, 8.72554997498281800000e-001) (6, 4.95870980646252120000e-001) (7, -5.09018962733521430000e-001) (8, -1.27738134791496850000e-002) (0, 2.10756564230347660000e-001) (1, -5.30287146952138500000e+000) (2, -9.18712876013823450000e+000) (3, -5.42363034282385040000e+000) (4, 5.13089984166161810000e+000) (5, 3.01324965605744840000e+000) (6, 5.51283755069685900000e+000) (7, -1.07395757474064890000e+001) (8, 2.60914234221961360000e-001) (0, 1.18694549377251630000e+000) (1, -2.91751005493390350000e-002) (2, 2.25864391531702860000e+000) (3, 1.06980301015905280000e+000) (4, 4.00492539841877450000e+000) (5, -1.61708140157617940000e+000) (6, 1.68000303858449680000e+000) (7, -2.66276001460608480000e-001) (8, -9.18772820448922060000e-002) (0, -1.70762110130543630000e+000) (1, -1.01036527883534770000e+001) (2, -5.43297373912420060000e-001) (3, 3.35430133290983650000e+001) (4, -1.83818334534364890000e+000) (5, -1.85595325288334370000e+001) (6, -1.79214853062739790000e+001) (7, 1.35887231819065890000e+001) (8, -5.78780572717373930000e-001) (0, -3.65559421984960390000e-001) (1, -6.16968210230258610000e-001) (2, 4.82033732841255970000e+000) (3, -1.41877434483816850000e+001) (4, 1.02989381718544660000e+001) (5, 1.88873366604533220000e+001) (6, 1.34844493025181640000e+000) (7, 3.58644270407331600000e+000) (8, 6.71090282565745770000e-001) (0, -1.09412509854049310000e+000) (1, 1.26282676348830840000e+001) (2, 1.00247043052119360000e+001) (3, -7.08590659876413740000e+000) (4, -1.86854934778152960000e+001) (5, 7.56486295499765940000e+000) (6, -9.67863236483454340000e+000) (7, 2.38476901266205770000e+001) (8, 9.55904736693293460000e-001) (0, 7.78983665796367350000e-001) (1, -1.52241830047910280000e+000) (2, 4.83839040033116400000e-001) (3, 4.66401462319513540000e+000) (4, -4.50107026292088240000e-002) (5, -1.76862692764901520000e+000) (6, -1.78287540582416450000e+000) (7, 3.75222373062887860000e+000) (8, -1.74146623380325830000e-001) (0, 1.04721074507394940000e-002) (1, 9.02396889612198190000e+000) (2, -4.16665270685063580000e+000) (3, -2.31045469227850390000e+000) (4, 1.30537641527130390000e+000) (5, -1.96690605200886680000e+000) (6, 6.75175093954741850000e-001) (7, 5.81696052240348220000e+000) (8, 8.21111601541515410000e-002) (0, 2.19745168698794040000e+000) (1, -1.09493048264275460000e+000) (2, 2.40530912280890490000e-001) (3, -1.49693811206814050000e+001) (4, 3.21811802914374350000e+000) (5, 5.79900628242531280000e+000) (6, 2.01575320207347050000e+000) (7, 3.11234025833188310000e+000) (8, 5.95052337325587380000e-001) (0, -7.46832071433403580000e-001) (1, 3.16215313819006380000e+000) (2, 1.03457259680733420000e+001) (3, -1.95124027270551180000e+000) (4, -6.00928573275026600000e+000) (5, 1.22971864139105370000e+000) (6, 3.01439238011417120000e+000) (7, -1.11609126383251760000e+001) (8, -2.10021312181344650000e-001) (9, -2.75889099186779600000e+000) (10, 2.29653034855680710000e-002) (11, 4.59217278494481460000e+000) (12, -6.16341852767698930000e-001) (13, -5.94956116666005670000e-001) (14, 1.10416542394311050000e+000) (15, -2.16240487695698350000e+000) (16, -2.26177918680969950000e+000) (17, -9.83603943021496900000e-001) (18, -1.30258683911804530000e+000) (19, 3.30287256043159120000e-001) (9, 4.15828794008936420000e+000) (10, -3.91177382602557190000e-001) (11, -4.42993416087780290000e+000) (12, 4.77217218140155160000e-001) (13, 7.06616786586226060000e-001) (14, -8.78276045841078880000e-001) (15, -5.35982539337757080000e-001) (16, 1.97702332798141270000e+000) (17, 6.92140125633745330000e-002) (18, 2.86972278416924800000e-001) (19, 9.03013005675779910000e-001) (9, -2.38557094970152940000e+000) (10, 2.31089187048071750000e+000) (11, -2.39085196583254730000e+000) (12, 9.77479911792117240000e-001) (13, 1.38237298066712230000e+000) (14, -2.55416352751268620000e-001) (15, 7.17677994958442780000e+000) (16, 2.23285021039865810000e+000) (17, 1.55443665765157340000e+000) (18, 3.40101903420449590000e+000) (19, 9.17252153914057790000e-001) (9, 4.78047718136423420000e+000) (10, 9.02688178848178310000e-001) (11, 5.07275276701082520000e-001) (12, 9.27683385754673910000e-001) (13, -1.83881550931799560000e-001) (14, 7.10277494440668900000e-001) (15, -4.86005619633105820000e+000) (16, 9.77716745881022420000e-001) (17, -5.47834681450519830000e-001) (18, -7.66575378918093800000e-001) (19, 6.50050775840544940000e-001) (9, -5.41449149687787210000e+000) (10, 2.04274974622042160000e+000) (11, 1.87869788680421830000e+000) (12, 1.56631308316508750000e+000) (13, 7.15587420051353230000e-001) (14, 2.33717468221485980000e-001) (15, 4.63309355149406970000e+000) (16, 8.40864271737616240000e-001) (17, 2.88521757753437800000e+000) (18, 2.74744150626851360000e+000) (19, 7.98886438222428890000e-001) 
