FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.90159784067550020000e-001) (1, 8.00472218330850890000e+000) (2, 2.91989872807466620000e+000) (3, -8.05799611084713340000e+000) (4, -1.69486393582668810000e+001) (5, 1.45045025382001750000e+001) (6, -9.40752530885366940000e+000) (7, 2.74358757381712910000e+001) (8, 1.05178567592624740000e+000) (0, -2.86442041573379800000e+000) (1, 5.02500351614758860000e+000) (2, -2.17589191226348880000e+000) (3, -2.69363675656939920000e+001) (4, 7.96714300834367780000e+000) (5, 2.85646730975648000000e+001) (6, 2.67544543916853290000e+000) (7, -3.97048501740164640000e+001) (8, -8.31139510560056530000e-001) (0, 8.87249922176663920000e-004) (1, 1.64193097712748410000e+000) (2, -4.03057359775277730000e-001) (3, 1.87900013498493550000e+000) (4, -2.55805984903706740000e+000) (5, -2.12367708269044450000e+000) (6, -6.63371506335440060000e-001) (7, 2.81466141480496250000e+000) (8, -1.86451096693691060000e-001) (0, 7.53047687827419490000e+000) (1, 1.57293007795667240000e+001) (2, -6.31118081042175930000e+000) (3, -4.87870520001361370000e+000) (4, 1.81980816672132240000e+001) (5, -7.34142574245724550000e+001) (6, 4.82923845548644050000e+001) (7, -1.74859199636720390000e+001) (8, -7.34928856287496710000e-001) (0, -1.52319773236417650000e+000) (1, -1.21860256682399620000e+001) (2, -1.83484494274179280000e+000) (3, 2.34326289158296640000e+001) (4, 7.09652752577886050000e+000) (5, -1.33882804300203520000e+001) (6, -1.62782578283278880000e+001) (7, 1.87856845193130940000e+001) (8, -5.23377002797261740000e-001) (0, -1.64061728389039470000e+000) (1, -7.25657682996550340000e+000) (2, 5.81817780932584410000e+000) (3, -3.62429333553659630000e+001) (4, 1.50063922547998650000e+001) (5, 8.44408656279849910000e+001) (6, 5.45612035648519900000e-001) (7, 5.57435714869995660000e-001) (8, 3.04371875109036650000e+000) (0, 1.72633579639676340000e+000) (1, 4.02644915409087110000e+000) (2, -1.99960700143825810000e+000) (3, 2.26021689563542560000e+000) (4, 1.86605838258023300000e+000) (5, -4.57627728914902580000e+000) (6, -7.05301598061551260000e+000) (7, -9.45444887484324780000e+000) (8, 7.56993020967835830000e-001) (0, 1.34020018955559110000e+000) (1, 1.27687692845434700000e+001) (2, -4.37590649334529050000e+000) (3, -4.22843327620267750000e+000) (4, 1.06553997793588520000e+000) (5, -1.35186156792510190000e+001) (6, 6.10760236089312510000e+000) (7, -9.25431016524999370000e-001) (8, 5.57692061560267630000e-001) (0, -1.87936693126318550000e-001) (1, 1.64598033600985170000e+000) (2, -2.61207019012606230000e-001) (3, -2.68596519695668890000e-001) (4, -4.34039804395493430000e+000) (5, 4.17624663033841070000e+000) (6, -5.23703280184468230000e+000) (7, 4.92868251431052510000e+000) (8, -1.22112318967441250000e-001) (0, 1.52398537935001110000e+000) (1, 4.74824359987614910000e-001) (2, 4.68256881886802530000e-001) (3, -2.39684814750605520000e+000) (4, 2.47252814972758950000e+000) (5, 1.23238391672317910000e-001) (6, 2.59160832625963570000e-001) (7, -1.22367558470775820000e+001) (8, 6.18685609811011510000e-001) (9, 8.43107505813521230000e-001) (10, 2.46284659243613310000e-001) (11, -1.80069384578563250000e-001) (12, 1.47799144385209250000e-001) (13, -4.56875742929263360000e-001) (14, -6.61252647274969800000e-001) (15, 1.88691703528255480000e+000) (16, -1.09329267692597280000e+000) (17, -3.18159920448996350000e+000) (18, -2.64223398297842270000e+000) (19, 9.95123368449482570000e-001) (9, -6.71005991080242840000e-001) (10, -8.56576195354014500000e-002) (11, -3.03080393036081420000e-001) (12, -5.14552608571854360000e-001) (13, 6.12823972246467670000e-001) (14, 4.54773859511899400000e-003) (15, -2.49915121598774940000e+000) (16, 1.98660543599055940000e+000) (17, 2.46694449033047560000e+000) (18, 3.03582593156486300000e+000) (19, 7.13462844691696190000e-001) (9, -4.22223650922659570000e-001) (10, 5.67465656450430120000e-001) (11, 5.76352075109224950000e+000) (12, -3.35252664919002550000e-002) (13, 5.28559137827115500000e-001) (14, 1.10894996235380280000e+000) (15, -1.42017717287152180000e+000) (16, 1.24319848995152710000e-001) (17, 3.97645212461138260000e-001) (18, 2.19135115864075880000e+000) (19, 8.94077942889997760000e-001) (9, 3.52207173408710490000e-001) (10, 2.56367955322088360000e-002) (11, -1.00928498261783380000e+000) (12, -3.09424447400024840000e-001) (13, 1.31523405692255960000e+000) (14, -8.35845506935400270000e-001) (15, -3.35456903974974270000e+000) (16, 1.95368821508549400000e+000) (17, 1.87114062095619800000e+000) (18, 4.94875637571054040000e+000) (19, 1.12080986255411140000e+000) (9, 8.39760949641155440000e-001) (10, 1.09059470993851960000e+000) (11, 3.32359718908803050000e+000) (12, 4.24878721030305610000e-001) (13, 1.85544006169520740000e+000) (14, 1.19928607327639100000e+000) (15, -1.79715112194332920000e+000) (16, 3.85956467489917910000e-001) (17, 7.53456424522415240000e-001) (18, 3.38381273243400750000e+000) (19, 5.30336686924845260000e-001) 
