FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 7.52466204736847470000e+000) (1, -4.48936693575827990000e-001) (2, -2.11345854351124050000e+000) (3, 2.01585047152868930000e-001) (4, 9.66510519560702260000e+000) (5, 3.49974545668733410000e+000) (6, -1.25637072967401280000e+001) (7, -4.63574511966291870000e+000) (8, -2.10191912935267430000e-001) (0, 5.09778500919490950000e-001) (1, -2.32600829086472150000e+000) (2, 4.29574929999076720000e+000) (3, -1.40552009714578720000e+001) (4, 1.50981023722263590000e+001) (5, 1.96683309063261400000e+001) (6, 4.26559498656280930000e+000) (7, -5.32674267047197870000e+000) (8, 6.39141097832215620000e-001) (0, 2.60422419630429060000e-001) (1, 1.69862894913101280000e-001) (2, 9.61162589004296570000e-002) (3, -2.25966234552099320000e+000) (4, 5.91070001230165620000e-001) (5, 3.21366605247252820000e-002) (6, 3.53884463912774120000e-001) (7, -1.28304485902252210000e+000) (8, 3.74282428910834020000e-001) (0, 1.68457811614302510000e-001) (1, 4.76406399141567590000e+000) (2, -4.03653516283607770000e+000) (3, 1.05389357891000050000e+001) (4, 6.41532569027709500000e-001) (5, -1.44427736778608620000e+001) (6, -4.05202835182002370000e+000) (7, 6.07427967086689070000e+000) (8, 7.63417823532649090000e-001) (0, 9.85513633595193110000e+000) (1, -3.17012298941738860000e+000) (2, 1.56408912187835150000e+000) (3, -8.34689209002971030000e+000) (4, 3.63395894668621060000e+000) (5, -1.58704407007997750000e+000) (6, -2.60038603886879490000e-001) (7, -1.97657272691131110000e+001) (8, 6.48920064187844540000e-002) (0, 6.95602818390367170000e+000) (1, 5.52102427558532940000e+000) (2, -1.25153022181062300000e+001) (3, -1.84700149504076560000e+001) (4, -9.94601412825700490000e+000) (5, 2.73525626749045370000e+001) (6, 4.50432677063410050000e+001) (7, -4.46844885427378390000e+001) (8, -2.85735735309635590000e-001) (0, 1.25207453524300470000e+000) (1, -5.56169981056276130000e-001) (2, 2.49611726665610600000e+000) (3, -4.91092908734572300000e+000) (4, 2.04820116242435500000e+000) (5, 6.50449128641919950000e-001) (6, 1.49651526956315650000e+000) (7, -4.73202589751917110000e+000) (8, -4.08541039409584810000e-002) (0, 1.06869296606913490000e+000) (1, 7.10822169141311580000e-001) (2, 2.58477764366122420000e+000) (3, 3.30440251300731270000e+000) (4, 5.23337528934163210000e+000) (5, -1.77048223070924210000e+001) (6, 1.37214323847349220000e+000) (7, 1.58724281483543340000e-001) (8, -1.54674406575231650000e-001) (0, 1.74225823435705040000e+001) (1, -6.61143265262101650000e+000) (2, -2.22602254469135090000e+001) (3, -1.97298873540048090000e+001) (4, 1.46638056194823300000e+001) (5, 4.98917151950832860000e+000) (6, 7.15229834657691160000e+001) (7, -5.03489075336740160000e+001) (8, -9.96892830997400450000e-001) (0, -1.94888254809473200000e+000) (1, -1.11729644052839950000e+001) (2, 2.06614913217520990000e+001) (3, -2.63472483100560770000e+000) (4, 1.31815462084338170000e+001) (5, -2.70395531637226620000e+001) (6, -6.23339465690965430000e+000) (7, 1.19770074874123300000e+001) (8, -5.04228488899291730000e-001) (9, 6.06801033848940570000e-001) (10, -4.06531027502850110000e-002) (11, 2.50929638223388360000e+000) (12, -2.36628709255851130000e+000) (13, -2.82124812999389800000e-001) (14, 4.48574680972719080000e-001) (15, -3.87561334653102740000e+000) (16, 2.57819864109976170000e+000) (17, -3.13479666855238540000e-001) (18, -2.16876182541657640000e-001) (19, 1.04273169850833970000e+000) (9, -7.93315376895638580000e-001) (10, 4.92970120478794850000e-001) (11, -8.38912345490124940000e-001) (12, 5.70591569243177890000e-001) (13, 4.15661261241638710000e-001) (14, -7.76762018174746110000e-001) (15, 2.02022285897839640000e+000) (16, -5.93911988038111520000e-001) (17, 1.98211242954411980000e-001) (18, -6.54846737658107520000e-001) (19, 3.69864153547560910000e-001) (9, -1.47730174440259290000e+000) (10, 1.33708944547358090000e+000) (11, -3.71998302434405700000e+000) (12, 6.37420746149100490000e-002) (13, 1.57336938349671130000e+000) (14, -4.80455725171995530000e-001) (15, -5.41869702324005890000e-001) (16, 6.78836717149663980000e-001) (17, -1.70677613684802250000e-001) (18, -8.52881132707237640000e-001) (19, 6.94215055400267730000e-001) (9, -1.01536808247522710000e+000) (10, -1.64175695095192640000e-001) (11, -4.28584440628451890000e+000) (12, 4.92279316158025780000e-001) (13, 3.05245549840947540000e-001) (14, -1.40450866119908960000e+000) (15, 5.11229218673998000000e+000) (16, -7.35236685537700270000e-001) (17, 5.83022727588167530000e-001) (18, -9.95938039949923030000e-001) (19, 1.42977267944522500000e+000) (9, -1.16479018062430570000e+000) (10, 8.18779101522825290000e-001) (11, -2.54240807148498060000e+000) (12, 6.94246240107209700000e-001) (13, 1.15315491356114120000e+000) (14, -1.13887532495668940000e+000) (15, 1.20862365762043480000e+000) (16, -4.88014961082950500000e-001) (17, 3.89730084168356420000e-001) (18, -6.52308612421581560000e-001) (19, 7.07153944659606350000e-001) 
