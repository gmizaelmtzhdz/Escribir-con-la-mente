FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -7.36472211626245430000e+000) (1, -3.54485765284090490000e+001) (2, -1.54784564570779310000e+000) (3, -7.82781453801506990000e+000) (4, -5.12290347884306170000e+001) (5, -9.87013352332313860000e+000) (6, 2.07042331641600580000e+001) (7, 1.19653804295216300000e+001) (8, 3.54150786588807920000e+000) (0, -1.16628861471631100000e+001) (1, -4.90763936864702540000e+001) (2, -1.00306591132916450000e+000) (3, -3.06063331292854070000e+001) (4, 1.94705689207698280000e+001) (5, 1.61760296278018000000e+001) (6, 1.92268036077800740000e+001) (7, -6.47205559316641230000e+001) (8, 2.39975367990876980000e+000) (0, -2.11434668315182870000e+000) (1, -1.35382248201039260000e+000) (2, 1.37902133676791780000e+000) (3, -1.48124101766035070000e+001) (4, 1.28040642607738760000e+001) (5, 1.09274395003213820000e+001) (6, 7.82233828721099810000e-001) (7, -1.13233327024967330000e+001) (8, -1.45393722303658370000e+000) (0, 1.39707824998233560000e+001) (1, 7.25713139510389600000e+001) (2, -4.22522594598600510000e+000) (3, 4.01449427642765000000e+001) (4, -5.51562770292038280000e+001) (5, -3.85552563875953350000e+001) (6, -2.02700931846480370000e+001) (7, 1.15921522019143890000e+002) (8, -2.71458615210662440000e+000) (0, -6.56106838737610330000e+001) (1, -9.84104262926048820000e+001) (2, 2.91301077718834050000e+002) (3, 6.90700808114273550000e+000) (4, -2.85124092352352700000e+002) (5, 9.48696766831640160000e+002) (6, -4.61993982059182710000e+002) (7, -1.07913608753213030000e+002) (8, -1.27148899339121740000e+001) (0, 4.83384466892517930000e+000) (1, 1.72826214320725030000e+001) (2, -2.26046433077632470000e+001) (3, 3.21649770213529820000e+001) (4, -8.93676531478737250000e+001) (5, -4.08751865651781690000e+001) (6, -3.30933306626386710000e+001) (7, 1.62497637612033200000e+002) (8, 1.05730978262189050000e+001) (0, 1.29843164482279420000e+001) (1, 2.49394229225610720000e+001) (2, 3.43357645519503320000e+000) (3, 3.86378096438894330000e+001) (4, -2.15756280560986760000e+001) (5, -1.62976552512632120000e+001) (6, -4.20706402735831460000e+000) (7, -4.76199903556570270000e+000) (8, -6.67778556971330510000e+000) (0, -1.63759811068655540000e+000) (1, -2.42036678792490110000e+001) (2, 1.27232292780625470000e+000) (3, 1.73649195805862920000e+001) (4, -3.97577688126239210000e+000) (5, -6.28795338214738830000e+000) (6, -5.78915965617862760000e+000) (7, -2.66649041728902430000e+000) (8, -6.10574609049916870000e-002) (0, 8.52939885568412940000e-001) (1, 3.53339289379755570000e+001) (2, 4.29378468697408170000e+000) (3, -6.14054891195527970000e+001) (4, -7.90849602665208720000e+000) (5, 2.10090664720746540000e+001) (6, 4.71456759426609370000e+001) (7, -1.15660939020410450000e+001) (8, 3.67314739102835190000e-001) (0, -4.84299165277945320000e+001) (1, -8.12006661824025710000e+001) (2, 1.19336867939119700000e+002) (3, -2.02131037610947490000e+002) (4, 2.28872488024845320000e+002) (5, 4.88160115140102620000e+002) (6, -7.35544113854965500000e+001) (7, -9.25636096624923110000e+001) (8, 1.93246468198365910000e+001) (9, -5.39729351840427580000e-001) (10, 1.05545681904784660000e+000) (11, -1.64654973618866830000e-001) (12, 8.10288905633556930000e-001) (13, 3.63431772556921660000e-002) (14, -3.13131149077299720000e-001) (15, -2.22523077123254700000e-001) (16, 9.53460866396167780000e-001) (17, 3.49698617427292520000e-001) (18, -2.07893507947830490000e-001) (19, 1.20106066249511260000e+000) (9, 6.09213043212985080000e-001) (10, -1.00532482898874000000e+000) (11, 1.05164167644891760000e+000) (12, -7.29101153241535240000e-001) (13, -1.37750557440196020000e-002) (14, 6.62493856914162290000e-001) (15, 2.67715820861449070000e-001) (16, -9.84524179031135540000e-001) (17, -3.99591666755021950000e-001) (18, 1.15635972203341900000e-001) (19, 5.03571067081867940000e-001) (9, 1.07592840274884530000e-001) (10, 1.85497573738950650000e-001) (11, -1.28186955769917940000e+000) (12, -1.39063937183534940000e-001) (13, 8.53882491919234630000e-002) (14, -1.57533352948578730000e-001) (15, -1.05304572466935450000e-001) (16, -1.12774231433055850000e+000) (17, -3.55671354880379040000e-001) (18, 1.92166073021009830000e-001) (19, -1.54915275510737030000e-001) (9, 7.82519381172598670000e-001) (10, -1.24215220639859460000e+000) (11, 3.66839344577548500000e+000) (12, -4.37545099754745700000e-001) (13, -1.14377065665087980000e-001) (14, 1.18424090882386480000e+000) (15, 9.37895743539025940000e-001) (16, 7.49884901280643560000e-002) (17, -2.67909305779861440000e-001) (18, 1.92589597833801890000e-001) (19, 2.48972511369866820000e+000) (9, 4.48162123951150180000e-001) (10, -9.41436865288375560000e-001) (11, 2.15227504611741070000e+000) (12, -5.69183586751128900000e-001) (13, -1.31229795475250900000e-001) (14, 1.20201055697097670000e+000) (15, 6.79120521214690460000e-001) (16, -4.15152488819815480000e-001) (17, -4.22706782683918430000e-001) (18, 4.89137201715975470000e-001) (19, 1.08751699317601360000e+000) 
