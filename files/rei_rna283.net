FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.66692459055806320000e-001) (1, 5.73341735738717160000e-001) (2, 6.49888516815612940000e-002) (3, 9.90268298422312900000e-001) (4, -2.29085011761879760000e+000) (5, 7.33043819116316330000e-001) (6, -9.41930783850826180000e-001) (7, 2.90128703613070020000e+000) (8, -2.55859690647173790000e-001) (0, -3.07183992871124630000e-002) (1, 1.01695736203661490000e-001) (2, 3.77259616925853970000e-001) (3, 4.71737176466399880000e+000) (4, -1.98406308151799830000e-001) (5, -6.73951010595568700000e+000) (6, 4.76128772032887680000e+000) (7, -1.85191728775383790000e+000) (8, 4.48307194932666630000e-001) (0, -8.30689412150875770000e-001) (1, -1.75664834733082520000e+000) (2, 3.11733584841530660000e+000) (3, -7.01448305933343970000e+000) (4, 8.50148862544907180000e-001) (5, 1.13215307245758420000e+001) (6, 1.23835870399347450000e+000) (7, 1.50677022094652500000e+000) (8, 4.19158874654105230000e-001) (0, 7.00952894951331730000e+000) (1, 3.94700956100962500000e+000) (2, -1.67250663420863450000e+000) (3, 1.16600309334384060000e+001) (4, 1.82124875116243890000e+001) (5, -6.87146020869318050000e+001) (6, 3.10944356021238450000e+001) (7, -1.18823310131020450000e+001) (8, -5.19543637975736550000e-001) (0, -1.96621358097113210000e+000) (1, 6.83558586783781670000e-001) (2, 4.04434284194582890000e+000) (3, 1.54277594027648820000e+000) (4, 1.04631016347541790000e+000) (5, -2.29679073913945110000e+000) (6, -2.02730894617193250000e+000) (7, -1.67708838566543750000e+001) (8, 3.03301439723966100000e-003) (0, -7.99184199178376240000e-001) (1, 1.28646768960089370000e+000) (2, -1.81040992794463060000e+000) (3, 2.43076915293534550000e+000) (4, -1.23576305690141890000e+000) (5, -5.43675760104162850000e-001) (6, -1.21614496203597060000e+000) (7, 7.13248899300282080000e+000) (8, -1.89770417498297590000e-001) (0, -1.58373022483900260000e+000) (1, 2.22357454716006940000e+000) (2, -1.25414986165746180000e+000) (3, -7.01949465872016810000e+000) (4, 4.45036556091109590000e+000) (5, 4.83047816605680240000e+000) (6, -3.68426457866651760000e+000) (7, -1.45377258442961850000e+001) (8, -3.10742052977766860000e-001) (0, -2.23125304810054900000e+000) (1, -1.47286806326773450000e+000) (2, 6.07937198252785560000e+000) (3, -2.38402981126899750000e+001) (4, 1.41010436124236130000e+001) (5, 4.31317906981503540000e+001) (6, 8.66058363136020760000e+000) (7, -1.16542789869025980000e+001) (8, 2.18879843613736650000e+000) (0, 6.29559943156017040000e-001) (1, 1.54581228810609690000e+001) (2, -1.49115961582681510000e-001) (3, -3.01507574988754570000e+001) (4, -2.54636233514817430000e+000) (5, 1.73664772715576310000e+001) (6, 1.60344090143826360000e+001) (7, -1.05628881011301810000e+001) (8, 6.12016815786554310000e-001) (0, -2.78265647166655970000e-001) (1, 1.21682056958692010000e+001) (2, -5.35886475553953630000e+000) (3, -6.37625548844141930000e+000) (4, 2.01929229054326110000e+000) (5, -6.00918020620709830000e+000) (6, 4.31879854538081530000e+000) (7, 7.08001642224143970000e-001) (8, 9.55571344233028250000e-001) (9, -3.38955672549331500000e+000) (10, 3.47366392487462210000e-001) (11, -2.81054148405505520000e-001) (12, -7.03469275581094720000e-003) (13, 4.27954828328288290000e-001) (14, 2.23218984956745950000e+000) (15, -2.78871580616604780000e-001) (16, -4.36993975246840860000e-001) (17, 6.57461025491913430000e-001) (18, -9.99401135430940220000e-001) (19, 8.98944880321236540000e-001) (9, 1.84914141556669560000e+000) (10, 2.90351973465207300000e-001) (11, 5.99372662801034630000e-001) (12, -2.83705304302953930000e-001) (13, -3.92799051409760740000e-001) (14, -2.17025662947616560000e+000) (15, 1.47984775662704270000e-001) (16, 1.25676905465463030000e-001) (17, -6.84184404869384920000e-001) (18, 1.43561954291953710000e+000) (19, 1.24472543924130430000e-001) (9, 6.21533837969617500000e+000) (10, 2.07976382173609990000e+000) (11, 8.20238910928161870000e-002) (12, -2.56697418543783070000e-002) (13, -1.11309440368292730000e+000) (14, -2.40532231118466110000e+000) (15, 1.80008621271842630000e+000) (16, 9.14907910182448990000e-001) (17, -5.68289697497080140000e-001) (18, 4.65484804516321290000e-001) (19, 5.88743912709362100000e-001) (9, -1.06313975101561760000e-001) (10, 3.94122665306063880000e-001) (11, 1.39532437488817160000e+000) (12, -2.78237708038071850000e-001) (13, -3.18855268667166180000e-001) (14, -2.58314462116316750000e+000) (15, -3.65356659387166440000e-001) (16, -9.15429483467568690000e-001) (17, -7.52935267498744620000e-001) (18, 1.55222908373772840000e+000) (19, 5.73788220604522950000e-001) (9, 8.89277597368216630000e+000) (10, 6.17079725023236710000e-001) (11, 1.47403565704228770000e+000) (12, 5.38583805247452420000e-001) (13, -1.70950954290021780000e+000) (14, -3.23027464171884840000e+000) (15, 2.83254104515697900000e+000) (16, 8.19407954823538450000e-001) (17, -1.38088923784464400000e+000) (18, 9.67723314877380950000e-001) (19, 1.34741594426482770000e+000) 
