FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 11 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (9, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (11, 6, 5.00000000000000000000e-001) (0, 6, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.10875985452862690000e-001) (1, -3.69032357928533010000e-001) (2, -1.13107489328009040000e-001) (3, -2.43584410970782090000e+000) (4, 2.49395923615841040000e+000) (5, 2.33577392524502200000e+000) (6, -2.33360574184589400000e+000) (7, -1.63879919545111830000e+000) (8, 6.04005362702442760000e-002) (0, 1.56550560315077810000e+000) (1, 5.52300287942726230000e-001) (2, -2.86219422360593220000e-001) (3, -5.79647816632934540000e+000) (4, 6.16691411685352890000e+000) (5, 1.48073499191794420000e+000) (6, -1.68603369723255730000e+001) (7, 1.25320209817709460000e+001) (8, 3.94724453956200430000e-001) (0, 1.11022944966426620000e+000) (1, 9.23272506836450010000e-001) (2, 5.93258133511868290000e-001) (3, -1.91338043874562070000e-001) (4, -1.17948665088781550000e+000) (5, -3.33452766852297030000e+000) (6, 1.52233296568733100000e+000) (7, -3.36666925080345960000e-001) (8, 2.06847320902058480000e-001) (0, -4.75912431005870930000e+000) (1, -1.72385053737144880000e+000) (2, -5.59579861236633920000e+000) (3, 4.16410264691454120000e+000) (4, -6.99050126750369750000e+000) (5, 1.82462726501093650000e+001) (6, -1.24353282454046310000e+000) (7, 7.33634286133859170000e+000) (8, 9.72800153700409510000e-001) (0, 6.90717196747755930000e+000) (1, -8.21183741477659980000e+000) (2, -1.64077114070544530000e+001) (3, -2.89083574270879270000e+000) (4, 8.58961989470278690000e-001) (5, 6.03761281749058740000e+000) (6, -5.17106086193983310000e+000) (7, 1.22194112758678700000e+001) (8, -8.10817130585038260000e-002) (0, -1.59820666487459550000e-001) (1, -5.32576243639537150000e-001) (2, -1.28283610304965250000e+000) (3, 1.83189689482917830000e+000) (4, -4.75434301007493690000e+000) (5, 7.82535210072110690000e-001) (6, -2.16992640769270650000e+000) (7, 7.01601696761270870000e+000) (8, 1.27632186852572490000e-001) (0, 4.62347139184482450000e+000) (1, -1.36178332748232630000e-001) (2, 1.97338040336928990000e+000) (3, 3.86649831321713580000e+000) (4, -1.67661161645272540000e+001) (5, -3.05655409747419830000e+000) (6, 4.57200421119403620000e+000) (7, 2.24462457386034940000e+000) (8, -1.21592511858385090000e-001) (0, -1.17319966280230080000e+001) (1, -1.19591450422075240000e+000) (2, 1.10628615133863450000e+001) (3, -4.22511352353502720000e+000) (4, -1.25047232502097870000e+001) (5, 1.65284451469989760000e+001) (6, -2.65682493807257560000e+001) (7, 1.33776695835931620000e+001) (8, -3.22474220065362690000e-001) (0, 7.68583063655158940000e+000) (1, 2.16596314220323550000e+000) (2, -6.66032445393452300000e-001) (3, 6.36430648116597220000e-001) (4, -7.20525033285754810000e+000) (5, 8.73647318930150130000e-001) (6, 1.33395809213633110000e+001) (7, -1.36223279462385940000e+001) (8, 8.60427566658508450000e-002) (0, -1.29564222544842230000e+000) (1, -4.91194542089500440000e+000) (2, -1.14178256206925130000e+001) (3, -4.66490884666419530000e+000) (4, 2.54340145617588580000e+001) (5, -1.59973200638855050000e+000) (6, 1.67026029160525090000e+001) (7, -2.87196934654591230000e+001) (8, -3.83921222780177210000e-001) (9, 2.35280846073916580000e-001) (10, -1.36023329808730150000e+000) (11, 4.09402351870596870000e-001) (12, -7.88082250198647750000e-001) (13, 5.10413377117611700000e-001) (14, 8.70020459169202340000e-001) (15, -1.63471946612429140000e+000) (16, 2.06634007943177430000e-001) (17, 3.17152464662097900000e-001) (18, -6.80434350558489330000e-001) (19, 9.06939251131615440000e-001) (9, -8.19838934051297260000e-001) (10, 1.31833920923448230000e+000) (11, 1.31956609038606130000e+000) (12, 1.17754421932135030000e+000) (13, -3.02619568665551180000e-001) (14, -1.53522262720880760000e+000) (15, 1.02958846071635700000e+000) (16, 1.69222174386654210000e-001) (17, 5.70708200325966170000e-004) (18, 5.90604843175083990000e-001) (19, 2.64177957173367560000e-001) (9, -4.64136150992361520000e+000) (10, 2.35236977749259820000e+000) (11, -9.92043696879307820000e-001) (12, 8.95731840588798070000e-001) (13, -6.18463873744735880000e-001) (14, -1.35118643658021000000e+000) (15, 1.87246354091530230000e+000) (16, 7.35276424172254690000e-001) (17, 6.92926991711695470000e-001) (18, 1.44263307534536930000e+000) (19, 9.43781909230422710000e-001) (9, -2.15303499235071750000e+000) (10, 7.34289561861361960000e-001) (11, -6.14455909668613960000e-001) (12, 1.22460819539864870000e+000) (13, 4.56128584102942600000e-001) (14, -6.71465757350557890000e+000) (15, 2.20257041583977480000e+000) (16, -6.16256221286092030000e-001) (17, -1.88948088927197340000e+000) (18, -2.51104044675922900000e-001) (19, 9.36035573598188120000e-001) (9, -5.26742363958938760000e+000) (10, 3.18843652576366710000e+000) (11, -2.89744951931308890000e+000) (12, 1.22268175867188340000e+000) (13, -6.40209706791299290000e-001) (14, -4.37521436546577910000e+000) (15, 3.61716021077905530000e+000) (16, -4.27540325740141670000e-001) (17, -1.19695247213736700000e+000) (18, 1.39272846419563230000e+000) (19, 1.05641989072222380000e+000) 
